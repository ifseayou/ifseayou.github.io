<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hive 及相关 SQL笔记</title>
    <url>/2023/10/01/Hive/</url>
    <content><![CDATA[<p>本篇文章记录了，自己在实际工作和学习中遇到的一些问题，算是SQL相关的总结</p>
<p>更多文章欢迎关注公众号：stackoverflow</p>
<p>下面是关于SQL在引擎内部执行的顺序的简易版/必记版：</p>
<blockquote>
<p>from 某表，group by 某字段，开窗 ，聚合函数，having，distinct , order by , limit ，尤其注意当group by 和 开窗相遇时，一定是分组<sub>groupBy</sub>优先</p>
</blockquote>
<h2 id="hive的架构">hive的架构</h2>
<p>如下图是Hive的架构图，即解析器-编译器-优化器-执行器，区别于MySQL的，连接器-分析器-优化器-执行器</p>
<span id="more"></span>
<p align="center">
  <img src="/2023/10/01/Hive/1.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> Hive架构 VS Mysql架构 </span>
</p>
<p>Metastrore是存储元数据的数据库，默认使用的是derby，可以更改为<em><strong>MySQL</strong></em>，元数据指的是将结构化数据映射成一张表的表名，表所属的数据库(默认为default)，表的拥有者，表的列，分区字段，表的类型(是否为外部表)表所在的目录等。Hive只是和RDB只是在SQL语句上有着类似之处</p>
<h2 id="第一部分">第一部分</h2>
<h3 id="collect-x">collect_x</h3>
<p>在使用这个函数时，需要设置<code>set hive.map.aggr = false;</code> 否则可能会发生<code>IllegalArgumentException Size requested for unknown type: java.util.Collection</code>的异常<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> collect_set(col_a)  <span class="keyword">as</span>          set_a</span><br><span class="line">     , collect_list(col_a) <span class="keyword">as</span>          list_a</span><br><span class="line">     , sort_array(collect_list(col_a)) sort_list_a  <span class="comment">-- sort_array 可对序列排序</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">select</span> <span class="string">'a'</span> col_a</span><br><span class="line">         <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">         <span class="keyword">select</span> <span class="string">'b'</span> col_a</span><br><span class="line">         <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">         <span class="keyword">select</span> <span class="string">'a'</span> col_a</span><br><span class="line">         <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">         <span class="keyword">select</span> <span class="string">'a'</span> col_a</span><br><span class="line">     ) t</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/10/01/Hive/12.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> collect_list函数和 collect_set函数的用法 </span>
</p>
<blockquote></blockquote>
<h3 id="日期">日期</h3>
<p>以下是 hive 语法</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> date_format(<span class="string">'2019-02-10'</span>,<span class="string">'yyyy-MM'</span>);  </span><br><span class="line"><span class="number">2019</span><span class="number">-02</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> date_add(<span class="string">'2019-02-10'</span>,<span class="number">-1</span>),date_add(<span class="string">'2019-02-10'</span>,<span class="number">1</span>);</span><br><span class="line"><span class="number">2019</span><span class="number">-02</span><span class="number">-09</span>  <span class="number">2019</span><span class="number">-02</span><span class="number">-11</span></span><br><span class="line"><span class="comment">-- (1)取当前天的下一个周一</span></span><br><span class="line"><span class="keyword">select</span> next_day(<span class="string">'2019-02-12'</span>,<span class="string">'MO'</span>)</span><br><span class="line"><span class="number">2019</span><span class="number">-02</span><span class="number">-18</span></span><br><span class="line"><span class="comment">-- 说明：星期一到星期日的英文(Monday，Tuesday、Wednesday、Thursday、Friday、Saturday、Sunday)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- (2)取当前周的周一   </span></span><br><span class="line"><span class="keyword">select</span> date_add(next_day(<span class="string">'2019-02-12'</span>,<span class="string">'MO'</span>),<span class="number">-7</span>);</span><br><span class="line"><span class="number">2019</span><span class="number">-02</span><span class="number">-11</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- (3)取当前周的周日   </span></span><br><span class="line"><span class="keyword">select</span> date_add(next_day(<span class="string">'2019-06-09'</span>,<span class="string">'mo'</span>),<span class="number">-1</span>);</span><br><span class="line"><span class="number">2019</span><span class="number">-06</span><span class="number">-09</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- (4)求当月最后一天日期</span></span><br><span class="line"><span class="keyword">select</span> last_day(<span class="string">'2019-02-10'</span>);</span><br><span class="line"><span class="number">2019</span><span class="number">-02</span><span class="number">-28</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 求上个月</span></span><br><span class="line"><span class="keyword">select</span> substr(add_months(<span class="built_in">current_date</span>(),<span class="number">-1</span>),<span class="number">1</span>,<span class="number">7</span>) method_one</span><br><span class="line">, substr(date_sub(from_unixtime(unix_timestamp()), dayofmonth(from_unixtime(unix_timestamp()))), <span class="number">1</span>, <span class="number">7</span>) <span class="keyword">as</span> method_two</span><br></pre></td></tr></tbody></table></figure>
<h3 id="时区">时区</h3>
<p>格林威治时间（Greenwich Mean Time，简称GMT）是世界上最常用的时间标准之一。它以英国伦敦的格林威治皇家天文台为参考点，用于标定全球的时间。格林威治时间通常用作协调世界时（Coordinated Universal Time，简称UTC）的基准，因此这两个术语通常是互换使用的</p>
<p><strong>UTC的时间戳，在全球任何一个地点，都是一个值，是一个13位的数字</strong>，小明在纽约，小红在上海，小蓝在格林威治天文台，他们三个在同一个时刻，得到的时间戳是一致的。只是在各自在不同的时区，换算当地的时区的时间表现形式不一致，如下的这个例子中</p>
<figure class="highlight tex"><table><tbody><tr><td class="code"><pre><span class="line">时间戳: 1694682379271</span><br><span class="line">纽约时间: 2023-09-14 05:06:19</span><br><span class="line">GMT<span class="built_in">&amp;</span>UTC时间: 2023-09-14 09:06:19</span><br><span class="line">北京时间: 2023-09-14 17:06:19</span><br></pre></td></tr></tbody></table></figure>
<p>以下的hive，impala语法</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 用于将【指定时区的时间】转换为 【UTC（协调世界时）时间】。这个函数接受两个参数：【要转换的时间】和【源时区】</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> to_utc_timestamp(<span class="string">'2023-09-14 17:06:19'</span>, <span class="string">'Asia/Shanghai'</span>)  <span class="keyword">as</span>  `将输入时区对应的时间转为GMT时间`;</span><br><span class="line"><span class="number">2023</span><span class="number">-09</span><span class="number">-14</span> <span class="number">09</span>:<span class="number">06</span>:<span class="number">19</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 用于将【UTC时区的时间】转换为【目标时区的时间】。这个函数接受两个参数：【UTC时区的时间】和【目标时区】</span></span><br><span class="line"><span class="keyword">SELECT</span> from_utc_timestamp(<span class="string">'2023-09-14 09:06:19'</span>, <span class="string">'Asia/Shanghai'</span>)  <span class="keyword">as</span>  `将UTC时区对应的时间转为目标时区`;</span><br><span class="line"><span class="number">2023</span><span class="number">-09</span><span class="number">-14</span> <span class="number">17</span>:<span class="number">06</span>:<span class="number">19</span></span><br><span class="line"><span class="keyword">SELECT</span> from_unixtime(unix_timestamp()) <span class="keyword">as</span> `UTC时间<span class="operator">&amp;</span>GMT时间`</span><br><span class="line">     , <span class="built_in">current_timestamp</span>()             <span class="keyword">as</span> `返回东八区`</span><br><span class="line">     , unix_timestamp()                <span class="keyword">as</span> `返回时间戳`</span><br></pre></td></tr></tbody></table></figure>
<p>下图可以发现 <code>hive 3</code>  中 <code>from_unixtime</code> 函数并没有根据本地的时区进行时间的转化，而是直接使用UTC的时区，而 <code>impala</code> 对时区做了转换</p>
<p align="center">
  <img src="/2023/10/01/Hive/27.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> impala和hive3时区对比 </span>
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 将北京时间转为巴西时间</span></span><br><span class="line"><span class="keyword">select</span> from_utc_timestamp(to_utc_timestamp("2021-05-09 22:14:30",<span class="string">'GMT+8'</span>),"GMT-3")</span><br><span class="line"><span class="number">2021</span><span class="number">-05</span><span class="number">-09</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">30.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> date_format(from_utc_timestamp(to_utc_timestamp("2021-05-09 22:14:30",<span class="string">'GMT+8'</span>),"GMT-3"),<span class="string">'yyyy-MM-dd HH:mm:ss'</span>)</span><br><span class="line"><span class="number">2021</span><span class="number">-05</span><span class="number">-09</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">30</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="字符串处理">字符串处理</h3>
<p><code>substr</code>，<code>replace</code>等就不赘述了</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 1)</span></span><br><span class="line"><span class="keyword">select</span> regexp_extract(<span class="string">'http://a.m.taobao.com/i41915173660.html'</span>, <span class="string">'i([0-9]+)'</span>, <span class="number">0</span>)</span><br><span class="line">     , regexp_extract(<span class="string">'http://a.m.taobao.com/i41915173660.html'</span>, <span class="string">'i([0-9]+)'</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">-- i41915173660    ,   41915173660</span></span><br><span class="line"><span class="comment">-- 0是显示与之匹配的整个字符串； 1是显示第一个括号里面的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2)</span></span><br><span class="line"><span class="keyword">select</span>  regexp_replace(<span class="string">'a1b2c3d4'</span>, <span class="string">'[0-9]'</span>, <span class="string">'-'</span>);</span><br><span class="line"><span class="comment">-- a-b-c-d-</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3)</span></span><br><span class="line"><span class="comment">-- 某字符串是另外一个字符串的子串</span></span><br><span class="line">instr(string string, string substring)</span><br><span class="line"><span class="comment">-- 返回查找字符串string中子字符串substring出现的位置，如果查找失败将返回0，如果任一参数为Null将返回null，位置为从1开始。</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="除数为0处理">除数为0处理</h3>
<p>这里我们将比较不同的引擎是如何处理<strong>除数为0</strong>的问题的，如下图：</p>
<p align="center">
  <img src="/2023/10/01/Hive/13.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 不同引擎除0的结果比对 </span>
</p>
<blockquote>
<p>对于除数为0问题，优先使用<code>nullif(a,0)</code>函数来进行处理，但是该函数Hive2.2才有对应实现，<code>nullif((a,b)</code> 的语义在于，如果参数 a 等于 参数 b 那么，该函数返回 <code>null</code></p>
</blockquote>
<h2 id="第二部分">第二部分</h2>
<h3 id="sum-over">sum()  + over()</h3>
<p align="center">
  <img src="/2023/10/01/Hive/6.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 不同引擎除0的结果比对 </span>
</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>over() 全局求和</p>
</li>
<li class="lvl-2">
<p>over(order by) 全局累积求和</p>
</li>
<li class="lvl-2">
<p>over(partition by ) 分区内全局求和</p>
</li>
<li class="lvl-2">
<p>over(partition by order by) 分区内累积求和</p>
</li>
</ul>
</blockquote>
<p>内网环境下，下面的脚本分别在 impala，hive，holo，pg , mysql ,执行以下，看下是什么情况</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> a,<span class="number">1</span> <span class="keyword">as</span> b </span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> a , <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span> </span><br><span class="line">    <span class="keyword">select</span> <span class="string">'b'</span> <span class="keyword">as</span> b , <span class="number">10</span> <span class="keyword">as</span> b</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> a , </span><br><span class="line">     <span class="built_in">avg</span>(b) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a <span class="keyword">order</span> <span class="keyword">by</span> b) x ,</span><br><span class="line">     <span class="built_in">sum</span>(b) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a <span class="keyword">order</span> <span class="keyword">by</span> b) y</span><br><span class="line"><span class="keyword">from</span> tmp1 </span><br><span class="line">;</span><br></pre></td></tr></tbody></table></figure>
<p>关于聚合函数+窗口函数的描述，<a href="https://www.geeksforgeeks.org/window-functions-in-sql/">GreeksforGreeks上的那个博文是错的</a></p>
<h3 id="侧写视图-lateral-view">侧写视图(lateral view)</h3>
<p>🎈<code>explode(split())</code> 只能用来解决一行转多列的单字段问题，侧写视图主要用来处理，通用行转列的问题</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- hive 语法</span></span><br><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span>(</span><br><span class="line"><span class="keyword">select</span> <span class="string">'A;B;C'</span> <span class="keyword">as</span> name , <span class="number">20</span> <span class="keyword">as</span> age</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> explode(split(name,<span class="string">';'</span>))</span><br><span class="line">         , age <span class="comment">-- Only a single expression in the SELECT clause is supported with UDTF's </span></span><br><span class="line">         <span class="comment">-- 如果是多列，使用测斜视图语法</span></span><br><span class="line"><span class="keyword">from</span> tmp1</span><br><span class="line">;</span><br><span class="line"><span class="comment">-- 如下（hive语法）</span></span><br><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span>(</span><br><span class="line"><span class="keyword">select</span> <span class="string">'A;B;C'</span> <span class="keyword">as</span> name , <span class="number">20</span> <span class="keyword">as</span> age</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> name </span><br><span class="line">     , age </span><br><span class="line">     , col_x</span><br><span class="line"><span class="keyword">from</span> tmp1 <span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(name,<span class="string">';'</span>)) x <span class="keyword">as</span> col_x</span><br><span class="line">;</span><br></pre></td></tr></tbody></table></figure>
<table>
<thead>
<tr>
<th>name</th>
<th>age</th>
<th>col_x</th>
</tr>
</thead>
<tbody>
<tr>
<td>A;B;C</td>
<td>20</td>
<td>A</td>
</tr>
<tr>
<td>A;B;C</td>
<td>20</td>
<td>B</td>
</tr>
<tr>
<td>A;B;C</td>
<td>20</td>
<td>C</td>
</tr>
</tbody>
</table>
<center>该表格可左右移动</center>
<h3 id="lag-over的使用">lag+over的使用</h3>
<p>其中最为常用的是：**按照时间正序排序，<code>lag</code>获取上个周期的值  **</p>
<p align="center">
  <img src="/2023/10/01/Hive/8.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> lag + over 的使用 </span>
</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>lag （落后）是获取上一个</p>
</li>
<li class="lvl-2">
<p>lead （领导）是获取下一个</p>
</li>
</ul>
<p align="center">
  <img src="/2023/10/01/Hive/21.png" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> SQL（StructuredQueryLanguage）标准认为当前行的上一个行是后面，下一行是前面 </span>
</p>
<h3 id="一周内连续3天活跃">一周内连续3天活跃</h3>
<p align="center">
  <img src="/2023/10/01/Hive/14.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 一周连续X天活跃的最佳解法 </span>
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span>(</span><br><span class="line">    <span class="keyword">select</span> <span class="number">0</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-12'</span> <span class="keyword">as</span> dt <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">0</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-16'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">0</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-17'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">0</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-18'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-11'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-13'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-14'</span> <span class="keyword">as</span> dt  <span class="keyword">union</span>  <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> mid_id,<span class="string">'2020-02-17'</span> <span class="keyword">as</span> dt</span><br><span class="line">) ,</span><br><span class="line">tmp2 <span class="keyword">as</span> (</span><br><span class="line">         <span class="keyword">select</span> mid_id</span><br><span class="line">            , dt</span><br><span class="line">            , <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> mid_id <span class="keyword">order</span> <span class="keyword">by</span> dt)               rk</span><br><span class="line">            , date_sub(dt, <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> mid_id <span class="keyword">order</span> <span class="keyword">by</span> dt)) diff</span><br><span class="line">       <span class="keyword">from</span> tmp1</span><br><span class="line">       <span class="keyword">where</span> dt <span class="keyword">between</span> date_sub(<span class="string">'2020-02-18'</span>, <span class="number">7</span>) <span class="keyword">and</span> <span class="string">'2020-02-18'</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> mid_id</span><br><span class="line"><span class="keyword">from</span> tmp2</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> mid_id,diff</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="operator">&gt;=</span><span class="number">3</span> ;</span><br></pre></td></tr></tbody></table></figure>
<p>对于类似的连续X天的问题，最优的解决方案是使用开窗函数，另外的一种解题思路是<strong>自关联</strong>，关联时，使用 <code>t1.mid_id = t2.mid_id and t1.dt = date_sub(t2.dt,x)</code>的方式</p>
<h3 id="left-semi-join">left semi join</h3>
<p>关于<code>left semi join</code> 注意2点：</p>
<p>🅰️<code>left semi join</code> 要严格区分于<code>left outer join(left join)</code></p>
<p>🅱️ <code>t1 left semi join t2 </code> 选列时，不允许出现t2 的字段</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> t1.id, t1.fieldA</span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">where</span> t1.id <span class="keyword">in</span> (</span><br><span class="line">    <span class="keyword">select</span> id</span><br><span class="line">    <span class="keyword">from</span> `table_B`</span><br><span class="line">); <span class="comment">-- A 和 B的 交集</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 可改写为exists的方式</span></span><br><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">exists</span> (</span><br><span class="line">    <span class="keyword">select</span> t2.id</span><br><span class="line">    <span class="keyword">from</span> `table_B` t2</span><br><span class="line">    <span class="keyword">where</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 还可改写为</span></span><br><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> `table_B` t2</span><br><span class="line"><span class="keyword">on</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"><span class="keyword">where</span> t2.id <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="comment">-- A 和 B 的交集</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 改写为 ，这种方式更加高效</span></span><br><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span> <span class="comment">-- 不允许出现t2 的字段</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">left</span> semi <span class="keyword">join</span> `table_B` t2</span><br><span class="line"><span class="keyword">on</span> t1.id <span class="operator">=</span> t2.id;</span><br></pre></td></tr></tbody></table></figure>
<p>同理对于<code>not  exist</code></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> `table_B` t2</span><br><span class="line"><span class="keyword">on</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"><span class="keyword">where</span> t2.id <span class="keyword">is</span>  <span class="keyword">null</span> <span class="comment">-- A中有B中没有</span></span><br><span class="line">;</span><br><span class="line"><span class="comment">-- 我们换成下面的写法</span></span><br><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">not</span> <span class="keyword">exists</span> (</span><br><span class="line">    <span class="keyword">select</span> t2.id</span><br><span class="line">    <span class="keyword">from</span> `table_B` t2</span><br><span class="line">    <span class="keyword">where</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line">) <span class="comment">-- A中有B中没有</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 或者换成下面的写法</span></span><br><span class="line"><span class="keyword">select</span> t1.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> `table_A` t1</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">not</span> <span class="keyword">in</span> (</span><br><span class="line">    <span class="keyword">select</span> t2.id</span><br><span class="line">    <span class="keyword">from</span> `table_B` t2</span><br><span class="line">    <span class="keyword">where</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line">) <span class="comment">-- A中有B中没有</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="distinct">distinct</h3>
<h4 id="🅰️-distinct-和-order-by-的结合">🅰️ distinct 和 order by 的结合</h4>
<p>先执行distinct ，后执行order by ，最后limit</p>
<p align="center">
  <img src="/2023/10/01/Hive/3.jpg" width="50%" alt="Your image description">
    <br>
  <span style="color:gray"> 先执行 distinct ，后执行 order by </span>
</p>
<h4 id="🅱️-distinct-多个字段">🅱️ distinct 多个字段</h4>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">distinct` 多个字段对所有字段都起作用，并不是一个；如 `select distinct field_a,field_b from table;</span><br><span class="line">a1,b1;</span><br><span class="line">a1,b2;</span><br><span class="line">a2,b2;</span><br><span class="line">-- 只要有不同就会被选择出来</span><br></pre></td></tr></tbody></table></figure>
<h3 id="limit-offset">limit offset</h3>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">limit x offset y` ,$y$是$x$的倍数出现，可以恰好将数据取完，`limit x offset y` 等效于 `limit y,x</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/10/01/Hive/15.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> limit 的用法 </span>
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="number">1</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">2</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">3</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">4</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">5</span> a</span><br><span class="line">) t</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">3</span> <span class="keyword">offset</span> <span class="number">3</span>; </span><br></pre></td></tr></tbody></table></figure>
<p>最后一个截图的SQL语句，我在Hive2.1.1中的执行结果是：</p>
<p align="center">
  <img src="/2023/10/01/Hive/24.png" width="70%" alt="Your image description">
    <br>
  <span style="color:gray">24 </span>
</p>
<p>说明在Hive中<code>offset</code>的排序是从1开始的（x取0等于x=1）</p>
<h3 id="ntile-over">ntile+over</h3>
<p><code>ntile(x)</code>将数据划均分为x个桶，并且返回桶编号，如果有多的元素，优先进入第一个桶</p>
<p align="center">
  <img src="/2023/10/01/Hive/22.png" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 使用nile将数据均分到x桶内 </span>
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> name , <span class="string">'one'</span> <span class="keyword">as</span> claz, <span class="number">1</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'b'</span> <span class="keyword">as</span> name , <span class="string">'two'</span> <span class="keyword">as</span> claz, <span class="number">2</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> name , <span class="string">'two'</span> <span class="keyword">as</span> claz, <span class="number">3</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'d'</span> <span class="keyword">as</span> name , <span class="string">'one'</span> <span class="keyword">as</span> claz, <span class="number">4</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'e'</span> <span class="keyword">as</span> name , <span class="string">'one'</span> <span class="keyword">as</span> claz, <span class="number">5</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'f'</span> <span class="keyword">as</span> name , <span class="string">'two'</span> <span class="keyword">as</span> claz, <span class="number">6</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'g'</span> <span class="keyword">as</span> name , <span class="string">'one'</span> <span class="keyword">as</span> claz, <span class="number">7</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'h'</span> <span class="keyword">as</span> name , <span class="string">'one'</span> <span class="keyword">as</span> claz, <span class="number">8</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'i'</span> <span class="keyword">as</span> name , <span class="string">'two'</span> <span class="keyword">as</span> claz, <span class="number">9</span> <span class="keyword">as</span> score <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'j'</span> <span class="keyword">as</span> name , <span class="string">'two'</span> <span class="keyword">as</span> claz, <span class="number">0</span> <span class="keyword">as</span> score</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line">     , <span class="built_in">ntile</span>(<span class="number">2</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> claz <span class="keyword">order</span> <span class="keyword">by</span> score) rn</span><br><span class="line"><span class="keyword">from</span> tmp1;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="模糊匹配多个字段">模糊匹配多个字段</h3>
<img src="/2023/10/01/Hive/23-6152215.png" width="100%" height="25%" alt="图片名称" align="left">
<p>在hive或者是impala种，或者使用 <code>rlike</code>：其作用在于<strong>模糊匹配多个值</strong></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- hive &amp; impala</span></span><br><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span>(</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'abc大'</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'中abc'</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'abc小'</span> <span class="keyword">as</span> a</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tmp1</span><br><span class="line"><span class="comment">-- where a rlike '大|中' -- 写法1</span></span><br><span class="line"><span class="keyword">where</span> a regxp <span class="string">'大|中'</span>    <span class="comment">-- 写法2</span></span><br><span class="line"><span class="comment">-- 中abc</span></span><br><span class="line"><span class="comment">-- abc大</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- holo &amp; pg</span></span><br><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span>(</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'abc大'</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'中abc'</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'abc小'</span> <span class="keyword">as</span> a</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tmp1</span><br><span class="line"><span class="keyword">where</span> a <span class="operator">~</span> <span class="string">'大|中'</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="窗口函数的范围选择">窗口函数的范围选择</h3>
<p>注意 <code>range</code> 和<code>rows</code>之间的使用区别：  <strong>rows计算的是行，range 计算的是值</strong>， preceding 往上，following 往下</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">agg_func <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> col_name <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> proceding <span class="keyword">and</span> <span class="number">1</span> following) <span class="comment">-- col_name的前后1行</span></span><br><span class="line">agg_func <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> col_name <span class="keyword">range</span> <span class="keyword">between</span> <span class="number">1</span> proceding <span class="keyword">and</span> <span class="number">1</span> following) <span class="comment">-- col_name值的(+/- 1) 的值</span></span><br><span class="line"></span><br><span class="line">agg_func <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> col_name <span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> unbounded following) <span class="comment">-- 全部行</span></span><br><span class="line">agg_func <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> col_name <span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span>) <span class="comment">-- 开头到当前行</span></span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/10/01/Hive/19.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 窗口函数的选择范围 </span>
</p>
<img src="/2023/10/01/Hive/20-6152215.png" width="100%" height="100%" alt="图片名称" align="left/">
<h2 id="第三部分">第三部分</h2>
<h3 id="select-非-group-by-字段">select 非 group by 字段</h3>
<p><strong>MySQL支持</strong>，Hive,Impala,PostgreSQL 不支持</p>
<p>对于下面这一段SQL</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> dept</span><br><span class="line">     , emp</span><br><span class="line">     , <span class="built_in">max</span>(sal) <span class="keyword">as</span> max_sal</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'A'</span> <span class="keyword">as</span> dept, <span class="string">'a1'</span> <span class="keyword">as</span> emp, <span class="number">10</span> <span class="keyword">as</span> sal <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'A'</span> <span class="keyword">as</span> dept, <span class="string">'a2'</span> <span class="keyword">as</span> emp, <span class="number">20</span> <span class="keyword">as</span> sal <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'B'</span> <span class="keyword">as</span> dept, <span class="string">'b2'</span> <span class="keyword">as</span> emp, <span class="number">100</span> <span class="keyword">as</span> sal <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'B'</span> <span class="keyword">as</span> dept, <span class="string">'b1'</span> <span class="keyword">as</span> emp, <span class="number">200</span> <span class="keyword">as</span> sal</span><br><span class="line">) t</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dept</span><br></pre></td></tr></tbody></table></figure>
<p>1️⃣MySQL 通过</p>
<p align="center">
  <img src="/2023/10/01/Hive/5.jpg" width="50%" alt="Your image description">
    <br>
  <span style="color:gray"> mysql select 非 group by 的字段 </span>
</p>
<p>MySQL 选择记录中的第一个记录(从实验结果来看，是记录的第一行)</p>
<p>2️⃣ postgreSQL：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">[<span class="number">42803</span>] ERROR: <span class="keyword">column</span> "t.emp" must appear <span class="keyword">in</span> the <span class="keyword">GROUP</span> <span class="keyword">BY</span> clause <span class="keyword">or</span> be used <span class="keyword">in</span> an aggregate <span class="keyword">function</span></span><br></pre></td></tr></tbody></table></figure>
<p>3️⃣ Hive：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">Error while compiling statement: FAILED: SemanticException [Error <span class="number">10025</span>]: line <span class="number">2</span>:<span class="number">7</span> Expression <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> key <span class="string">'emp'</span></span><br></pre></td></tr></tbody></table></figure>
<p>4️⃣ Impala：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">AnalysisException: <span class="keyword">select</span> list expression <span class="keyword">not</span> produced <span class="keyword">by</span> aggregation output (missing <span class="keyword">from</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> clause?): emp</span><br></pre></td></tr></tbody></table></figure>
<h3 id="having-过滤是否支持别名">having 过滤是否支持别名</h3>
<p>MySQL和Hive是支持的， impala和postgreSQL不支持，🎈：<strong>推荐无论何时都不使用别名进行分组后过滤</strong></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> cnt</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="number">5</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">4</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">4</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">3</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">3</span> <span class="keyword">as</span> a</span><br><span class="line">) t</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a</span><br><span class="line"><span class="keyword">having</span> cnt <span class="operator">&gt;</span> <span class="number">1</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>上述的SQL在MySQL 和 hive中执行都是没问题的，在impala和postgreSQL报错 <code>column "cnt" does not exist</code>,需要下面的写法</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> cnt</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="number">5</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">4</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">4</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">3</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="number">3</span> <span class="keyword">as</span> a</span><br><span class="line">) t</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="operator">&gt;</span> <span class="number">1</span>;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="order-by-字符串">order by 字符串</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span>  <span class="string">'a'</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span>  <span class="comment">-- 97</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">''</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span>    <span class="comment">-- 66</span></span><br><span class="line">    <span class="keyword">select</span>  <span class="string">' '</span> <span class="keyword">as</span> a <span class="keyword">union</span> <span class="keyword">all</span>  <span class="comment">-- 32</span></span><br><span class="line">    <span class="keyword">select</span> <span class="keyword">null</span> <span class="keyword">as</span> a            <span class="comment">-- 0</span></span><br><span class="line">) t</span><br><span class="line"><span class="keyword">order</span>  <span class="keyword">by</span> a <span class="keyword">desc</span> ;</span><br></pre></td></tr></tbody></table></figure>
<p>对于以上查询和排序，Hive和MySQL认为NULL是最小；Impala和PostgresSQL认为NULL最大，如果使用<code>explain</code>命令查看SQL的执行计划的话，会明显看到编译器会给SQL添加1个<code>null first / null last</code>的明亮，这个取决于具体的引擎，感兴趣的读者可以自己test下，比如Hive会将null设为最小，impala会将null设为最大</p>
<p align="center">
  <img src="/2023/10/01/Hive/10.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> null，空串，空格 之间的排序关系</span>
</p>
<h3 id="24-5-的结果">$24/5$的结果</h3>
<table>
<thead>
<tr>
<th>DB/Program Language</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Java / PostgreSQL</td>
<td>4</td>
</tr>
<tr>
<td>Hive / Impala / MySQL</td>
<td>4.8</td>
</tr>
</tbody>
</table>
<h3 id="窗口函数是否支持distinct">窗口函数是否支持<code>distinct</code></h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span>  A, B , <span class="built_in">count</span>( <span class="keyword">distinct</span> A) <span class="keyword">over</span>()</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> A ,<span class="string">'a'</span> <span class="keyword">as</span> B <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> A ,<span class="string">'b'</span> <span class="keyword">as</span> B <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> A ,<span class="string">'c'</span> <span class="keyword">as</span> B <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">3</span> <span class="keyword">as</span> A ,<span class="string">'d'</span> <span class="keyword">as</span> B</span><br><span class="line">) t</span><br></pre></td></tr></tbody></table></figure>
<p>比如以上的SQL查询：Hive是支持的，Impala，MySQL，PostgreSQL暂时没有实现</p>
<h3 id="窗口嵌套">窗口嵌套</h3>
<p>窗口函数的嵌套，只Hive<sub>2.1.1</sub>中是支持的，PostgreSQL(<code>window functions are not allowed in window definitions</code>)，MySQL，Impala 中只能多嵌套一层</p>
<p align="center">
  <img src="/2023/10/01/Hive/17.jpg" width="80%" alt="Your image description">
    <br>
  <span style="color:gray"> 不同的引擎对于窗口嵌套的支持 </span>
</p>
<h3 id="字符串写入数值类型">字符串写入数值类型</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span>  business (</span><br><span class="line">    name strng,</span><br><span class="line">    order_date string,</span><br><span class="line">    cost <span class="type">float</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> business <span class="keyword">values</span>(<span class="string">'xioaming'</span>,<span class="string">'2021-08-22'</span>,<span class="string">''</span>);</span><br></pre></td></tr></tbody></table></figure>
<p>Hive 会将字符串转为<code>null</code>写入；Impala，MySQL，PostgreSQL会进行类型检查异常</p>
<h3 id="字段截取">字段截取</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- MySql</span></span><br><span class="line"><span class="keyword">select</span> substring_index(substring_index(<span class="string">'A/B/C/D/E'</span>, <span class="string">'/'</span>, <span class="number">4</span>), <span class="string">'/'</span>, <span class="number">-1</span>) <span class="keyword">as</span> dept_name0 <span class="comment">-- D</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- hive，索引从0开始</span></span><br><span class="line"><span class="keyword">select</span> substring_index(substring_index(<span class="string">'A/B/C/D/E'</span>, <span class="string">'/'</span>, <span class="number">4</span>), <span class="string">'/'</span>, <span class="number">-1</span>) <span class="keyword">as</span> dept_name0 <span class="comment">-- D</span></span><br><span class="line">     , split(<span class="string">'A/B/C/D/E'</span>, <span class="string">'/'</span>)[<span class="number">3</span>]                                     <span class="keyword">as</span> dept_name1 <span class="comment">-- D</span></span><br><span class="line">     </span><br><span class="line">    </span><br><span class="line"><span class="comment">-- pg/holo 索引从1开始</span></span><br><span class="line"><span class="keyword">select</span> split_part(<span class="string">'A/B/C/D/E'</span>, <span class="string">'/'</span>,<span class="number">4</span>)                                <span class="keyword">as</span> dept_name1 <span class="comment">-- D</span></span><br><span class="line"><span class="comment">-- impala 索引从1开始</span></span><br><span class="line"><span class="keyword">select</span> split_part(<span class="string">'A/B/C/D/E'</span>, <span class="string">'/'</span>,<span class="number">4</span>)                                <span class="keyword">as</span> dept_name1 <span class="comment">-- D、</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 其中，holo存在以下函数</span></span><br><span class="line"><span class="keyword">select</span> string_to_array(<span class="string">'xx~^~yy~^~zz'</span>, <span class="string">'~^~'</span>)           <span class="comment">-- {xx,yy,zz}</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="column-name-not-in-a-会过滤掉-null-的记录"><code>column_name not in (a)</code> 会过滤掉 <code>null</code> 的记录</h3>
<p><code>column_name not in (a)</code>： 出了会过滤掉值为<code>a</code>的记录，还会过滤掉 <code>column_name</code>为 <code>null</code> 的记录</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (<span class="comment">-- </span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'b'</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> a</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="keyword">null</span> <span class="keyword">as</span> a</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tmp1</span><br><span class="line"><span class="keyword">where</span> a <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">'a'</span>)</span><br><span class="line"><span class="comment">-- 结果返回 a,c</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="Impala-的模糊关联（非等值关联）"><code>Impala</code> 的模糊关联（非等值关联）</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- t2.name 是 t1.name 的子串的时候即返回 true ，注意顺序</span></span><br><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> ( <span class="comment">--</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'康恩贝/CONBA'</span> <span class="keyword">as</span> name, <span class="string">'2023-01-01'</span> <span class="keyword">as</span> live_date</span><br><span class="line">)</span><br><span class="line">   , tmp2 <span class="keyword">as</span> ( <span class="comment">--</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'CONBA'</span> <span class="keyword">as</span> name, <span class="string">'2023-01-01'</span> <span class="keyword">as</span> live_date</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tmp1      t1</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> tmp2 t2</span><br><span class="line">          <span class="keyword">on</span> t1.live_date <span class="operator">=</span> t2.live_date</span><br><span class="line">              <span class="keyword">and</span> t1.name rlike t2.name</span><br></pre></td></tr></tbody></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">name</th>
<th style="text-align:left">live_date</th>
<th style="text-align:left">name</th>
<th style="text-align:left">live_date</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">康恩贝/CONBA</td>
<td style="text-align:left">2023-01-01</td>
<td style="text-align:left">CONBA</td>
<td style="text-align:left">2023-01-01</td>
</tr>
</tbody>
</table>
<h2 id="第四部分">第四部分</h2>
<h3 id="null-x-关联"><code>null</code>,<code>x</code> 关联</h3>
<p align="center">
  <img src="/2023/10/01/Hive/11.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> null 和其他值的关联 </span>
</p>
<p>在任何 <code>SQL(MySQL,PostgreSQL,Hive,Impala) </code>引擎中，<strong><code>null</code>和任意值都无法关联无法相互关联，包括其本身</strong></p>
<blockquote>
<p>PostgreSQL中有类型探测，执行以上关联会发生：<a href="https://stackoverflow.com/questions/18073901/failed-to-find-conversion-function-from-unknown-to-text">Failed to find conversion function from unknown to text</a></p>
</blockquote>
<h3 id="返回1行-返回0行">返回1行&amp;返回0行</h3>
<p><strong>使用聚合函数，返回的行数一定大于等于1</strong></p>
<p align="center">
  <img src="/2023/10/01/Hive/16.png" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 返回0行和返回1行 </span>
</p>
<h3 id="union-all-的类型">union all 的类型</h3>
<p><strong>任何引擎，<code>union all</code>的类型必须保持一致</strong></p>
<h3 id="组合主键非null">组合主键非<code>null</code></h3>
<p>对于<code>test01</code>表，字段<code>a</code>和字段<code>b</code>在作为联合主键时，在字段<code>a</code>为<code>null</code>，字段<code>b</code>非<code>null</code>的时候</p>
<p>1️⃣<code>kudu</code>将不会写入该记录，不会抛异常，<strong>导致写入数据和查询数据记录数不一致</strong></p>
<p>2️⃣<code>MySql</code>插入时抛出异常 类似(<code>primary key not null</code>)</p>
<p>3️⃣<code>postgresql</code> 插入时抛出异常 类似(<code>primary key not null</code>)</p>
<h3 id="时间戳">时间戳</h3>
<p>⚠️时间是人可识别的，时间戳基本是机器识别的，比如2022-01-01 00:00:00（1640966400），前者是时间，后者是时间戳，几乎所有的引擎都实现了 <code>unix_timestamp</code>方法，支持传入一个时间，如果没有传入时间将使用当前的时刻</p>
<p>1️⃣ 获取时间戳</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">--mysql</span></span><br><span class="line"><span class="keyword">select</span> unix_timestamp(<span class="string">'2022-01-01 00:00:00'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- hive </span></span><br><span class="line"><span class="keyword">select</span> unix_timestamp(<span class="string">'2022-01-01 00:00:00'</span>);</span><br></pre></td></tr></tbody></table></figure>
<p>2️⃣获取时间</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- mysql</span></span><br><span class="line"><span class="keyword">select</span> now();</span><br><span class="line"></span><br><span class="line"><span class="comment">-- hive</span></span><br><span class="line"><span class="keyword">select</span> from_unixtime( unix_timestamp());</span><br><span class="line"></span><br><span class="line"><span class="comment">-- impala</span></span><br><span class="line"><span class="keyword">select</span> now(),  utc_timestamp(),<span class="built_in">current_timestamp</span>(),from_unixtime( unix_timestamp());</span><br><span class="line"></span><br><span class="line"><span class="comment">-- pg</span></span><br><span class="line"><span class="keyword">select</span>  now() ,  <span class="built_in">current_timestamp</span>;</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="去掉文本中的换行符-回车符-制表符-空格，正则替换">去掉文本中的换行符/回车符/制表符/空格，正则替换</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- \s 表示匹配一个或者多个空白字符（包括空格、制表符、换行符）， '+' 表示匹配前面的模式（即'\s'）一次或多次 </span></span><br><span class="line"><span class="keyword">select</span> regexp_replace(input_content,<span class="string">'\\s+'</span>,<span class="string">''</span>) <span class="keyword">as</span> after_content</span><br><span class="line"><span class="comment">-- hive</span></span><br><span class="line"><span class="keyword">select</span> regexp_replace(video_desc,<span class="string">'\t|\n|\001|\r'</span>,<span class="string">''</span>) <span class="keyword">as</span> video_desc</span><br><span class="line"></span><br><span class="line"><span class="comment">-- mysql5.7中不支持regexp_replace，8.0中支持，所以在5.7中使用</span></span><br><span class="line"><span class="keyword">select</span> replace(replace(video_desc, <span class="type">char</span>(<span class="number">13</span>), <span class="string">''</span>), <span class="type">char</span>(<span class="number">10</span>), <span class="string">''</span>) <span class="keyword">as</span> video_desc</span><br><span class="line"><span class="keyword">select</span> <span class="string">'1\r2\t\3\n4\0015'</span></span><br><span class="line">    ,regexp_replace(<span class="string">'1\r2\t\3\n4'</span>,<span class="string">'\\s+'</span>,<span class="string">''</span>)</span><br><span class="line">    ,regexp_replace(<span class="string">'1     \r2\t\3\n4\0015'</span>,<span class="string">'\\s+'</span>,<span class="string">''</span>)</span><br><span class="line">    ,regexp_replace(<span class="string">'1     \r2\t\3\n4\0015'</span>,<span class="string">'\t|\n|\001|\r'</span>,<span class="string">''</span>)</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/10/01/Hive/18.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 由于特殊字符导致表错位串行的问题描述 </span>
</p>
<h3 id="impala-upsert-Kudu">impala upsert + Kudu</h3>
<p>本质是<code>insert</code>  + <code>update</code> 的结合</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>主键存在时，<strong>全字段</strong>更新</p>
</li>
<li class="lvl-2">
<p>主键不存在时，插入</p>
</li>
</ul>
<h3 id="不使用order-by-找到工资第二的员工">不使用<code>order by</code> 找到工资第二的员工</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    e.emp_no,</span><br><span class="line">    salary,</span><br><span class="line">    last_name,</span><br><span class="line">    first_name</span><br><span class="line"><span class="keyword">from</span> employees e</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> salaries s</span><br><span class="line"><span class="keyword">on</span> e.emp_no <span class="operator">=</span> s.emp_no</span><br><span class="line"><span class="keyword">where</span> s.to_date <span class="operator">=</span> <span class="string">'9999-01-01'</span> </span><br><span class="line"><span class="keyword">and</span> s.salary <span class="operator">=</span> </span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span> s1.salary</span><br><span class="line">    <span class="keyword">from</span> salaries s1</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> salaries s2</span><br><span class="line">    <span class="keyword">on</span> s1.salary <span class="operator">&lt;=</span> s2.salary</span><br><span class="line">    <span class="keyword">where</span> s1.to_date <span class="operator">=</span> <span class="string">'9999-01-01'</span> <span class="keyword">and</span> s2.to_date <span class="operator">=</span> <span class="string">'9999-01-01'</span> </span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> s1.salary</span><br><span class="line">    <span class="keyword">having</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> s2.salary) <span class="operator">=</span> <span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>
<p>最大值只能小于等于最大值（出现1次)；次大值只能小于等于最大值和本身（出现2次）</p>
<p align="center">
  <img src="/2023/10/01/Hive/4.jpg" width="30%" alt="Your image description">
    <br>
  <span style="color:gray"> 求薪资次高的员工 </span>
</p>
<h3 id="from-tmp1-tmp2-的本质">from tmp1 , tmp2 的本质</h3>
<p><strong><code>from tmp1 , tmp2</code> 的本质就是 <code>inner join</code>的行为</strong></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (<span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> name, <span class="number">10</span> <span class="keyword">as</span> age</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'b'</span> <span class="keyword">as</span> name, <span class="number">11</span> <span class="keyword">as</span> age</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> name, <span class="number">12</span> <span class="keyword">as</span> age</span><br><span class="line">)</span><br><span class="line">   , tmp2 <span class="keyword">as</span> (<span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> name, <span class="string">'female'</span> <span class="keyword">as</span> sex</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'d'</span> <span class="keyword">as</span> name, <span class="string">'male'</span> <span class="keyword">as</span> sex</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'e'</span> <span class="keyword">as</span> name, <span class="string">'female'</span> <span class="keyword">as</span> sex</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> t1.name</span><br><span class="line">     , t1.age</span><br><span class="line">     , t2.sex</span><br><span class="line"><span class="keyword">from</span> tmp1 t1</span><br><span class="line">   , tmp2 t2</span><br><span class="line"><span class="keyword">where</span> t1.name <span class="operator">=</span> t2.name</span><br></pre></td></tr></tbody></table></figure>
<p>上述的SQL等同于下列SQL</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (<span class="keyword">select</span> <span class="string">'a'</span> <span class="keyword">as</span> name, <span class="number">10</span> <span class="keyword">as</span> age</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'b'</span> <span class="keyword">as</span> name, <span class="number">11</span> <span class="keyword">as</span> age</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> name, <span class="number">12</span> <span class="keyword">as</span> age</span><br><span class="line">)</span><br><span class="line">   , tmp2 <span class="keyword">as</span> (<span class="keyword">select</span> <span class="string">'c'</span> <span class="keyword">as</span> name, <span class="string">'female'</span> <span class="keyword">as</span> sex</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'d'</span> <span class="keyword">as</span> name, <span class="string">'male'</span> <span class="keyword">as</span> sex</span><br><span class="line">              <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">              <span class="keyword">select</span> <span class="string">'e'</span> <span class="keyword">as</span> name, <span class="string">'female'</span> <span class="keyword">as</span> sex</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> t1.name, t1.age, t2.sex</span><br><span class="line"><span class="keyword">from</span> tmp1       t1</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> tmp2 t2</span><br><span class="line">           <span class="keyword">on</span> t1.name <span class="operator">=</span> t2.name</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Hive-中强制-mapjoin">Hive 中强制 <code>mapjoin</code></h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+ mapjoin(t2)*/</span>  <span class="comment">--强制指定关联方式</span></span><br><span class="line"><span class="keyword">from</span> t1</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> t2 </span><br><span class="line"><span class="keyword">on</span> t1.key<span class="operator">=</span> t2.key</span><br></pre></td></tr></tbody></table></figure>
<h2 id="第四部分-2">第四部分</h2>
<p><a href="https://github.com/ifseayou/virgin-sql/blob/master/test_app.fna_compare_zhubo_stat_df.sql">ORC存储格式 和 RCFile存储格式的一个问题 - 发生 Unknow Reason问题</a></p>
<p><a href="https://github.com/ifseayou/virgin-sql/blob/master/test_app.live_goods_category_detail_df.sql">union all  + distint 的时候需要设置 <code>set hive.vectorized.execution.enabled=false;</code></a></p>
<p><a href="https://stackoverflow.com/questions/41057311/the-value-of-spark-yarn-executor-memoryoverhead-setting">spark.yarn.executor.memoryOverhead</a> ，该参数<a href="https://spark.apache.org/docs/2.2.0/running-on-yarn.html">官方地址</a>，出现这个问题提升该参数的阈值是一方面，另一方面可以增加 executor的数量，<code>set spark.dynamicAllocation.maxExecutors=14;</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask. Spark job failed because of out of memory.</span><br><span class="line"></span><br><span class="line">ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 15.3 GB of 15.3 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p><code>spark.yarn.executor.memoryOverhead</code>是Yarn分配给 <code>executor</code> 的堆外内存</p>
</blockquote>
<figure class="highlight lua"><table><tbody><tr><td class="code"><pre><span class="line">Finished Stage<span class="number">-2</span>_0: <span class="number">1098</span>(+<span class="number">1</span>,<span class="number">-35</span>) /<span class="number">1099</span></span><br><span class="line">Finished Stage<span class="number">-2</span>_0: <span class="number">1099</span>(<span class="number">-35</span>)/<span class="number">1099</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- success/total</span></span><br><span class="line"><span class="comment">-- a(x,y)/b</span></span><br><span class="line">hive,spark的运行日志，如果a最终等于b,就是task是成功的；</span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何获取月初月末">如何获取月初月末</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> trunc(date_add(<span class="built_in">current_date</span>,<span class="number">-1</span>),<span class="string">'MM'</span>) <span class="keyword">as</span> month_first_day    <span class="comment">-- hive  月初</span></span><br><span class="line"><span class="keyword">select</span> date_format(<span class="string">'2020-01-02 10:09:08'</span>,<span class="string">'yyyy-MM-01'</span>) <span class="comment">--  hive</span></span><br><span class="line"><span class="keyword">select</span> trunc(<span class="built_in">current_date</span>,<span class="string">'MM'</span>)  <span class="comment">-- spark-sql ,hive</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> last_day(<span class="built_in">current_timestamp</span>()) <span class="comment">-- 月末</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何处理动态分区写入">如何处理动态分区写入</h3>
<ol>
<li class="lvl-3">
<p>开启非严格模式 <code>set hive.exec.dynamic.partition.mode=nonstrict</code></p>
</li>
<li class="lvl-3">
<p>动态分区写入注意partition（date_id）的字段和select 后的字段名称保持一致</p>
</li>
<li class="lvl-3">
<p>动态分区字段放在<code>select</code> 的最后一行</p>
</li>
</ol>
<p>Memory limit exceeded: Could not allocate memory while trying to increase reservation</p>
<blockquote>
<ol>
<li class="lvl-3">
<p>最常用的方式是：重试</p>
</li>
<li class="lvl-3">
<p>降低查询并发度：减少同时执行的查询数量，这样可以为每个查询分配更多的内存</p>
</li>
<li class="lvl-3">
<p>配置准入控制：Impala 支持准入控制功能，可以限制同时执行的查询数量，避免资源竞争。 <a href="https://docs.cloudera.com/documentation/enterprise/5-8-x/topics/impala_admission.html">Impala Admission Control 文档</a></p>
</li>
<li class="lvl-3">
<p>考虑优化查询以降低内存需求（sql 本身，<code>limit</code> 等）</p>
</li>
</ol>
</blockquote>
<h3 id="json数组如何解析">json数组如何解析</h3>
<p>如何解析JSON 数组？JSON数组大概长这个样子： <code>[{},{}]</code>，以下是解析demo</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> explode(</span><br><span class="line">               split(</span><br><span class="line">                       regexp_replace(</span><br><span class="line">                               regexp_replace(                                      <span class="string">'[{"skuNo":"KU413455571546619913","propertyValue":"雾霾蓝"},{"skuNo":"KU413455571546619912","propertyValue":"北极绿"},{"skuNo":"KU413455571546619911","propertyValue":"亚麻金"}]'</span>,</span><br><span class="line">                                       <span class="string">'\\[|\\]'</span>, <span class="string">''</span>), <span class="comment">--将json数组两边的中括号去掉</span></span><br><span class="line">                               <span class="string">'\\}\\,\\{'</span>, <span class="string">'\\}\\;\\{'</span>), <span class="comment">--将json数组元素之间的逗号换成分号</span></span><br><span class="line">                       <span class="string">'\\;'</span>) <span class="comment">--以分号作为分隔符(split函数以分号作为分隔)</span></span><br><span class="line">           )</span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何求-当前日期至前7-30天-的聚合值？">如何求 <code>当前日期至前7/30天</code> 的聚合值？</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> ( <span class="comment">-- 求：同一个账号，同一个商品，在包含直播日期内的7天内，播过多少次？</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'1424128656'</span> <span class="keyword">as</span> account_id, <span class="string">'259183220'</span> <span class="keyword">as</span> goods_id, <span class="string">'2022-06-28'</span> live_date</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'1424128656'</span> <span class="keyword">as</span> account_id, <span class="string">'259183220'</span> <span class="keyword">as</span> goods_id, <span class="string">'2022-06-22'</span> live_date</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'1424128656'</span> <span class="keyword">as</span> account_id, <span class="string">'259183220'</span> <span class="keyword">as</span> goods_id, <span class="string">'2022-06-17'</span> live_date</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'1424128656'</span> <span class="keyword">as</span> account_id, <span class="string">'259183220'</span> <span class="keyword">as</span> goods_id, <span class="string">'2022-06-15'</span> live_date</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'1424128656'</span> <span class="keyword">as</span> account_id, <span class="string">'262220152'</span> <span class="keyword">as</span> goods_id, <span class="string">'2021-12-09'</span> live_date</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line">     , <span class="built_in">count</span>(<span class="operator">*</span>)</span><br><span class="line">             <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> account_id,goods_id</span><br><span class="line">                 <span class="keyword">order</span> <span class="keyword">by</span> unix_timestamp(live_date, <span class="string">'yyyy-MM-dd'</span>) <span class="keyword">desc</span></span><br><span class="line">                 <span class="keyword">range</span> <span class="keyword">between</span> <span class="number">1</span> following <span class="keyword">and</span> <span class="number">604800</span> following) <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> day_7 <span class="comment">-- 过去包含今天在内的7天内出现了多少次</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tmp1</span><br></pre></td></tr></tbody></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">account_id</th>
<th style="text-align:left">goods_id</th>
<th style="text-align:left">live_date</th>
<th style="text-align:left">day_</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1424128656</td>
<td style="text-align:left">259183220</td>
<td style="text-align:left">2022-06-28</td>
<td style="text-align:left">2</td>
</tr>
<tr>
<td style="text-align:left">1424128656</td>
<td style="text-align:left">259183220</td>
<td style="text-align:left">2022-06-22</td>
<td style="text-align:left">3</td>
</tr>
<tr>
<td style="text-align:left">1424128656</td>
<td style="text-align:left">259183220</td>
<td style="text-align:left">2022-06-17</td>
<td style="text-align:left">2</td>
</tr>
<tr>
<td style="text-align:left">1424128656</td>
<td style="text-align:left">259183220</td>
<td style="text-align:left">2022-06-15</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">1424128656</td>
<td style="text-align:left">262220152</td>
<td style="text-align:left">2021-12-09</td>
<td style="text-align:left">1</td>
</tr>
</tbody>
</table>
<h3 id="Hive，cast-as-int-into-bigint-时，数据都是0">Hive，cast( as int) into  bigint 时，数据都是0</h3>
<p>Hive中</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- table_A 中 A字段的类型为 bigint</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> table_A</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">cast</span>(a <span class="keyword">as</span> <span class="type">int</span>) <span class="keyword">as</span> A</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 最后查询 A的数据为，均为0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- solutions ： 2边类型保持一致即可</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="时间A在B时间开始后的第几个小时">时间A在B时间开始后的第几个小时</h3>
<p>确定A 时间（ <code>on_top_time</code> ）在 B时间 （<code>start_time</code>） 的第几个小时内，相当于求相对位置问题（5相对于1的位置是多少）</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> ( <span class="comment">-- </span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'2023-01-01 12:00:00'</span> <span class="keyword">as</span> on_top_time, <span class="string">'2023-01-01 11:00:00'</span> <span class="keyword">as</span> start_time</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'2023-01-01 12:02:00'</span> <span class="keyword">as</span> on_top_time, <span class="string">'2023-01-01 11:00:00'</span> <span class="keyword">as</span> start_time</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'2023-01-01 12:59:00'</span> <span class="keyword">as</span> on_top_time, <span class="string">'2023-01-01 11:00:00'</span> <span class="keyword">as</span> start_time</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'2023-01-01 16:00:00'</span> <span class="keyword">as</span> on_top_time, <span class="string">'2023-01-01 11:00:00'</span> <span class="keyword">as</span> start_time</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> on_top_time                                          <span class="keyword">as</span> on_top_time</span><br><span class="line">     , start_time                                           <span class="keyword">as</span> start_time</span><br><span class="line">     , <span class="built_in">cast</span>((unix_timestamp(on_top_time) <span class="operator">-</span></span><br><span class="line">             unix_timestamp(start_time)) <span class="operator">/</span> <span class="number">3600</span> <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="keyword">as</span> hours_id</span><br><span class="line"><span class="keyword">from</span> tmp1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="is-not-in-the-vectorization-context-column-map">is not in the vectorization context column map</h3>
<p>在<a href="https://community.cloudera.com/t5/Support-Questions/hive-vectorization-union-all-problem/td-p/183179">Hive vectorization union all problem </a> 一文中，提出了一定的解决方案，但是没有写出原因</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 在计算时不使用向量化计算</span></span><br><span class="line"><span class="keyword">set</span> hive.vectorized.execution.enabled<span class="operator">=</span><span class="literal">false</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何处理数据倾斜？">如何处理数据倾斜？</h3>
<p>当你遇到下面倾斜的问题的时候：假设A表在 <code>id = 1</code> 有大量的数据，针对这种倾斜场景，有2种处理方式：方式 🅰️</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 原有的逻辑是：</span></span><br><span class="line"><span class="keyword">select</span> A.id </span><br><span class="line"><span class="keyword">from</span> A </span><br><span class="line"><span class="keyword">join</span> B </span><br><span class="line"><span class="keyword">on</span> A.id <span class="operator">=</span> B.id </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 改进后的逻辑，第一部分，该部分查询不会有任何倾斜</span></span><br><span class="line"><span class="keyword">select</span> A.id </span><br><span class="line"><span class="keyword">from</span> A </span><br><span class="line"><span class="keyword">join</span> B </span><br><span class="line"><span class="keyword">on</span> A.id <span class="operator">=</span> B.id </span><br><span class="line"><span class="keyword">where</span> A.id <span class="operator">&lt;&gt;</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 改进后的逻辑，第二部分,B.id=1的数据量很小，我们将其放入内存关联，在spark种叫广播关联，在hive中叫做 map-join</span></span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ mapjoin(B)*/</span> A.id </span><br><span class="line"><span class="keyword">from</span> A </span><br><span class="line"><span class="keyword">join</span> B </span><br><span class="line"><span class="keyword">on</span> A.id <span class="operator">=</span> B.id </span><br><span class="line"><span class="keyword">where</span> A.id <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">and</span> B.id <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure>
<p>方式 🅱️</p>
<p>通过增加随机数 列的方式，增加关联键,举个例子：对于A表</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">id</span><br><span class="line">a </span><br><span class="line">a</span><br><span class="line">a</span><br><span class="line">a</span><br><span class="line"><span class="comment">-- 将变成</span></span><br><span class="line">id  rand_column(<span class="number">0</span><span class="operator">~</span><span class="number">2</span>) </span><br><span class="line">a               <span class="number">0</span></span><br><span class="line">a           <span class="number">1</span></span><br><span class="line">a             <span class="number">2</span></span><br><span class="line">a           <span class="number">2</span></span><br><span class="line"></span><br><span class="line">对于B表</span><br><span class="line">```<span class="keyword">sql</span></span><br><span class="line">id</span><br><span class="line">a</span><br><span class="line"><span class="comment">-- 将变成</span></span><br><span class="line">id rand_num</span><br><span class="line">a  <span class="number">0</span></span><br><span class="line">a  <span class="number">1</span></span><br><span class="line">a  <span class="number">2</span></span><br><span class="line"></span><br><span class="line">假设之前的关联关系是 A.id <span class="operator">=</span> B.id，为了处理倾斜，我们间关联关系修改为：</span><br><span class="line">`A.id <span class="operator">=</span> B.id <span class="keyword">and</span> A.rand_num <span class="operator">=</span> B.rand_num`</span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何为Hive表增加一列？">如何为Hive表增加一列？</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">`<span class="keyword">alter</span> <span class="keyword">table</span> dw.live_thin_room_order_goods_df  <span class="keyword">add</span> columns (third_party_shop_id string comment <span class="string">'三方店铺id'</span>)`</span><br></pre></td></tr></tbody></table></figure>
<h3 id="生成日期维度列">生成日期维度列</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 在hive中</span></span><br><span class="line"><span class="keyword">select</span> date_add("2023-08-01", a.pos) <span class="keyword">as</span> range_date</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">   <span class="keyword">select</span> posexplode(split(repeat("@", datediff("2023-08-31", "2023-08-01")), "@")) <span class="comment">-- 第一个日期终止日期，第二个日期起始日期，</span></span><br><span class="line">) a</span><br></pre></td></tr></tbody></table></figure>
<p>维表生成，使用 <code>date_id = '2023-08-08'</code> 的日期生成 <code>date_id = '2023-08-08'</code> 之前的日期</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> target_table <span class="keyword">partition</span> (date_id)</span><br><span class="line"><span class="keyword">select</span> id   <span class="keyword">as</span> id</span><br><span class="line">     , name <span class="keyword">as</span> name</span><br><span class="line">     , t1.date_id</span><br><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> date_add("2023-02-01", a.pos) <span class="keyword">as</span> date_id</span><br><span class="line">      <span class="keyword">from</span> (<span class="keyword">select</span> posexplode(split(repeat("@", datediff("2023-08-08", "2023-02-01")), "@")) <span class="comment">-- 第一个日期终止日期，第二个日期起始日期，</span></span><br><span class="line">      ) a</span><br><span class="line">)            t1</span><br><span class="line"><span class="keyword">cross</span> <span class="keyword">join</span> (<span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line">            <span class="keyword">from</span> target_table</span><br><span class="line">            <span class="keyword">where</span> date_id <span class="operator">=</span> <span class="string">'2023-08-09'</span></span><br><span class="line">           ) t2</span><br></pre></td></tr></tbody></table></figure>
<h3 id="如何将过程数据划分到小时">如何将过程数据划分到小时</h3>
<p>场景描述：现在有一个网页的页面，爬虫读取数据，每分钟读取一次，并且落库，需求是得到每个小时的增量数据</p>
<p align="center">
  <img src="/2023/10/01/Hive/26.png" width="100%" alt="Your image description">
   <br>
   <span style="color:gray"> info about the picture </span>
</p>
<p>以上的代码如下</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> ( <span class="comment">-- l_c : launch_consume, up_at : updated_at, s_at: start_time ， s_diff 更改时间距离开始时间多少秒</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">10</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 01:00:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">20</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 01:30:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">30</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 01:50:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">25</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 02:00:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">60</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 02:40:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">80</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 03:00:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">180</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 04:00:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">200</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 04:05:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="number">400</span> <span class="keyword">as</span> l_c, <span class="string">'2023-08-01 04:20:00'</span> <span class="keyword">as</span> up_at, <span class="string">'2023-08-01 00:30:00'</span> <span class="keyword">as</span> s_at</span><br><span class="line">)</span><br><span class="line">   , tmp2 <span class="keyword">as</span> ( <span class="comment">--</span></span><br><span class="line">    <span class="keyword">select</span> o_id                                                         <span class="keyword">as</span> o_id</span><br><span class="line">         , l_c                                                          <span class="keyword">as</span> l_c</span><br><span class="line">         , up_at                                                        <span class="keyword">as</span> up_at</span><br><span class="line">         , s_at                                                         <span class="keyword">as</span> s_at</span><br><span class="line">         , <span class="built_in">lag</span>(l_c, <span class="number">1</span>, <span class="number">0</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> o_id <span class="keyword">order</span> <span class="keyword">by</span> up_at)       <span class="keyword">as</span> l_l_c</span><br><span class="line"></span><br><span class="line">         , l_c <span class="operator">-</span> <span class="built_in">lag</span>(l_c, <span class="number">1</span>, <span class="number">0</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> o_id <span class="keyword">order</span> <span class="keyword">by</span> up_at) <span class="keyword">as</span> l_c_diff</span><br><span class="line">         , (unix_timestamp(up_at) <span class="operator">-</span> unix_timestamp(s_at))               <span class="keyword">as</span> s_diff</span><br><span class="line">         , (unix_timestamp(up_at) <span class="operator">-</span> unix_timestamp(s_at)) <span class="operator">/</span> <span class="number">3600</span>        <span class="keyword">as</span> hour_diff</span><br><span class="line">         , <span class="built_in">cast</span>((unix_timestamp(up_at) <span class="operator">-</span></span><br><span class="line">                 unix_timestamp(s_at)) <span class="operator">/</span> <span class="number">3600</span> <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> <span class="type">int</span>)               <span class="keyword">as</span> real_hours_id</span><br><span class="line">    <span class="keyword">from</span> tmp1</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tmp2</span><br></pre></td></tr></tbody></table></figure>
<h3 id="动态参数">动态参数</h3>
<p>实现效果：当某一列没有传参时，将 <code>where</code> 当前列的过滤逻辑去除</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">where</span> <span class="keyword">case</span> <span class="keyword">when</span> ${param} <span class="operator">=</span> <span class="string">'你预设的参数'</span> <span class="keyword">then</span> ture</span><br><span class="line">        <span class="keyword">else</span> platform_name <span class="operator">=</span> ${param}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="多字段-full-join">多字段 full join</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp1 <span class="keyword">as</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-01'</span> <span class="keyword">as</span> data_id, <span class="number">50</span> <span class="keyword">as</span> money</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_03'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-02'</span> <span class="keyword">as</span> data_id, <span class="number">50</span> <span class="keyword">as</span> money</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_04'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-03'</span> <span class="keyword">as</span> data_id, <span class="number">50</span> <span class="keyword">as</span> money</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">   , tmp2 <span class="keyword">as</span> ( <span class="comment">--</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_01'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-01'</span> <span class="keyword">as</span> data_id, <span class="number">60</span> <span class="keyword">as</span> money</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_02'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-02'</span> <span class="keyword">as</span> data_id, <span class="number">60</span> <span class="keyword">as</span> money</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="keyword">select</span> <span class="string">'o_05'</span> <span class="keyword">as</span> o_id, <span class="string">'2023-08-03'</span> <span class="keyword">as</span> data_id, <span class="number">60</span> <span class="keyword">as</span> money</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span> if(t1.data_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span>, t1.o_id, t2.o_id)       <span class="keyword">as</span> o_id</span><br><span class="line">     , if(t1.data_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span>, t1.data_id, t2.data_id) <span class="keyword">as</span> date_id</span><br><span class="line">     , <span class="built_in">coalesce</span>(t1.money, t2.money)                       <span class="keyword">as</span> money</span><br><span class="line"><span class="keyword">from</span> tmp1      t1</span><br><span class="line"><span class="keyword">full</span> <span class="keyword">join</span> tmp2 t2</span><br><span class="line">          <span class="keyword">on</span> t1.o_id <span class="operator">=</span> t2.o_id</span><br><span class="line">              <span class="keyword">and</span> t1.data_id <span class="operator">=</span> t2.data_id</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/10/01/Hive/28.png" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 从 select * 到 select 判断逻辑  </span>
</p>
<h2 id="第-X-部分">第 X 部分</h2>
<p>这里继续收录一下问题或者解决方案，ToDo</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>设置map的聚合为false , 在map端聚合还可能会引发内存溢出的问题，详情可查看：<a href="http://dev.bizo.com/2013/02/map-side-aggregations-in-apache-hive.html">http://dev.bizo.com/2013/02/map-side-aggregations-in-apache-hive.html</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>msyql 45 讲</title>
    <url>/2023/09/30/mysql/</url>
    <content><![CDATA[<p>MySQL实战45讲</p>
<p>🅰️ 本文内容来源于极客时间专栏：<a href="https://time.geekbang.org/column/intro/100020801">《MySQL 实战45讲》</a></p>
<p>🅱️ 本文脚注的作用是对前一段描述内容的解释说明，并且放在<strong>当前</strong>章节的最后，而不是文末。更好的阅读体验推荐typora</p>
<span id="more"></span>
<h1>1-基础架构：一条SQL是如何执行的</h1>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">select * from T where ID=10; </span><br></pre></td></tr></tbody></table></figure>
<h2 id="1-1-MySQL-基础架构">1.1-MySQL 基础架构</h2>
<p><strong>如下图所示</strong>：</p>
<p align="center">
  <img src="/2023/09/30/mysql/01.jpg" width="70%" alt="Your image description">
</p>
<p>对比下hive的架构是：解析器-编译器-优化器-执行器</p>
<h3 id="A-连接器">A-连接器</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>客户端连接连接器使用的协议是 <strong>TCP 协议</strong></p>
</li>
<li class="lvl-2">
<p>连接完成后，如果没有后续动作，这个连接就会处于<strong>sleep</strong>状态 ,也就是空闲状态（另外一个状态是 Query）</p>
</li>
<li class="lvl-2">
<p>客户端如果 <strong>wait_timeout</strong>（默认是8h）时间内没的动静，连接就会断开</p>
</li>
</ul>
<h4 id="MySQL-长短连接：">MySQL 长短连接：</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>长连接：连接成功后，一直持有这个连接，向 Server 发起请求</p>
</li>
<li class="lvl-2">
<p>短连接：执行完几次查询之后就断开连接，下次查询的时候在重新建立一个</p>
</li>
</ul>
<p>💁‍♂️ 由于连接的过程是比较复杂的，开发中需要尽量减少连接动作，也就是使用长连接</p>
<p>MySQL 在执行的过程中，临时使用的内存是管理在连接对象里面的，这些资源在连接断开的时候才释放，所以有时MySQL的内存涨的很快，而内存占用过大可能会导致被 <strong>Kill</strong>掉 ，表现为MySQL异常重启。如何避免：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>定期断开长连接</p>
</li>
<li class="lvl-2">
<p>MySQL5.7  之后的版本，在执行一个比较大的操作后，执行<code>mysql_reset_connection</code>来初始化连接(该操作不需要重连和鉴权，就恢复到刚创建完的状态)</p>
</li>
</ul>
<h3 id="B-执行器">B-执行器</h3>
<p>执行器是Server和存储引擎交互的部分，Server会调用存储引擎的接口，如对于</p>
<p><code>select * from T where ID=10;</code> ID 字段没有索引</p>
<p>1️⃣ 调用 InnoDB引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是，则将这行存在结果集中</p>
<p>2️⃣ 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行(取满足条件的第一行和满足条件的下一行这个逻辑在存储引擎中已经实现)</p>
<p>3️⃣ 执行器将上述遍历过程中所有满足条件的行，组成结果集返回给客户端</p>
<h1>2-日志系统：一条SQL更新是如何执行的</h1>
<p>MySQL中有2个重要的日志：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>redo log 重做日志 <strong>引擎层日志</strong>(InnoDB引擎特有)</p>
</li>
<li class="lvl-2">
<p>bin log 归档日志 <strong>server 层日志</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>redo log</th>
<th>bin log</th>
</tr>
</thead>
<tbody>
<tr>
<td>引擎模块，InnoDB引擎特有</td>
<td>server模块，所有引擎都可用</td>
</tr>
<tr>
<td>循环写</td>
<td>追加写</td>
</tr>
<tr>
<td>物理日志（在某个页面做了什么修改）</td>
<td>逻辑日志（语句的更改逻辑，如给<code>id=2</code>这一行的c字段加1）</td>
</tr>
</tbody>
</table>
<h2 id="2-1-redolog">2.1-redolog</h2>
<p>对于一个更新操作来说，如果每次更新都需要立刻写磁盘，则MySQL的存储引擎需要找到被更新的记录，然后更新。这个先定位再更新的机制必然有一定的成本（查找成本+IO成本<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>）。MySQL尝试使用下面的思路来提升 <strong>更新效率</strong></p>
<blockquote>
<p>WAL : Write - Ahead Logging ： 先写日志，后写磁盘</p>
</blockquote>
<p><strong>当涉及更新一条记录的时候，InnoDB引擎会将记录写到 redo log 里，并且更新内存</strong>。InnoDB引擎会在适当（系统比较空）的时候，将操作记录刷写到磁盘。在细节上：MySQL了会设置固定大小的 redo log，比如配置一组4个文件，每个文件1GB</p>
<p align="center">
  <img src="/2023/09/30/mysql/02.jpg" width="70%" alt="Your image description">
</p>
<p>有了redo log， InnoDB可以实现 crash-safe（保证在数据库发生异常重启之后，之前提交的记录不会丢失）。redo log的写入 被拆分为2个步骤 ： prepare + commit 也就是<strong>两阶段提交</strong>：</p>
<p align="center">
  <img src="/2023/09/30/mysql/03.jpg" width="60%" alt="Your image description">
</p>   
<p><strong>两阶段提交实现了 bin log 和 redo  log 的逻辑一致</strong></p>
<p>对于 <code> update T set c=c+1 where ID=2 ;</code> id 是主键  , 更新的细节如下：</p>
<p>1️⃣ 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 <code>ID=2</code> 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回</p>
<p>2️⃣ 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据</p>
<p>3️⃣ 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务</p>
<p>4️⃣ 执行器生成这个操作的 binlog，并把 binlog 写入磁盘</p>
<p>5️⃣ 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（<code>commit</code>）状态，更新完成</p>
<p>可以通过反证法的方式来证明，无论是先写redolog再写binlog，还是先写binlog再写redolog都会导致崩溃恢复后的数据不一致。而两阶段提交可以保证数据一致性</p>
<h2 id="2-2-bin-log">2.2-bin log</h2>
<p>bin log 是MySQL server层维护的一种二进制日志，记录所有的DML和DDL。作用有：</p>
<p>1️⃣ 复制： MySQL Master端开启binlog，slave 可以获得数据备份，同样可以实现数据同步（如数据采集）</p>
<p>2️⃣ 数据恢复：根据binlog来回放历史数据</p>
<p>binlog 包含两类文件</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>二进制日志索引文件(.index)：记录所有的二进制文件</p>
</li>
<li class="lvl-2">
<p>二进制日志文件(.00000*)：记录所有 DDL 和 DML 语句事件</p>
</li>
</ul>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 查看binlog的状态：查看当前二进制日志文件的状态信息，显示正在写入的二进制文件，及当前position</span></span><br><span class="line"><span class="keyword">show</span> master status;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看二进制索引文件和二进制日志文件存储位置</span></span><br><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">'%log_bin%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看binlog文件列表</span></span><br><span class="line"><span class="keyword">show</span> <span class="type">binary</span> logs;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 解析binlog 日志文件</span></span><br><span class="line"><span class="keyword">show</span> binlog events <span class="keyword">in</span>  <span class="string">'mysql-bin.000238'</span>; </span><br></pre></td></tr></tbody></table></figure>
<p><code>show master  status</code> 命令结果如下：<img src="/2023/09/30/mysql/09/30/mysql/04.jpg" class=""></p>
<blockquote>
<p>Executed_Gtid_Set : 数据发生变化，当前值就会发生变化</p>
</blockquote>
<h4 id="binlog-日志格式">binlog 日志格式</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>Statement 模式：基于 SQL 语句的复制(statement-based replication-SBR)，日志量小，会产生非确定性（比如使用不确定的函数<code>now()</code>）</p>
</li>
<li class="lvl-2">
<p>Row 模式：基于行的复制(row-based replication-RBR)，日志量大，可以保证一致性，<strong>记录了记录修改前后的样子</strong></p>
</li>
<li class="lvl-2">
<p>Mixed 模式：混合模式复制(mixed-based replication-MBR)，根据SQL语句的类型自动选择Statement或Row格式</p>
</li>
</ul>
<p><a href="https://zhuanlan.zhihu.com/p/33504555">参考1</a></p>
<p><a href="https://www.cnblogs.com/rickiyang/p/13841811.html">参考2</a></p>
<h1>3-事务隔离： 为什么你改了，我还看不见</h1>
<p>在 MySQL 中，事务支持是在引擎层实现的</p>
<h2 id="3-1-隔离性和隔离级别">3.1-隔离性和隔离级别</h2>
<p>SQL 标准的事务隔离级别包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>读未提交（read uncommitted）</p>
</li>
<li class="lvl-2">
<p>读提交（read committed）</p>
</li>
<li class="lvl-2">
<p>可重复读（repeatable read）(MySQL 默认的隔离级别)</p>
</li>
<li class="lvl-2">
<p>串行化（serializable ）</p>
</li>
</ul>
<p>结合下图，说说上面前3种隔离级别下，v1,v2,v3 的值</p>
<p align="center">
  <img src="/2023/09/30/mysql/06.jpg" width="50%" alt="Your image description">
</p>
<p>1️⃣ 读未提交：<code>V1=2,v2=2,v3=2</code></p>
<p>2️⃣ 读已提交：<code>V1=1,v2=2,v3=2</code></p>
<p>3️⃣ 可重复读：<code>V1=1,v2=1,v3=2</code></p>
<p>4️⃣ 可串行化：事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看 <code>V1=1,v2=1,v3=2</code></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 查看 MySQL当前的隔离级别设置值：</span></span><br><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">'tx_isolation'</span> </span><br><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">'transaction_isolation'</span> <span class="comment">-- mysql5.7以上version </span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="3-2-事务隔离的实现">3.2-事务隔离的实现</h2>
<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准</p>
<p>1️⃣ “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念</p>
<p>2️⃣ 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的</p>
<p>3️⃣ 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图</p>
<p>4️⃣ “串行化”隔离级别下直接用加锁的方式来避免并行访问</p>
<p>拿<strong>可重复读</strong>来说：假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录</p>
<p align="center">
  <img src="/2023/09/30/mysql/07.jpg" width="80%" alt="Your image description">
</p>
<p>当前值是4，不同时刻启动的事务会有不同的 read-view（事务视图），对于是三个视图记录的值分别不同：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>read-view A               1</p>
</li>
<li class="lvl-2">
<p>read-view B                 2</p>
</li>
<li class="lvl-2">
<p>read-view C                 4</p>
</li>
</ul>
<blockquote>
<p><strong>MVCC（ Multi-Version Concurrency Control） : 同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制</strong>。其主要的思想是在读取数据时创建数据的一份快照，并对该快照进行读取，而不是直接在原始数据上进行操作。这样做可以实现非阻塞的读操作，从而提高并发性能</p>
</blockquote>
<p>对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到</p>
<p>💁‍♂️  <strong>建议尽量不要使用长事务</strong>：</p>
<p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这会大量占用存储空间</p>
<h2 id="3-3-事务启动方式">3.3-事务启动方式</h2>
<p>事务启动的方式如下：</p>
<p>1️⃣ : 显示启动事务语句，<code>begin / start transaction</code> 开启事务，<code>commit / rollback</code> 结束事务（提交/回滚）</p>
<p>2️⃣ : <code>set autocommit = 0</code> ,将线程的自动提交off ，意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接， <strong>这会导致长事务</strong>。</p>
<p>💁‍♂️ <strong>建议：set autocommit = 1（开启自动提交）</strong>，通过显式语句的方式来启动事务。<code>commit work and chain</code>，则是提交事务并自动启动下一个事务，这种方式可以省去了再次执行 begin 语句的开销</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 你可以在 information_schema 库的 innodb_trx 这个表中查询长事务</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.innodb_trx <span class="keyword">where</span> TIME_TO_SEC(timediff(now(),trx_started))<span class="operator">&gt;</span><span class="number">60</span></span><br></pre></td></tr></tbody></table></figure>
<h1>4-深入浅出 索引 (上)</h1>
<h2 id="4-1-索引的常见模型">4.1-索引的常见模型</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>哈希表 ： 只是适合等值查询的场景，对范围查询不友好，严重依赖内存（size 瓶颈）</p>
</li>
<li class="lvl-2">
<p>有序数组： 等值查询、范围查询都很快，对数据更新（插入/删除后数据）不友好</p>
</li>
<li class="lvl-2">
<p>N叉树：在读写上有性能有点，适配磁盘的访问模式</p>
</li>
<li class="lvl-2">
<p>跳表 ：  可以说是有序的带层次的(在数据的基础上一层层加索引)链表</p>
</li>
</ul>
<p>单纯从存储上来说，LSM（log structure merge）树(日志结构合并树) 这种新的存储引擎也具备一定的优势，关于LSM这种结构可以参考《design data intensive application》 这本书的第三章节，从 追加日志，到SSTable ,到 LSM的过程</p>
<h2 id="4-2-InnoDB的索引模型">4.2-InnoDB的索引模型</h2>
<p>InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。举个例子来说：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- table schema</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> T</span><br><span class="line">(</span><br><span class="line">    id   <span class="type">int</span> <span class="keyword">primary</span> key,</span><br><span class="line">    k    <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">    name <span class="type">varchar</span>(<span class="number">16</span>),</span><br><span class="line">    index (k)</span><br><span class="line">) engine <span class="operator">=</span> InnoDB;</span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> T (id,k)</span><br><span class="line"><span class="keyword">values</span> (<span class="number">100</span>, <span class="number">1</span>),</span><br><span class="line">       (<span class="number">200</span>, <span class="number">2</span>),</span><br><span class="line">       (<span class="number">300</span>, <span class="number">3</span>),</span><br><span class="line">       (<span class="number">500</span>, <span class="number">5</span>),</span><br><span class="line">       (<span class="number">600</span>, <span class="number">6</span>)</span><br><span class="line">;</span><br></pre></td></tr></tbody></table></figure>
<p>对于上述的索引和数据，形成2颗索引树：</p>
<p align="center">
  <img src="/2023/09/30/mysql/08.jpg" width="80%" alt="Your image description">
</p>
<p>基于主键索引的查询和基于普通索引的查询的区别：</p>
<p>🅰️ <code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索 ID 这棵 B+ 树</p>
<p>🅱️ <code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为<strong>回表</strong></p>
<p>InnoDB引擎中，主键索引默认就是聚簇索引（clustered index）</p>
<h2 id="4-3-索引维护">4.3-索引维护</h2>
<p>这里我们讨论2种情况</p>
<p>1️⃣ 插入新行 <code>id = 700</code> ，只是需要在R5的后面插入新记录</p>
<p>2️⃣ 插入新行 <code>id = 400</code> ，这种情况下又分成2种情况：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>R3~R5所在的数据页没有满，需要移动R4,R5的数据，给<code>id=400</code>空出位置</p>
</li>
<li class="lvl-2">
<p>R3~R5所在的数据页满了，会发生页分裂[^10]</p>
<blockquote>
<p>页分裂会导致性能下降，同时空间利用率下降，需要申请新的数据页,将R4，R5移动到新的分页，同时如果相邻的2个页由于数据删除，数据页会进行合并</p>
</blockquote>
</li>
</ul>
<p>建表时维护自增主键的优势：</p>
<p>1️⃣ 不会发生页分裂</p>
<p>2️⃣ 自增主键一般占用的空间比较小，二级索引存储主键时，占用存储也比较小</p>
<p>💁‍♂️ 无论是删除主键索引还是创建主键索引，都会导致表重建，而重建普通索引可以达到节省空间的目的，如果你有重建主键索引的需求：<code>alter table T engine=InnoDB</code> 会触发MySQL重建表，并进行碎片处理，达到节省空间的目的</p>
<h1>5-深入浅出 索引 (下)</h1>
<p>对于上面的表插入如下数据：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> T(id,k,name)</span><br><span class="line"><span class="keyword">values</span> (<span class="number">100</span>, <span class="number">1</span>, <span class="string">'aa'</span>),</span><br><span class="line">       (<span class="number">200</span>, <span class="number">2</span>, <span class="string">'bb'</span>),</span><br><span class="line">       (<span class="number">300</span>, <span class="number">3</span>, <span class="string">'cc'</span>),</span><br><span class="line">       (<span class="number">500</span>, <span class="number">5</span>, <span class="string">'ee'</span>),</span><br><span class="line">       (<span class="number">600</span>, <span class="number">6</span>, <span class="string">'ff'</span>),</span><br><span class="line">       (<span class="number">700</span>, <span class="number">7</span>, <span class="string">'gg'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据查询</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> k <span class="keyword">between</span> <span class="number">3</span> <span class="keyword">and</span> <span class="number">5</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>问执行上述的查询，需要执行几次树的搜索操作，会扫描多少行？SQL 的执行流程如下：</p>
<p>1️⃣ 在 k 索引树上找到 k=3 的记录，取得 ID = 300；</p>
<p>2️⃣再到 ID 索引树查到 ID=300 对应的 R3；</p>
<p>3️⃣ 在 k 索引树取下一个值 k=5，取得 ID=500；</p>
<p>4️⃣ 再回到 ID 索引树查到 ID=500 对应的 R4；</p>
<p>5️⃣在 k 索引树取下一个值 k=6，不满足条件，循环结束。</p>
<p>上面的查询过程读了K索引的3条记录，（步骤1|3|5）回表了2次（步骤2|4）。回表的过程会影响数据响应时间，所以查询应该尽可能的避免回表，<strong>索引覆盖</strong>会解决这个问题</p>
<p>回表：从普通索引树搜索回到主键索引锁搜索的过程，就叫做回表</p>
<h2 id="5-1-索引覆盖">5.1-索引覆盖</h2>
<p><code>select ID from T where k between 3 and 5</code>  查询，只需要查询索引K就可以得到查询结果，不需要回表，这就是索引覆盖。其中</p>
<p>🅰️ 对引擎来说：在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项）</p>
<p>🅱️ MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2</p>
<h2 id="5-2-最左前缀原则">5.2-最左前缀原则</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `tuser` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">  `id_card` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `age` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `ismale` tinyint(<span class="number">1</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  <span class="keyword">primary</span> key (`id`),</span><br><span class="line">  key `id_card` (`id_card`),</span><br><span class="line">  key `name_age` (`name`,`age`)</span><br><span class="line">) engine<span class="operator">=</span>innodb</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p><strong>最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符</strong></p>
</blockquote>
<p>🅰️ <code>where name like '张%' </code></p>
<p>🅱️ <code>where name  = '张三'</code></p>
<p>以上两种查询都可以用到 name_age 这个索引</p>
<h2 id="5-3-索引下推">5.3-索引下推</h2>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">select * from tuser where name like '张%' and age=10 and ismale=1;</span><br></pre></td></tr></tbody></table></figure>
<p>对于上面的查询查询过程如下：</p>
<p>1️⃣ 使用普通索引(name_age)树,找到第一个满足条件的记录ID3</p>
<p>2️⃣  按照版本分</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>MySQL 5.6前 ： 只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值</p>
</li>
<li class="lvl-2">
<p>MySQL 5.6后 ：可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</p>
</li>
</ul>
<p>下图是二者的区别： 左表回表4次，右表回表2次</p>
<p align="center">
  <img src="/2023/09/30/mysql/09.jpg" width="90%" alt="Your image description">
</p>
<h1>6-全局锁和表锁 ：给表加个字段怎么有这么多阻碍？</h1>
<p>数据库锁设计的初衷是为了处理并发（多个线程访问同一个资源）问题，按照锁的范围分：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>全局锁</p>
</li>
<li class="lvl-2">
<p>表锁</p>
</li>
<li class="lvl-2">
<p>行锁</p>
</li>
</ul>
<h2 id="6-1-全局锁">6.1-全局锁</h2>
<p>MySQL通过FTWRL（Flush tables with read lock）,来加全局锁，加上全局锁之后，所有的数据更新语句和DML语句都会被阻塞。全局锁的典型使用场景是：<strong>做全库的逻辑备份</strong>。通过FTWRL的方式来添加全局锁，可以有效的突破的存储引擎带来的限制（MyISAM是不支持事务的，如果是InnoDB引擎，在RR的情况下，可以实现逻辑备份并且备份的时是支持更新的）</p>
<p><a href="https://time.geekbang.org/column/article/69862">关于使用FTWRL 还是使用 set global readonly=true</a></p>
<h2 id="6-2-表级锁">6.2-表级锁</h2>
<p>MySQL 的表级锁有2种</p>
<p>🅰️ 表锁</p>
<p>🅱️ DML锁 （Metadata Lock）</p>
<h3 id="6-2-1-表锁">6.2.1-表锁</h3>
<p>（假设是线程A）锁表的语法<code>lock table t1 read,t2 write</code> ,使用 <code>unlock talbe </code> 释放锁，对于该锁表语句：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>除了A之外的线程 对 t1 可读，对 t2 不可读写</p>
</li>
<li class="lvl-2">
<p>线程A 在执行<code>unlock tables</code>之前，只能执行读 t1, 读写 t2, 不能在访问其他表（写t1都不行，更别他其他的表了）</p>
</li>
</ul>
<h3 id="6-2-2-DML锁">6.2.2-DML锁</h3>
<p>🅰️ 对一个表做增删改查的操作的时候（会申请读锁），加DML 读锁，<strong>读锁之间不互斥</strong></p>
<p>🅱️ 对表做DML 变更的时候，加DML写锁，<strong>读写锁、写写锁之间互斥</strong></p>
<p>如下例子中，给表T增加字段，表T变的完全 不可读写</p>
<p align="center">
  <img src="/2023/09/30/mysql/10.jpg" width="80%" alt="Your image description">
</p>
<p>处理上述问题，我们首先要尽量避免长事务（session A位置 及时 commit），下面的语句在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃，<strong>阻塞会引发后面的阻塞</strong></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tbl_name nowait <span class="keyword">add</span> <span class="keyword">column</span> ...</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tbl_name wait n <span class="keyword">add</span> <span class="keyword">column</span> ... </span><br></pre></td></tr></tbody></table></figure>
<h1>7-行锁功过：怎么减少行锁对性能的影响</h1>
<p>MySQL 的行锁是在引擎层面实现的，InnoDB支持行锁，MyISAM不支持行锁</p>
<h2 id="7-1-两阶段锁">7.1-两阶段锁</h2>
<p>两阶段锁协议（Two-Phase Locking Protocol），目的是为了保证事务的隔离性，避免数据的不一致性，在两阶段锁协议中，事务的执行过程被分为两个阶段：获取锁阶段（Growing Phase）和释放锁阶段（Shrinking Phase）</p>
<p>🅰️ 获取锁阶段：在这个阶段中，事务可以获取需要的锁，但不能释放任何锁</p>
<p>🅱️ 释放锁阶段：在这个阶段中，事务可以释放锁，但不能再获取新的锁（事务结束的时候释放锁）</p>
<p>右图事务B需等A释放锁才能获得<code>id=1</code>的锁</p>
 <p align="center">
  <img src="/2023/09/30/mysql/11.jpg" width="80%" alt="Your image description">
</p>
<p>在InnoDB事务中，<strong>行锁满足两阶段锁协议</strong>。这个协议对我们的帮助就是： <strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong> 比如在一个简易的影票交易系统中，如顾客A要在影院B 购买电影票，步骤如下：</p>
<p>1️⃣ 从顾客A账户余额中扣除电影票价 update</p>
<p>2️⃣ 给影院B的账户余额增加这张电影票价 update（同时可能有另外一个顾客C在影院B购票，此处可能是最容易造成锁冲突的地方）</p>
<p>3️⃣ 记录一条交易日志 insert</p>
<p>1,2,3应在一个事务中，根据两阶段锁协议，我们的事务应该将2 安排在最后。<strong>能够最大限度的减少事务之间的锁等待</strong></p>
<p>两阶段锁协议确保了在事务处理过程中，其他事务不能访问正在处理的数据。然而，它也可能会导致死锁，因为可能会出现两个或更多的事务，互相等待对方释放锁的情况。因此，实际的数据库系统需要额外的机制来检测和解决死锁</p>
<h2 id="7-2-死锁和死锁检测">7.2-死锁和死锁检测</h2>
<p align="center">
  <img src="/2023/09/30/mysql/12.jpg" width="80%" alt="Your image description">
</p>
<p>右图例子为，行锁中的死锁（当并发系统中不同线程出现，循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁）</p>
<p>出现死锁后，有2种策略：</p>
<p>1️⃣ 进入等待状态，直到超时（<code>MySQL innodb</code> 超时时间 由<code>innodb_lock_wait_timeout</code> 指定，默认50s）, 由于超时时间阈值设置过小可能会导致假阴性（误杀，将正常的等待判断为死锁），通常不会采用此方案</p>
<p>2️⃣ 发起死锁检测（<code>innodb_deadlock_detect</code> 设置为 <code>on</code>） , 发现死锁后，主动回滚其中一个事务，让其他事务继续执行。死锁检测有额外的负担（死锁检测是$O(N^2)$的时间复杂度）</p>
<p><strong>减少死锁的主要方向，就是控制访问相同资源的并发事务量</strong>，即降低$N$值</p>
<p>为什么死锁检测是$O(N^2)$的时间复杂度</p>
<blockquote>
<p>并发更新同一行的1000个线程，整体耗费的死锁检测操作为$1000\times1000=100$万。 为什么是个乘法——并发更新此行R1的某单个线程Tx，其所作的死锁检测工作为，Tx会有查看锁持有情况，耗费1000此操作——a.查看自身持有的行锁; b.遍历其他999个线程所持有的行锁，总共为$1 + 999=1000$次。 为什么会遍历其他999个线程，而不是仅看当前持有R1行锁的这个线程就行了？—— 因为行锁排队。某线程Tm排队获取R1行锁，排在Tx前。如果Tx当前持有行锁R2，过会Tm先于Tx获持R1后，会变成——Tm持有R1，等待R2 &amp;&amp; Tx持有R2，等待R1——Tm和Tx成环死锁。 因此并发更新同一行的有N个线程，对应的死锁检测耗费代价为$O(N^2)$ ! 死锁检测不可避免，为防止死锁检测代价过高引起性能问题——想办法减少同时对同一行的更新的并发并发度。即降低N值</p>
</blockquote>
<p>为了避免死锁检测带来的性能问题，我们可以也可以从业务逻辑的角度出发去解决这个问题，比如在购买影票的例子中，我们可以将一行改为，<strong>逻辑上的多行</strong>来减少锁冲突:</p>
<blockquote>
<p>可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗,如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理</p>
</blockquote>
<h1>8-事务到底是隔离的还是不隔离的？</h1>
<p>当前讨论的隔离级别：<mark>RR</mark>，id = 1 的原始值为1，如下图顺序进行查询：</p>
<p align="center">
  <img src="/2023/09/30/mysql/13.jpg" width="80%" alt="Your image description">
</p> 
<p>🅰️ A事务查到的  k = 1</p>
<p>🅱️ B事务查到的  k = 3</p>
<h2 id="8-1-MVCC是如何工作的？">8.1-MVCC是如何工作的？</h2>
<p><strong>transaction id</strong> ： 每个事务的唯一 id号（对象是某一个动作）。InnoDB中每个事务都有一个唯一的事务ID，记为 transaction id ,该 id 是事务开启的时候向InnoDB的事务系统申请的，该 id 按照申请顺序严格递增</p>
<p><strong>row  trx_id</strong>： 记录当前数据是被哪个transaction_id 改为当前值的 （对象是某一个数据）。每次事务更新数据时，会生成新的数据版本，row trx_id 记录当前的数据版本是被哪个事务改为当前值的</p>
<p>如下图：一个记录被多个事务连续更新后的状态：</p>
<p align="center">
  <img src="/2023/09/30/mysql/14.jpg" width="80%" alt="Your image description">
</p>
<p>关于undo log : 语句更新会产生 undo log (回滚日志)，作用是可以用于回滚，同时可以提供多版本并发控制下的读（MVCC）<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p><mark>从可读性上来说</mark>：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p>
<blockquote>
<p>1️⃣ 版本未提交，不可见</p>
<p>2️⃣ 版本已提交，但是</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>在视图创建后提交的，不可见</p>
</li>
<li class="lvl-2">
<p>是在视图创建前提交的，可见</p>
</li>
</ul>
</blockquote>
<p>按照上面的规则来判断事务A，事务A的一致性视图是在事务A启动的时候生成的，此时：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>事务B的 (id=1,k=3) 还没有提交，不可见 ，属于情况 1</p>
</li>
<li class="lvl-2">
<p>事务C的(id=1,k=2) 已经提交，但是是在A的一致性视图创建<strong>后</strong>提交的，不可见，属于情况2.1</p>
</li>
<li class="lvl-2">
<p>(id=1,k=1) 已经提交，而且是在A的一致性视图创建<strong>前</strong>提交的，可见，属于情况2.2</p>
</li>
</ul>
<p>真实的物理实现，涉及到<strong>高水位</strong>（视图数组最大值+1）、<strong>低水位</strong>（视图数组的最小值）、<strong>视图数组</strong>（已经开始，但没有提交的事务id构成的数组）</p>
<p><a href="https://time.geekbang.org/column/article/70562">参考逻辑</a></p>
<h2 id="8-2-更新逻辑">8.2-更新逻辑</h2>
<p>我们再来分析一下事务B的 <code>update</code> 逻辑，按照上述的一致性读逻辑，事务B，是不能读到事务C的(1,2)的，因为事务C的是在事务B的一致性视图生成后提交的，按理说不可见；视图B在更新前去查询一次数据，返回的K=1，但是当更新的时候，必须拿到最新的值（1,2），否则事务C的更新就丢失了，因此更新数据涉及到一条规则：</p>
<blockquote>
<p><strong>当前读：更新数据是先读后写的，读只能读当前已提交的最新值，这个读 称之为当前读</strong></p>
</blockquote>
<p>因此，事务B查询结果是 (id=1,k=3)</p>
<p>此外，<strong>除了update 语句外，select 语句如果加锁，也是当前读</strong>，如我们将事务A的查询改为如下语句，也可以得到<code>k=3</code>的结果</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> lock <span class="keyword">in</span> share mode; <span class="comment">-- 读锁（S 锁，共享锁）</span></span><br><span class="line"><span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>; <span class="comment">-- 写锁（X 锁，排他锁)</span></span><br><span class="line"><span class="comment">-- update 的加锁语义和 select …for update 是一致的</span></span><br></pre></td></tr></tbody></table></figure>
<p>进一步假设事务C还没有提交，事务B就更新，事务B的更新语句会如何处理呢？</p>
<p align="center">
  <img src="/2023/09/30/mysql/15.jpg" width="60%" alt="Your image description">
  <n>
  <span style="color:gray"> info about the picture </span>
</n></p>
<p>由于<strong>2阶段锁协议</strong>（2PL）的存在，事务C’ 没有提交，即  (1,2) 这个版本的写锁 还没有释放，而事务B是当前读，必须得到当前版本(1,2)，而且必须加锁，因此阻塞了，必须等事务C’释放这个锁，才能继续它的当前读，如下图：</p>
<p align="center">
  <img src="/2023/09/30/mysql/16.jpg" width="50%" alt="Your image description">
</p>
<p>对于开头的3个事务，下面更改隔离级别为：<mark>RC</mark>：</p>
<p align="center">
  <img src="/2023/09/30/mysql/17.jpg" width="50%" alt="Your image description">
</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>事务A ： k = 2</p>
</li>
<li class="lvl-2">
<p>事务B ： k = 3</p>
</li>
</ul>
<h1>9-普通索引和唯一索引，应该怎么选？</h1>
<p>对于表T 查询，讨论在 k 上建立唯一索引还是普通索引</p>
<p align="center">
  <img src="/2023/09/30/mysql/08.jpg" width="70%" alt="Your image description">
</p>
<h2 id="9-1-查询过程">9.1-查询过程</h2>
<p>对于<code>select id from T where k=5</code>查询，该查询在索引树上的查询过程，先是从 B+ 树的 root 开始，按层搜索到叶子节点(右下角数据页，可以认为数据页内部通过二分法来定位记录)</p>
<p>1️⃣ : 对于普通索引来说，查找满足条件的第一个记录(5,500)后 ,需要查找下一个记录，直到碰到第一个不满足k=5条件的记录</p>
<p>2️⃣: 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就停止检索</p>
<p>但是两者的性能差异微乎其微的，因为<code>InnoDB</code>引擎是以数据页为单位来进行数据的读写的，当找到 k = 5 的记录的时候，它所在的数据页已经在内存中了，普通索引需要多做一次的 <strong>‘查找和判断下一条记录’</strong>  只是一次指针寻址和一次计算，如果k=5记录数据页的最后一个记录，这种情况的概率很低，计算平均性能的差异对现在的CPU来说可以忽略不计</p>
<blockquote>
<p>以数据页为单位进行数据读写：当需要读一条记录的时候，并不是将目标记录本身从磁盘中读出来，而是以页为单位，将目标记录所在的页整体读入内存，每个数据页大小默认为16KB</p>
</blockquote>
<h2 id="9-2-更新过程">9.2-更新过程</h2>
<p>当需要更新一个数据页时，MySQL会进行判断当前修改的数据页是否在内存中：</p>
<p>1️⃣ : 在内存中，直接对数据进行更新</p>
<p>2️⃣ : <code>InnoDB</code>将更新缓存在change buffer（既存储在内存中，也存储磁盘中： 可以缓存更新逻辑）中，在下次访问这个数据页的时候，将数据读入内存，执行change buffer 中和这个数据页有关的更新操作</p>
<p>访问数据页时会触发merge（将change buffer的操作应用到数据页，得到最终的结果的过程称之为 merge），系统后台线程会定期merge，在数据库正常关闭过程中，也会执行merge。无疑，使用change buffer  能够有效的提升语句的执行效率，而且由于数据页不需要读入内存占用<strong>buffer pool</strong><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>,还可以提高内存利用率</p>
<p>为什么唯一索引不能使用change buffer？是因为唯一索引需要检查当前的插入是否违反了唯一约束，这个检查需要将数据页读取到内存中，因此不能使用change buffer。只有普通索引可以使用change buffer，对于一张表需要插入新记录 (5,500)，<code>InnoDB</code>的处理流程如下：</p>
<p>1️⃣ 这个记录在内存中</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果是唯一索引：找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束</p>
</li>
<li class="lvl-2">
<p>如果是普通索引：找到3和5之间的位置，插入这个值，语句执行结束</p>
</li>
</ul>
<p>相比之下只是相差一个CPU时间</p>
<p>2️⃣ 这个记录不在内存中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>唯一索引：将数据页读入到内存，判断到没有冲突，插入这个值，语句执行结束</p>
</li>
<li class="lvl-2">
<p>普通索引：将更新记录在 change buffer，语句执行就结束了</p>
</li>
</ul>
<p>相比下，普通索引省掉了磁盘读入内存涉及随机IO的访问<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>， 使用change buffer，对于写多读少的系统很合适，如账单日志类目这种页面写完之后被访问的概率很低的系统</p>
<p>💁‍♂️ 关于唯一索引和普通索引选取的建议：</p>
<blockquote>
<p><strong>2类索引在查询上对性能没有什么影响，优先尽量使用普通索引；如果所有的更新后，都立马伴随着这个记录的查询，应该关闭change buffer</strong></p>
</blockquote>
<h4 id="对比redo-log-WAL-和-Change-buffer">对比redo log WAL 和 Change buffer</h4>
<p>在性能上<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>：redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗</p>
<h1>10-MySQL为什么有时候会选错索引？</h1>
<p>双1设置可以=&gt; 数据安全 <a href="https://www.cnblogs.com/kevingrace/p/10441086.html">参考link</a></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables  <span class="keyword">like</span> <span class="string">'innodb_flush_log_at_trx_commit'</span>; </span><br><span class="line"><span class="comment">-- innodb_flush_log_at_trx_commit = 1 每次事务提交时MySQL都会把 redo log buffer的数据写入log file，并且flush(刷到磁盘)中去;</span></span><br><span class="line"><span class="keyword">show</span> variables  <span class="keyword">like</span> <span class="string">'sync_binlog'</span>  </span><br><span class="line"><span class="comment">-- sync_binlog = 1  sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。</span></span><br></pre></td></tr></tbody></table></figure>
<p>对于某个表t</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span> auto_increment,</span><br><span class="line">  `a` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `b` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  <span class="keyword">primary</span> key (`id`),</span><br><span class="line">  key `a` (`a`),</span><br><span class="line">  key `b` (`b`)</span><br><span class="line">) engine<span class="operator">=</span>innodb;</span><br></pre></td></tr></tbody></table></figure>
<p>在数据库中，影响执行效率的因素：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>扫描行数是影响执行代价的因素之一，扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少</p>
</li>
<li class="lvl-2">
<p>否使用了 临时表</p>
</li>
<li class="lvl-2">
<p>是否排序等因素</p>
</li>
<li class="lvl-2">
<p>扫描普通索引会考虑到回表的代价</p>
</li>
</ul>
<p>索引基数（索引上不同值的个数）越大，索引的区分度越大，通过 <code>show index from table_name</code> 查看索引基数。该命令得到的是一个采样估算值<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup></p>
<p>优化器存在选错索引的可能性。对于由于索引统计信息不准确导致的问题，你可以用 <code>analyze table</code> 来解决。而对于其他优化器误判的情况</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>你可以在应用端用 force index 来强行指定索引</p>
</li>
<li class="lvl-2">
<p>也可以通过修改语句来引导优化器</p>
</li>
<li class="lvl-2">
<p>还可以通过增加或者删除索引来绕过这个问题</p>
</li>
</ul>
<h1>11-怎么给字符串字段加索引</h1>
<h2 id="11-1-前缀索引">11.1-前缀索引</h2>
<p>在原字段建立索引和建立前缀索引：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> SUser <span class="keyword">add</span> index index1(email); <span class="comment">-- 在email上建立索引</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> SUser <span class="keyword">add</span> index index2(email(<span class="number">6</span>)); <span class="comment">-- 在 email的前6个字符建立索引</span></span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/09/30/mysql/18.jpg" width="80%" alt="Your image description">
</p>
<p>前缀索引的优势：占用空间更小；前缀索引的劣势：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>无法使用覆盖索引</p>
</li>
<li class="lvl-2">
<p>由于长度定义的不好(前缀索引要选择合适的长度)，导致索引的基数变小，最终导致回表扫描变多。如何选择前缀索引的长度：</p>
</li>
</ul>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="keyword">left</span>(email, <span class="number">4</span>)) <span class="keyword">as</span> L4</span><br><span class="line">     , <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="keyword">left</span>(email, <span class="number">5</span>)) <span class="keyword">as</span> L5</span><br><span class="line">     , <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="keyword">left</span>(email, <span class="number">6</span>)) <span class="keyword">as</span> L6</span><br><span class="line">     , <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="keyword">left</span>(email, <span class="number">7</span>)) <span class="keyword">as</span> L7</span><br><span class="line"><span class="keyword">from</span> SUser;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="11-2-倒序存储-hash-字段">11.2-倒序存储 &amp; hash 字段</h2>
<p>2种方式否不支持范围查询</p>
<h1>12-为什么我的MySQL会“抖”一下？</h1>
<p>一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。表现出来，就好像MySQL抖了一下</p>
<h2 id="12-1-SQL为什么变慢？">12.1-SQL为什么变慢？</h2>
<p><strong>脏页</strong> ： 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页“</p>
<p><strong>干净页</strong>：内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</p>
<p><strong>flush</strong> : 将内存数据刷写到磁盘上使得，内存数据和磁盘的数据一致</p>
<p>什么情况下会触发数据库的 Flash？</p>
<p>1️⃣ redo log 写满，需要推进 checkpoint时</p>
<p>2️⃣ 内存不足，需要淘汰脏页时</p>
<p>3️⃣ MySQL空闲时，刷脏页</p>
<p>4️⃣ MySQL正常关闭的时候，刷写脏页</p>
<p>其中情况1出现的时候，MySQL会阻塞所有更新，从监控上看，更新数变为0 ；情况2出现的时候，MySQL使用buffer pool来管理内存，buffer pool 中的内存页存在三种状态：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>还没有使用的</p>
</li>
<li class="lvl-2">
<p>使用了而且是干净页</p>
</li>
<li class="lvl-2">
<p>使用了而且是脏页</p>
</li>
</ul>
<p>当读入的数据页没有在内存中时，必须从 buffer pool中申请新页，淘汰则会淘汰最久不使用的数据页，如果是干净页直接释放出来使用，如果是脏页，必须将脏页刷写到磁盘变成干净页才能使用，MySQL刷脏页是一个常态，但是一个查询要淘汰的脏页个数太多时，会导致查询时间加长。从而导致MySQL抖动了一下</p>
<h2 id="12-2-InnoDB刷脏页的控制策略">12.2-<code>InnoDB</code>刷脏页的控制策略</h2>
<p>InnoDB使用<code>innodb_io_capacity</code><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>，告知InnoDB所在的主机的IO能力，这样InnoDB才能最大发挥磁盘IOPS的能力。当前的这个参数是最大的写磁盘的能力，还需要$innodb_io_capacity \times R %$ <sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>InnoDB的刷盘速度实际参考2个因素：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>脏页比例</p>
</li>
<li class="lvl-2">
<p>redo log 写盘速度</p>
</li>
</ul>
<h1>13-为什么表数据删掉一半，表文件大小不变？</h1>
<p>MySQL在进行数据删除的时候，会将数据页标记为可复用，实际上并不会进行删除，会形成空洞；如果主键不是依次递增的，插入数据会导致页分裂，会导致页空洞，更新数据可以认为是先删除在插入，也会导致页分裂。如果把这些空洞去掉，就可以达到收缩表空间的目的。而重建表，就可以达到这样的目的</p>
<p>左图：MySQL5.5 | 右图： MySQL5.6</p>
<p align="center">
  <img src="/2023/09/30/mysql/19.jpg" width="100%" alt="Your image description">
</p>
<h1>14-count(*)这么慢，我该怎么办？</h1>
<p>普通索引树比主键索引树小很多<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>，对于count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上是一致的，MySQL优化器会找到最小的那棵树来遍历，<strong>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统涉及的通用法则之一</strong></p>
<p>InnoDB 表直接<code> count(*)</code> 会遍历全表，虽然结果准确，但会导致性能问题(全表扫描会导致所导致的性能问题)。可以考虑使用外部存储的方式来存储<code>count(*)</code>,比如redis。不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图</p>
<h2 id="14-1-count-的用法">14.1-count(?) 的用法</h2>
<p>至于分析性能差别的时候，你可以记住这么几个原则：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>server 层要什么就给什么；</p>
</li>
<li class="lvl-2">
<p>InnoDB 只给必要的值；</p>
</li>
<li class="lvl-2">
<p>现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做</p>
</li>
</ul>
<p>1️⃣ 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加</p>
<p>2️⃣ 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加</p>
<p>3️⃣ 对于 count(字段) 来说：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；</p>
</li>
<li class="lvl-2">
<p>如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加</p>
</li>
</ul>
<p>4️⃣ <code>count(*)</code> 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加</p>
<p>按照效率排序的话，<code>count(字段)</code>&lt;<code>count(主键 id)</code>&lt;<code>count(1)</code>≈<code>count(*)</code>，所以我建议你，尽量使用 <code>count(*)</code></p>
<h1>15-答疑文章（一）：日志和索引相关问题</h1>
<p>redo log buffer 就是一块内存，用来先存 redo 日志的。可以认为WAL和redo log 是一个东西</p>
<h1>16-<code>order by </code>是怎么工作的?</h1>
<p>对于下面的查询，MySQL是如何执行的呢？</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> city</span><br><span class="line">            ,name</span><br><span class="line">            ,age </span><br><span class="line"><span class="keyword">from</span> t </span><br><span class="line"><span class="keyword">where</span> city<span class="operator">=</span><span class="string">'杭州'</span> </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> name limit <span class="number">1000</span>  ; <span class="comment">-- id是主键， city上有索引</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="16-1-全字段排序">16.1-全字段排序</h2>
<p align="center">
  <img src="/2023/09/30/mysql/20.jpg" width="100%" alt="Your image description">
</p>
<p>1️⃣ 初始化 sort buffer<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>, 确定放入 <code>name,city,age</code> 3个字段</p>
<p>2️⃣ 根据 <code>city</code> 的索引树，找到第一个满足 <code>city = '杭州'</code> 的主键id</p>
<p>3️⃣ 回表取出整行，取<code>name,city , age</code> 3个字段的值，存入 sort buffer</p>
<p>4️⃣ 从索引city 取下一个记录的主键id</p>
<p>5️⃣ 重复3,4 直到不满足查询条件为止</p>
<p>6️⃣ 对 sort buffer 中的数据按照name 做 快排。 <code>sort_buffer_size</code>（当前参数的大小决定排序是基于内存的快排，还是开辟磁盘空间，使用归并排序）</p>
<p>7️⃣ 取前1000行返回给客户端</p>
<h2 id="16-2-row-id-排序">16.2-row_id 排序</h2>
<p align="center">
  <img src="/2023/09/30/mysql/21.jpg" width="100%" alt="Your image description">
</p>
<p>1️⃣ 初始化 sort_buffer<sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup>，确定放入两个字段，即 name 和 id</p>
<p>2️⃣ 从索引 city 找到第一个满足 <code>city='杭州’</code> 条件的主键 id，也就是图中的 ID_X（city索引数的图）</p>
<p>3️⃣ 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中</p>
<p>4️⃣ 从索引 city 取下一个记录的主键 id</p>
<p>5️⃣ 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y（city索引数的图）</p>
<p>6️⃣ 对 sort_buffer 中的数据按照字段 name 进行排序 , <code>max_length_for_sort_data</code>（设置该参数，对于太长的字段，可以实现只是取排序字段  和主键 排序，select的字段通过回表的方式获取）</p>
<p>7️⃣ 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端</p>
<h2 id="16-3-联合索引">16.3-联合索引</h2>
<p>执行如下语句：<code>alter table t add index city_user(city, name);</code></p>
<p align="center">
  <img src="/2023/09/30/mysql/22.jpg" width="100%" alt="Your image description">
</p>
<p>1️⃣ 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id</p>
<p>2️⃣ 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回</p>
<p>3️⃣ 从索引 (city,name) 取下一个记录主键 id</p>
<p>4️⃣ 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束</p>
<p>当然我们可以进一步在 <code>city name age</code> 3个字段上建立索引，然后当前的查询就会索引覆盖，更快</p>
<h1>17-如何正确的显示随机消息</h1>
<p>对于需求：从单词表中随机选出3个单词，<code>select word from words order by rand() limit 3;</code> 测试插入10W条记录，本章使用了</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>内存临时表 -&gt; 按照row id 的方式进行排序</p>
</li>
<li class="lvl-2">
<p>磁盘临时表 -&gt; 优先队列排序算法，生成一个大根堆，完成排序</p>
</li>
</ul>
<p>然后介绍了一种<em>随机1排序</em>的方法：</p>
<p>1️⃣ 取得这个表的主键 id 的最大值 M 和最小值 N</p>
<p>2️⃣ 用随机函数生成一个最大值到最小值之间的数 $X = (M-N)\times rand() + N$</p>
<p>3️⃣ 取不小于 X 的第一个 ID 的行</p>
<p>最后又介绍了一种<em>随机2排序</em>方法：</p>
<p>1️⃣ 取得整个表的行数，并记为 C</p>
<p>2️⃣ 取得 $Y = floor(C * rand())$。 floor 函数在这里的作用，就是取整数部分</p>
<p>3️⃣ 再用 limit Y,1 取得一行</p>
<h1>18-为什么我的这些SQL语句逻辑相同，性能确差异巨大？</h1>
<h2 id="18-1-条件字段函数操作">18.1-条件字段函数操作</h2>
<p>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。比如，你在 <code>t_modified</code> 、<code>id</code>上建立索引，却产生了下面的SQL写法：<code>where month(t_modified)  = 7</code> 或者 <code>where id - 1 = 100</code> 。</p>
<h2 id="18-2-隐式类型转换">18.2-隐式类型转换</h2>
<p>首先，<strong>在MySQL、PostgreSQL、 Hive 中，字符串类型和数字类型比较的时候，都是将字符串转为数字比较</strong>，验证方法如下：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="string">'10'</span> <span class="operator">&gt;</span> <span class="number">9</span>;</span><br><span class="line"><span class="comment">-- 如果是字符类型转为数字类型，返回结果应该为1或者是true</span></span><br><span class="line"><span class="comment">-- 如果是数字类型转为字符类型，返回的结果应该是0或者是false</span></span><br></pre></td></tr></tbody></table></figure>
<p>所以对于表 tradelog（tradeid 类型为字符类型），执行如下查询将无法使用索引：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tradelog <span class="keyword">where</span> tradeid<span class="operator">=</span><span class="number">110717</span>; </span><br><span class="line"><span class="comment">-- 因为实际的SQL是：</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tradelog <span class="keyword">where</span>  <span class="built_in">CAST</span>(tradid <span class="keyword">AS</span> signed <span class="type">int</span>) <span class="operator">=</span> <span class="number">110717</span>;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="18-3-隐式字符编码转换">18.3-隐式字符编码转换</h2>
<p>表trade_detail 字符集使用utf8; tradelog 表使用 utf8mb4<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>字符集，2个表在做关联Join的时候</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> tradelog l <span class="comment">-- utf8mb4</span></span><br><span class="line">   , trade_detail d <span class="comment">-- utf8</span></span><br><span class="line"><span class="keyword">where</span> d.tradeid <span class="operator">=</span> l.tradeid <span class="comment">-- l表的tradeid 有索引</span></span><br><span class="line">  <span class="keyword">and</span> l.id <span class="operator">=</span> <span class="number">2</span>;</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/09/30/mysql/23.jpg" width="100%" alt="Your image description">
</p>
<h1>19-为什么我只查一行的语句，也执行这么慢？</h1>
<p>如果MySQL数据库本身就有很大的压力，导致数据库的CPU利用率很高或者是 ioutil(IO 利用率) 很高，这种情况下所有的语句执行都可能变慢。除了这个原因之外，还有另外2种情况：</p>
<h2 id="19-1-查询长时间不返回">19.1-查询长时间不返回</h2>
<p>这种情况下，有2种原因导致，遇到这种情况，详细分析可以参考 <a href="https://time.geekbang.org/column/article/74687">链接</a></p>
<p>1️⃣  等 DML锁，通过 <code>sys.schema_table_lock_waits</code><sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>表可以定位到哪个 process id 造成了阻塞</p>
<p>2️⃣  等flush， flush table 是很快的，出现 waiting for table flush 状态的情况可能是,有一个flush tables  命令被别的语句阻塞了，然后flush table 又阻塞了我们的select 语句。</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">flush tables t <span class="keyword">with</span> read lock;  <span class="comment">-- 只关闭表t</span></span><br><span class="line">flush tables <span class="keyword">with</span> read lock;     <span class="comment">-- 关闭 MySQL里所有打开的表</span></span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/09/30/mysql/24.jpg" width="100%" alt="Your image description">
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">'%long_query_time%'</span>; <span class="comment">-- 查看慢查询阈值</span></span><br><span class="line"><span class="keyword">set</span> long_query_time <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 设置慢查询阈值</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> mysql.slow_log; <span class="comment">-- 记录慢查询可以记录到表中，也可以记录到文件中，如果记录到表中，可以按照当前的方式查询</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="19-2-查询慢">19.2-查询慢</h2>
<p>1️⃣ 全表扫描， 从SQL上来说，我们应该避免全表扫描</p>
<p>2️⃣ 时间消耗在unlog回滚上 ：</p>
<p>对于<code>select * from t where id = 1; -- 10w记录，id是主键，从查询返回来看返回结果很慢</code></p>
<p align="center">
  <img src="/2023/09/30/mysql/25.jpg" width="100%" alt="Your image description">
</p>
<p>当前读可以很快的读取到数据；而一致性读需要相当的响应时间</p>
<h1>20-幻读是什么，幻读有什么问题？</h1>
<h2 id="20-1-幻读是什么？">20.1-幻读是什么？</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `d` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  <span class="keyword">primary</span> key (`id`),</span><br><span class="line">  key `c` (`c`)</span><br><span class="line">) engine<span class="operator">=</span>innodb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>),</span><br><span class="line">(<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>),(<span class="number">15</span>,<span class="number">15</span>,<span class="number">15</span>),(<span class="number">20</span>,<span class="number">20</span>,<span class="number">20</span>),(<span class="number">25</span>,<span class="number">25</span>,<span class="number">25</span>);</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/09/30/mysql/26.jpg" width="80%" alt="Your image description">
    <br>
  <span style="color:gray"> info about the picture </span>
</p>
<p>幻读说明：当前读+新插入的 数据才会出现</p>
<p>1️⃣ 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，<strong>幻读在“当前读（读到所有已提交记录的最新值）”下才会出现</strong></p>
<p>2️⃣ 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。<strong>幻读仅专指“新插入的行”</strong></p>
<h2 id="20-2-幻读有什么问题？">20.2-幻读有什么问题？</h2>
<p>幻读会导致：</p>
<p>🅰️ 破坏语义。 如上例中 T1语义就是对所有<code>d=5</code>的行都加上锁，SessionB的 T2语句更新<code>id=0</code>后，还可以修改<code>id=0</code>的字段值，破坏了SessionA中 T1定义的对所有<code>d=5</code>的行加锁的逻辑</p>
<p>🅱️ 破坏数据一致性<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup></p>
<p align="center">
  <img src="/2023/09/30/mysql/45.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> info about the picture </span>
</p>
<p>如上的分析，都是建立在假设 <code>select * from t where d=5 for update</code> 这条语句只给 <code>d=5</code> 这一行，也就是 <code>id=5</code> 的这一行加锁”导致的，我们尝试把扫描过程中碰到的行，也都加上写锁，看看会发生什么？</p>
<p align="center">
  <img src="/2023/09/30/mysql/46.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> info about the picture </span>
</p>
<p>如上，即使把所有的记录都加上锁，还是阻止不了新插入的记录，在 T3 时刻，我们给所有行加锁的时候，<code>id=1</code> 这一行还不存在，不存在也就加不上锁</p>
<p>行锁只能锁住行，但是新插入记录的动作要更新的是记录之间的**“间隙” **， 为了解决幻读问题，MySQL引入了 <strong>间隙锁</strong>（Gap lock）</p>
<h2 id="20-3-间隙锁">20.3-间隙锁</h2>
<p align="center">
  <img src="/2023/09/30/mysql/27.png" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> info about the picture </span>
  </p>
<p><strong>跟行锁有冲突关系的是“另外一个行锁”</strong>。但是间隙锁不一样，<strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong>。间隙锁之间都不存在冲突关系</p>
<p align="center">
  <img src="/2023/09/30/mysql/28.jpg" width="80%" alt="Your image description">
</p>
<p>如果这里 <code>begin ; select  * from where c = 5 lock in share mode;</code> 此时 session B是会被阻塞的</p>
<p>间隙锁和行锁合称 next-key lock，<strong>每个 next-key lock 是前开后闭区间</strong>。也就是说，我们的表 t 初始化以后，如果用 <code>select * from t for update</code> 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是<br>
$$<br>
(-\infty,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20,25],(25,+\infty)<br>
$$<br>
下图是一个间隙锁导致的死锁例子：</p>
<p align="center">
  <img src="/2023/09/30/mysql/29.jpg" width="80%" alt="Your image description">
</p>
<ol>
<li class="lvl-3">
<p>session A 执行 <code>select … for update</code> 语句，由于 <code>id=9</code> 这一行并不存在，因此会加上间隙锁 (5,10)</p>
</li>
<li class="lvl-3">
<p>session B 执行 <code>select … for update</code> 语句，会加上间隙锁 (5,10)，间隙锁之间不会冲突，该语句执行成功</p>
</li>
<li class="lvl-3">
<p>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了</p>
</li>
</ol>
<p>可以发现间隙锁的引入，可能会导致同样的语句锁住更大的范围，解决掉了幻读，但是影响了并发度的。<strong>只有在可重复读的隔离级别下，才会有间隙锁。读提交的隔离级别下不会有间隙锁</strong>。要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row，这也是现在不少公司使用的配置组合</p>
<h1>21-为什么我只改一行的语句，锁这么多？</h1>
<p>隔离级别：<mark>RR</mark>；间隙锁和 next-key lock（行锁和间隙锁统一称为 next-key lock） 的加锁规则：</p>
<p>1️⃣ 原则 1：加锁的基本单位是 next-key lock，next-key lock 是前开后闭区间</p>
<p>2️⃣ 原则 2：查找过程中访问到的对象才会加锁</p>
<p>3️⃣ 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁</p>
<p>4️⃣优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁</p>
<p>5️⃣一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止</p>
<p>具体案例<a href="https://time.geekbang.org/column/article/75659">移步</a></p>
<p>锁退化的问题，</p>
<h1>22-MySQL有哪些“饮鸩止渴”提高性能的方法？</h1>
<p>💡 下面这些优化的方式都是有损的</p>
<h2 id="22-1-短链接风暴">22.1-短链接风暴</h2>
<p>连接过程涉及TCP+鉴权等会占用CPU资源</p>
<p>1️⃣ 第一种方法：先处理掉那些占着连接但是不工作的线程。<code>kill connection + id </code>的命令<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道</p>
<p>2️⃣ 第二种方法：减少连接过程的消耗。重启数据库，并使用–skip-grant-tables 参数启动。风险很高</p>
<h2 id="22-2-慢查询性能问题">22.2-慢查询性能问题</h2>
<p>引发性能的情况有三种：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>索引没有设计好； 可以Online DDL</p>
</li>
<li class="lvl-2">
<p>SQL 语句没写好；参见<a href="#18-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84%E8%BF%99%E4%BA%9BSQL%E8%AF%AD%E5%8F%A5%E9%80%BB%E8%BE%91%E7%9B%B8%E5%90%8C%EF%BC%8C%E6%80%A7%E8%83%BD%E7%A1%AE%E5%B7%AE%E5%BC%82%E5%B7%A8%E5%A4%A7%EF%BC%9F">章节 18</a> 为什么这些SQL语句逻辑相同，性能差异确巨大</p>
</li>
<li class="lvl-2">
<p>MySQL 选错了索引。应急方案 force index</p>
</li>
</ul>
<p>如何避免情况1和情况2？</p>
<p>1️⃣ 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志</p>
<p>2️⃣ 在测试表里插入模拟线上的数据，做一遍回归测试</p>
<p>3️⃣ 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致</p>
<p>不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障排除的时间</p>
<p><strong>查询重写</strong>：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> query_rewrite.rewrite_rules(<span class="keyword">pattern</span>, replacement, pattern_database) <span class="keyword">values</span> ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");</span><br><span class="line"></span><br><span class="line"><span class="keyword">call</span> query_rewrite.flush_rewrite_rules();</span><br></pre></td></tr></tbody></table></figure>
<h2 id="22-3-QPS-突增问题">22.3-QPS 突增问题</h2>
<p>有时由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。<a href="https://time.geekbang.org/column/article/75746">详情移步</a></p>
<h1>23-MySQL是怎么保证数据不丢的？</h1>
<p>关于数据可靠性,也即持久性的</p>
<h2 id="23-1-binlog-写入机制">23.1-binlog 写入机制</h2>
<blockquote>
<p>只要redo log 和binlog 写入了磁盘，就能确保MySQL异常重启后，数据可以恢复</p>
</blockquote>
<p align="center">
  <img src="/2023/09/30/mysql/30.jpg" width="100%" alt="Your image description">
</p>
<p>1️⃣ 事务执行过程中，先把日志写入到binlog cache ，事务提交的时候，再把binlog cache写入到binlog 文件中，并清空binlog cache</p>
<p>2️⃣ 系统给 binlog cache 分配了一片内存，每个线程会按照参数<strong>binlog_cache_size</strong> 的大小获取自己享有的cache大小，如果不够用就暂存到磁盘</p>
<p>write 和 fsync 的时机，是由参数 sync_binlog 控制的：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；</p>
</li>
<li class="lvl-2">
<p>sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；</p>
</li>
<li class="lvl-2">
<p>sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup></p>
</li>
</ul>
<p>将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，比较常见的是将其设置为 100~1000 中的某个数值</p>
<h2 id="23-2-redo-log-的写入机制">23.2-redo log 的写入机制</h2>
<p>redo log 3种存储状态</p>
<p align="center">
  <img src="/2023/09/30/mysql/31.jpg" width="100%" alt="Your image description">
</p>
<p>InnoDB 提供了 <code>innodb_flush_log_at_trx_commit</code> 参数来控制 redo log 的写入策略：</p>
<p>1️⃣ 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中</p>
<p>2️⃣ 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘</p>
<p>3️⃣ 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache</p>
<p>InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>。此外还有2种情况也会写盘：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>redo log buffer 占用的空间即将达到 <code>innodb_log_buffer_size</code> 一半的时候，后台线程会主动写盘(只是write 不 fsync)</p>
</li>
<li class="lvl-2">
<p>并行事务提交时，顺带将这个事务的redo log buffer 持久化到磁盘</p>
</li>
</ul>
<p><strong>日志逻辑序列号<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup></strong> : 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length</p>
<p><strong><a href="">组提交</a></strong></p>
<p>todo : 部分内容没有做总结</p>
<h1>24-MySQL是怎么保证主备一致的？</h1>
<p><strong>主备库的区别</strong>：备库和从库的概念是不同的，虽然二者都是只读的，但是从库对外提供服务，而备库只是为主库提供备份</p>
<h2 id="24-1-MySQL-主备的基本原理">24.1-MySQL 主备的基本原理</h2>
<p>左图为主备切换流程(M-S架构)，右图为节点 A 到 B 这条线的内部流程是什么样的</p>
<p align="center">
  <img src="/2023/09/30/mysql/32.jpg" width="100%" alt="Your image description">
</p>
<p>一个事务日志同步的完整过程是这样的：</p>
<p>1️⃣ 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量</p>
<p>2️⃣ 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接</p>
<p>3️⃣ 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B</p>
<p>4️⃣ 备库 B 拿到 binlog 后，写到本地文件，称为<strong>中转日志</strong>（relay log）</p>
<p>5️⃣ sql_thread 读取中转日志，解析出日志里的命令，并执行</p>
<h2 id="24-2-binlog-的三种格式对比">24.2-binlog 的三种格式对比</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>statement</p>
</li>
<li class="lvl-2">
<p>row</p>
</li>
<li class="lvl-2">
<p>mixed</p>
</li>
</ul>
<p>row 格式使用 mysqlbinlog工具解析出来的结果：</p>
<p align="center">
  <img src="/2023/09/30/mysql/33.jpg" width="100%" alt="Your image description">
</p>
<p>越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。其中一个直接看出来的好处：<strong>恢复数据</strong></p>
<h2 id="24-3-M-M架构">24.3-M-M架构</h2>
<p align="center">
  <img src="/2023/09/30/mysql/34.jpg" width="90%" alt="Your image description">
</p>
<h1>25-MySQL是怎么保证高可用的？</h1>
<h2 id="25-1-主备延迟">25.1-主备延迟</h2>
<p>和数据同步有关的时间点主要包括以下三个：</p>
<p>1️⃣ 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1</p>
<p>2️⃣ 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2</p>
<p>3️⃣ 备库 B 执行完成这个事务，我们把这个时刻记为 T3</p>
<p><strong>主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 $T3-T1$</strong></p>
<h2 id="25-2-造成主备延迟的原因">25.2-造成主备延迟的原因</h2>
<p>1️⃣ 备库所在机器的性能要比主库所在的机器性能差</p>
<p>2️⃣ 备库的压力大</p>
<p>3️⃣ 大事务<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup></p>
<p>4️⃣ 备库的并行复制能力</p>
<h2 id="25-3-可靠性优先策略">25.3-可靠性优先策略</h2>
<p>推荐使用该策略</p>
<h2 id="25-4-可用性优先策略">25.4-可用性优先策略</h2>
<p>介绍了异常切换的情况</p>
<h1>26-备库为什么会延迟好几个小时？</h1>
<p>主要介绍：备库并行复制能力。MySQL5.6之前备库的复制时单线程的。为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从而导致备库上 seconds_behind_master 的值越来越大</p>
<p align="center">
  <img src="/2023/09/30/mysql/35.png" width="100%" alt="Your image description">
</p>
<p>coordinator 在分发的时候，需要满足以下这两个基本要求：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中</p>
</li>
<li class="lvl-2">
<p>同一个事务不能被拆开，必须放到同一个 worker 中</p>
</li>
</ul>
<p>todo:待更</p>
<h1>27-主库出问题了，从库怎么办？</h1>
<p>大多数的互联网应用场景都是读多写少，在发展过程中很可能先会遇到读性能的问题。而在数据库层解决读性能问题，就要涉及到接下来两篇文章要讨论的架构，一主多从。（前3章是一主一备）</p>
<p>1️⃣ 基于位点的主备切换(需要注意的是这个位点并不准确)</p>
<p>2️⃣ GTID：GTID](全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识格式： <code>GTID=server_uuid:gno</code></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值</p>
</li>
<li class="lvl-2">
<p>gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup></p>
</li>
</ul>
<h1>28-读写分离有哪些坑？</h1>
<p>自定义的<a href="%E5%9C%A8%E4%BB%8E%E5%BA%93%E4%B8%8A%E4%BC%9A%E8%AF%BB%E5%88%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%80%E4%B8%AA%E8%BF%87%E6%9C%9F%E7%8A%B6%E6%80%81%E2%80%9D%E7%9A%84%E7%8E%B0%E8%B1%A1%EF%BC%8C%E5%9C%A8%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E9%87%8C%EF%BC%8C%E6%88%91%E4%BB%AC%E6%9A%82%E4%B8%94%E7%A7%B0%E4%B9%8B%E4%B8%BA%E2%80%9C%E8%BF%87%E6%9C%9F%E8%AF%BB%E2%80%9D">过期读</a> 。 涉及到的处理过期读的方案如下：</p>
<p>1️⃣ 强制走主库方案；<a href="%E6%AF%94%E5%A6%82%EF%BC%8C%E5%9C%A8%E4%B8%80%E4%B8%AA%E4%BA%A4%E6%98%93%E5%B9%B3%E5%8F%B0%E4%B8%8A%EF%BC%8C%E5%8D%96%E5%AE%B6%E5%8F%91%E5%B8%83%E5%95%86%E5%93%81%E4%BB%A5%E5%90%8E%EF%BC%8C%E9%A9%AC%E4%B8%8A%E8%A6%81%E8%BF%94%E5%9B%9E%E4%B8%BB%E9%A1%B5%E9%9D%A2%EF%BC%8C%E7%9C%8B%E5%95%86%E5%93%81%E6%98%AF%E5%90%A6%E5%8F%91%E5%B8%83%E6%88%90%E5%8A%9F%E3%80%82%E9%82%A3%E4%B9%88%EF%BC%8C%E8%BF%99%E4%B8%AA%E8%AF%B7%E6%B1%82%E9%9C%80%E8%A6%81%E6%8B%BF%E5%88%B0%E6%9C%80%E6%96%B0%E7%9A%84%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%B0%B1%E5%BF%85%E9%A1%BB%E8%B5%B0%E4%B8%BB%E5%BA%93%E3%80%82%E4%B9%B0%E5%AE%B6%E6%9D%A5%E9%80%9B%E5%95%86%E9%93%BA%E9%A1%B5%E9%9D%A2%EF%BC%8C%E5%B0%B1%E7%AE%97%E6%99%9A%E5%87%A0%E7%A7%92%E7%9C%8B%E5%88%B0%E6%9C%80%E6%96%B0%E5%8F%91%E5%B8%83%E7%9A%84%E5%95%86%E5%93%81%EF%BC%8C%E4%B9%9F%E6%98%AF%E5%8F%AF%E4%BB%A5%E6%8E%A5%E5%8F%97%E7%9A%84">对于必须要拿到最新结果的请求，强制将其发到主库上。对于可以读到旧数据的请求，才将其发到从库上</a></p>
<p>2️⃣ sleep 方案</p>
<p>3️⃣ 判断主备无延迟方案</p>
<p>4️⃣ 配合 semi-sync 方案</p>
<p>5️⃣ 等主库位点方案</p>
<p>6️⃣ 等 GTID 方案</p>
<h1>29-如何判断一个数据库是不是出问题了？</h1>
<p>主备切换有下面2种场景：</p>
<p>🅰️ 主动切换</p>
<p>🅱️ 被动切换；即由HA 系统确认主库出了问题，然后HA系统发起切换</p>
<h1>30-答疑文章（二）：用动态的观点看加锁</h1>
<h1>31-误删数据后除了跑路，还能怎么办？</h1>
<p>误删数据的事后处理办法，更重要是要做到事前预防误删数据，下面是2个建议：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>[sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错](如果你确定这个删除操作没问题的话，可以在 delete 语句中加上 where 条件，比如 where1=1)</p>
</li>
<li class="lvl-2">
<p>代码上线前，必须经过 SQL 审计</p>
</li>
</ul>
<p>防止误删表，误删库的建议：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>第一条建议是，账号分离</p>
</li>
<li class="lvl-2">
<p>第二条建议是：制定操作规范。这样做的目的，是避免写错要删除的表名(比如：在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。改表名的时候，要求给表名加固定的后缀比如加 _to_be_deleted ，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表)</p>
</li>
</ul>
<h1>32-为什么还有kill不掉的语句？</h1>
<h1>33-我查这么多数据，会不会把数据库内存打爆？</h1>
<h2 id="全表扫描对-server层的影响">全表扫描对 server层的影响</h2>
<p>假如，现在有一个 对 200G的<code>InnoDB</code>表 db1.t 进行全表扫描，并将结果集保存在客户端的需求，你可能会有下面命令：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">mysql <span class="operator">-</span>h$host <span class="operator">-</span>P$port <span class="operator">-</span>u$<span class="keyword">user</span> <span class="operator">-</span>p$pwd <span class="operator">-</span>e "select * from db1.t" <span class="operator">&gt;</span> $target_file</span><br></pre></td></tr></tbody></table></figure>
<p>那么server端 取数据和发数据的流程是下面这样的：</p>
<p>1️⃣ 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k</p>
<p>2️⃣ 重复获取行，直到 net_buffer 写满，调用网络接口发出去</p>
<p>3️⃣ 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer</p>
<p>4️⃣ 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待，直到网络栈重新可写，再继续发送</p>
<p>即：<strong>边读边发</strong>，整个流程如下：</p>
<p align="center">
  <img src="/2023/09/30/mysql/36.jpg" width="80%" alt="Your image description">
</p>
<p>执行 <code>show processlist </code> state 处于 Sending to client 状态的，就表示服务器端的网络线程写满了。<strong>对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议使用 <code>mysql_store_result</code> 这个接口，直接把查询结果保存到本地内存</strong></p>
<h2 id="全表扫描对InnoDB的影响">全表扫描对<code>InnoDB</code>的影响</h2>
<p><strong>内存利用率</strong>： buffer pool (实际是 buffer pool 中的 change buffer) 可以起到加速更新的作用，同时也具备加速查询的作用，事务提交的时候，磁盘的数据页是旧的，如果马上有一个查询来读数据页，MySQL并不需要将redo log 应用到数据页，也是直接读内存页就可以了。Buffer pool 对查询的加速效果，依赖内存命中率。<code>show engine innodb status</code>  搜索hit 即可定位到。[如何设置buffer pool的大小？](其中 buffer pool 的大小，可通过 参数 <code>innodb_buffer_pool_size</code> 设置，一般设置为物理内存的 60%~80%。)</p>
<p><code>InnoDB</code> 内存管理使用的 [LRU](Least Recently Used) 这个缓存淘汰算法，并且是基于链表实现的缓存淘汰算法</p>
<p align="center">
  <img src="/2023/09/30/mysql/37.jpg" width="100%" alt="Your image description">
</p>
<p>改进后的 LRU 算法执行流程变成了下面这样。</p>
<p>1️⃣ 图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态</p>
<p>2️⃣之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处</p>
<p>3️⃣ 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部</p>
</li>
<li class="lvl-2">
<p>如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒</p>
</li>
</ul>
<p>这个策略，就是为了处理类似全表扫描的操作量身定制的，在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率</p>
<h1>34-到底可不可以使用join？</h1>
<p>🔥 首先，对于我们的查询语句，在上线之前，explain一下是很有必要的，那么对于explain的几种类型需要了解：</p>
<p>1️⃣ <code>const </code>: 根据主键 等值匹配，唯一索引(is null除外) 等值匹配</p>
<p>2️⃣ index : 索引覆盖，无须回表</p>
<p>3️⃣ ref ： 普通索引等值匹配 ，普通索引 is null ，唯一索引 is null</p>
<p>4️⃣ range: 主键索引或者唯一索引范围查询，或者普通索引范围查询 ， 若范围在总范围中占比大，会变为 ALL</p>
<p>其中，各个类型的优劣如下：</p>
<blockquote>
<p><code>const </code>&gt; ref &gt; index &gt; range &gt; all</p>
</blockquote>
<p>t1 和 t2的表结构如下：其中t1中100条记录，t2中1000条记录</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t2` (`id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">                   `a`  <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">                   `b`  <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">                   <span class="keyword">primary</span> key (`id`),</span><br><span class="line">                   key `a` (`a`)</span><br><span class="line">) engine <span class="operator">=</span> innodb</span><br></pre></td></tr></tbody></table></figure>
<h2 id="34-1-Index-Nested-Loop-Join">34.1-Index Nested-Loop Join</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 straight_join t2 <span class="keyword">on</span> (t1.a <span class="operator">=</span> t2.a);</span><br></pre></td></tr></tbody></table></figure>
<p>当前语句的执行流程：</p>
<p>1️⃣ 从表 t1 中读入一行数据 R</p>
<p>2️⃣ 从数据行 R 中，取出 a 字段到表 t2 里去查找</p>
<p>3️⃣ 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分</p>
<p>4️⃣ 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束</p>
<p align="center">
  <img src="/2023/09/30/mysql/38.jpg" width="100%" alt="Your image description">
</p>
<p>如果t1 = N 行，t2 M 行，近似复杂度如下：<br>
$$<br>
O(N)= N + N \times2\times\log2 M<br>
$$<br>
可以发现，N 越小，整个复杂度越低。</p>
<h2 id="34-2-Simple-Nested-Loop-Join">34.2-Simple Nested-Loop Join</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 straight_join t2 <span class="keyword">on</span> (t1.a<span class="operator">=</span>t2.b);</span><br></pre></td></tr></tbody></table></figure>
<p>由于t2的字段b上没有索引，每次去t2匹配的时候，就需要做一个全表扫描。共需要扫描:$100,000 = 100\times1000$</p>
<p>MySQL并没有使用这个Simple Nested-Loop Join 算法， 而是 Block Nested-Loop Join</p>
<h2 id="34-3-Block-Nested-Loop-Join">34.3-Block Nested-Loop Join</h2>
<p>对于 查询，<code>select * from t1 straight_join t2 on (t1.a=t2.b);</code> 流程如下：</p>
<p>1️⃣ 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；</p>
<p>2️⃣ 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。</p>
<p>这个过程对 t1和 t2都做了一次全表扫描 ， 总的扫描行数是1100，对于t2的每一行都需要在内存中做判断，共需要 100,000 次比较。但是这个比较是基于内存操作，比Simple Nested-Loop Join 快很多。</p>
<p>其中 join_buffer<sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup> 如果放不下驱动表，就需要分块（block）放置，过程如下：</p>
<p>1️⃣ 扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；</p>
<p>2️⃣ 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；</p>
<p>3️⃣ 清空 join_buffer；</p>
<p>4️⃣ 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。</p>
<p align="center">
  <img src="/2023/09/30/mysql/39.jpg" width="80%" alt="Your image description">
</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>扫描行数 : N+λ * N * M （λ 取值(0,1)）</p>
</li>
<li class="lvl-2">
<p>内存判断 : N * M</p>
</li>
</ul>
<p><strong>在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表</strong>。</p>
<h1>35-join语句怎么优化？</h1>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1(id <span class="type">int</span> <span class="keyword">primary</span> key, a <span class="type">int</span>, b <span class="type">int</span>, index(a)); </span><br><span class="line"><span class="comment">-- t1 插入1000行数据，每行的a = 1001-id，即表t1中的字段a是逆序的</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t2 <span class="keyword">like</span> t1;  <span class="comment">-- 在表t2中插入 100w 数据</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="35-1-Multi-Range-Read-优化">35.1-Multi-Range Read 优化</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 <span class="keyword">where</span> a<span class="operator">&gt;=</span><span class="number">1</span> <span class="keyword">and</span> a<span class="operator">&lt;=</span><span class="number">100</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>如上查询中，会涉及到回表的过程，回表过程是一行行查询数据，还是批量的查询数据呢？主键索引是一颗B+树，每次只能根据一个主键id 查到一行数据，因此<strong>回表一定是一行行搜索主键索引的</strong>。在上面的例子中，如果随着a的值递增顺序查询的话，id的值就变成随机的了，那么就会出现随机访问磁盘，性能相对较差。</p>
<blockquote>
<p>因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>
</blockquote>
<p>以上，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：</p>
<p>1️⃣ 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ; (如果read_rnd_buffer 放置满了，就会先执行 2,3步骤)</p>
<p>2️⃣ 将 read_rnd_buffer 中的 id 进行递增排序；</p>
<p>3️⃣ 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。</p>
<p align="center">
  <img src="/2023/09/30/mysql/40.jpg" width="90%" alt="Your image description">
</p>
<p>MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>
<h2 id="35-2-Batched-Key-Access">35.2-Batched Key Access</h2>
<p>Batched Key Accesss（BKA）算法，其实是对 NLJ(Index Nested Loop Join) 算法的优化，NLJ的逻辑是，从驱动表t1，一行行取出a的值，再到被驱动表t2做join，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了，而BKA的逻辑是，将表t1的数据取出来一部分，放置到join_buffer中，然后一起传给表t2。</p>
<p align="center">
  <img src="/2023/09/30/mysql/41.jpg" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>Post Script : BKA 算法的优化要依赖于 MRR，使用BKA的前提是开启了 MRR</p>
<h1>36-为什么临时表可以重名？</h1>
<h4 id="说说临时表和内存表的区别？">说说临时表和内存表的区别？</h4>
<p>内存表，指的是使用 Memory 引擎的表，建表语法是 <code>create table … engine=memory</code>。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在</p>
<p>临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎</p>
<h4 id="临时表有哪些特性？">临时表有哪些特性？</h4>
<p align="center">
  <img src="/2023/09/30/mysql/42.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<ol>
<li class="lvl-3">
<p>建表语法是 <code>create temporary table …</code></p>
</li>
<li class="lvl-3">
<p>一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的</p>
</li>
<li class="lvl-3">
<p>临时表可以与普通表同名</p>
</li>
<li class="lvl-3">
<p>session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表</p>
</li>
<li class="lvl-3">
<p>show tables 命令不显示临时表</p>
</li>
</ol>
<p>由于临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。为什么呢？原因主要包括以下两个方面：</p>
<ol>
<li class="lvl-3">
<p>不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题</p>
</li>
<li class="lvl-3">
<p>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作</p>
</li>
</ol>
<h1>37-什么时候会使用内部临时表？</h1>
<h1>38-都说<code>InnoDB</code>好，那还要不要使用Memory引擎？</h1>
<p><code>show processlist</code> 命令的作用：可以帮助确定哪些查询可能会导致性能问题，常用语调试MySQL性能或锁问题，其输出列的含义如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>Id</strong>：连接的唯一标识符</p>
</li>
<li class="lvl-2">
<p><strong>User</strong>：建立此连接的MySQL用户</p>
</li>
<li class="lvl-2">
<p><strong>Host</strong>：用户连接到MySQL服务器的机器或IP地址</p>
</li>
<li class="lvl-2">
<p><strong>db</strong>：当前连接使用的数据库。可能为空，如果没有选择数据库</p>
</li>
<li class="lvl-2">
<p><strong>Command</strong>：执行的命令，如 Query（查询）, Sleep（休眠）, etc.</p>
</li>
<li class="lvl-2">
<p><strong>Time</strong>：命令已经运行的秒数</p>
</li>
<li class="lvl-2">
<p><strong>State</strong>：连接的当前状态，如<code>Waiting for table lock</code></p>
</li>
<li class="lvl-2">
<p><strong>Info</strong>：具体执行的查询或命令。对于非查询命令，此列可能为空</p>
</li>
</ul>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- t1表使用内存表，Memory存储引擎</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1(id <span class="type">int</span> <span class="keyword">primary</span> key, c <span class="type">int</span>) engine<span class="operator">=</span>Memory;</span><br><span class="line"><span class="comment">-- t2表使用innodb存储引擎</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t2(id <span class="type">int</span> <span class="keyword">primary</span> key, c <span class="type">int</span>) engine<span class="operator">=</span>innodb;</span><br><span class="line"><span class="comment">-- 向 t1和t2插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">4</span>),(<span class="number">5</span>,<span class="number">5</span>),(<span class="number">6</span>,<span class="number">6</span>),(<span class="number">7</span>,<span class="number">7</span>),(<span class="number">8</span>,<span class="number">8</span>),(<span class="number">9</span>,<span class="number">9</span>),(<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t2 <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">4</span>),(<span class="number">5</span>,<span class="number">5</span>),(<span class="number">6</span>,<span class="number">6</span>),(<span class="number">7</span>,<span class="number">7</span>),(<span class="number">8</span>,<span class="number">8</span>),(<span class="number">9</span>,<span class="number">9</span>),(<span class="number">0</span>,<span class="number">0</span>);</span><br></pre></td></tr></tbody></table></figure>
<h2 id="38-1-内存表的数据组织方式">38.1-内存表的数据组织方式</h2>
<p align="center">
  <img src="/2023/09/30/mysql/53.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p align="center">
  <img src="/2023/09/30/mysql/54.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>🅰️ InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）</p>
<p>🅱️ 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）</p>
<p>2种引擎比对的差异如下：</p>
<ol>
<li class="lvl-3">
<p>InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的</p>
</li>
<li class="lvl-3">
<p>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值</p>
</li>
<li class="lvl-3">
<p>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引</p>
</li>
<li class="lvl-3">
<p>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的</p>
</li>
<li class="lvl-3">
<p>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同</p>
</li>
</ol>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 最开始插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">4</span>),(<span class="number">5</span>,<span class="number">5</span>),(<span class="number">6</span>,<span class="number">6</span>),(<span class="number">7</span>,<span class="number">7</span>),(<span class="number">8</span>,<span class="number">8</span>),(<span class="number">9</span>,<span class="number">9</span>),(<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">-- 查询结果</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="comment">-- 删除id=5的数据</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> t1 <span class="keyword">where</span> id<span class="operator">=</span><span class="number">5</span>;</span><br><span class="line"><span class="comment">-- id=10填充原本id=5的位置，由于内存表中每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span>(<span class="number">10</span>,<span class="number">10</span>);</span><br><span class="line"><span class="comment">-- 查询结果</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="38-2-内存表的哈希索引和B-Tree索引">38.2-内存表的哈希索引和B-Tree索引</h2>
<p>t1 的这个主键索引是哈希索引，执行范围查询时，实际走的是全表扫描，当然我们可以使得内存表支持B-Tree索引</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 在 id 列上创建一个 B-Tree 索引</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t1 <span class="keyword">add</span> index a_btree_index <span class="keyword">using</span> btree (id);</span><br></pre></td></tr></tbody></table></figure>
<p align="center">
  <img src="/2023/09/30/mysql/55.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>内存表的优势是速度快，速度快的2点：</p>
<p>🅰️  Memory 引擎支持 hash 索引</p>
<p>🅱️  内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快</p>
<h2 id="38-3-内存表的锁">38.3-内存表的锁</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"># 让返回的数据睡一会</span><br><span class="line"><span class="keyword">select</span> sleep(<span class="number">2</span>) <span class="keyword">as</span> sleep_interval , <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure>
<p>内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作</p>
<p align="center">
  <img src="/2023/09/30/mysql/56.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<h2 id="38-4-内存表的持久性">38.4-内存表的持久性</h2>
<p align="center">
  <img src="/2023/09/30/mysql/57.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p align="center">
  <img src="/2023/09/30/mysql/58.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>基于以上的分析，我们得出结论：<strong>内存表并不适合在生产环境上作为普通数据表使用</strong></p>
<h1>39-自增主键为什么不是连续的？</h1>
<p>自增主键是递增的，但是不一定连续。主键的递增特性避免了页分裂</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span> auto_increment,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  `d` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">  <span class="keyword">primary</span> key (`id`),</span><br><span class="line">  <span class="keyword">unique</span> key `c` (`c`)</span><br><span class="line">) engine<span class="operator">=</span>innodb;</span><br></pre></td></tr></tbody></table></figure>
<p>表的结构定义存放在后缀名为<code>.frm</code> 的文件后面，在这个空表 t 里面执行 <code>insert into t values(null, 1, 1);</code> 插入一行数据，再执行 <code>show create table</code> 命令，就可以看到如下图所示的结果</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `d` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY `c` (`c`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB AUTO_INCREMENT<span class="operator">=</span><span class="number">2</span> <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4</span><br><span class="line"></span><br><span class="line"><span class="comment">-- AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2</span></span><br></pre></td></tr></tbody></table></figure>
<p>InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是：</p>
<ol>
<li class="lvl-3">
<p>在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 <code>max(id)+1</code> 作为这个表当前的自增值。�举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。</p>
</li>
<li class="lvl-3">
<p>也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值</p>
</li>
<li class="lvl-3">
<p>在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值</p>
</li>
</ol>
<h2 id="39-1-自增值修改机制">39.1-自增值修改机制</h2>
<p>在 MySQL 里面，如果字段 id 被定义为 <code>AUTO_INCREMENT</code>，在插入一行数据的时候，自增值的行为如下：</p>
<ol>
<li class="lvl-3">
<p>如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 <code>AUTO_INCREMENT</code> 值填到自增字段</p>
</li>
<li class="lvl-3">
<p>如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值，可能会更新 <code>auto_increment_increment</code> 的值，假设某次要插入的值是 X，当前的自增值是 Y</p>
<ol>
<li class="lvl-6">如果 X&lt;  Y，那么这个表的自增值不变</li>
<li class="lvl-6">如果 X≥ Y，就需要把当前自增值修改为新的自增值 （从 <code>auto_increment_offset</code> 开始，以 <code>auto_increment_increment </code>为步长(默认设置为1)，持续叠加，直到找到第一个大于 X 的值，作为新的自增值）</li>
</ol>
</li>
</ol>
<p>尝试执行以下代码，进行测试</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"># 第一次执行插入</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"># 观察 AUTO_INCREMENT 的值</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> t;</span><br><span class="line"></span><br><span class="line"># 第二次执行插入</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>);</span><br><span class="line"># 观察 AUTO_INCREMENT 的值</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> t;</span><br><span class="line"></span><br><span class="line"># 第三次执行插入</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>);</span><br><span class="line"># 观察 AUTO_INCREMENT 的值</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> t;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 会观察到 id 不在连续了</span></span><br></pre></td></tr></tbody></table></figure>
<p>当 <code>auto_increment_offset</code> 和 <code>auto_increment_increment</code> 都是 1 的时候，新的自增值生成逻辑很简单，就是：</p>
<ol>
<li class="lvl-3">
<p>如果准备插入的值 &gt;= 当前自增值，新的自增值就是“准备插入的值 +1”</p>
</li>
<li class="lvl-3">
<p>否则，自增值不变</p>
</li>
</ol>
<h2 id="39-2-自增值的修改时机">39.2-自增值的修改时机</h2>
<p>目前，假设表 t 里面已经有了 (1,1,1) 这条记录，这时我再执行一条插入数据命令<code>insert into t values(null, 1, 1); </code></p>
<p align="center">
  <img src="/2023/09/30/mysql/51.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>事务回滚也会导致逐渐不连续</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>,<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">begin</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>,<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line"><span class="keyword">rollback</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>,<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>插入的行是(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="自增值为什么不能回退">自增值为什么不能回退?</h3>
<p>假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请</p>
<ol>
<li class="lvl-3">
<p>假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行</p>
</li>
<li class="lvl-3">
<p>事务 B 正确提交了，但事务 A 出现了唯一键冲突</p>
</li>
<li class="lvl-3">
<p>如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2</p>
</li>
<li class="lvl-3">
<p>接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”</p>
</li>
</ol>
<p>而为了解决这个主键冲突，有两种方法：</p>
<p>🅰️ 每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。</p>
<p>🅱️ 把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降</p>
<p>这两个方法都会导致性能问题。造成这些麻烦的罪魁祸首，就是我们假设的这个“允许自增 id 回退”的前提导致的。因此，InnoDB 放弃了这个设计，语句执行失败也不回退自增 id。也正是因为这样，所以才只保证了自增 id 是递增的，但不保证是连续的</p>
<h2 id="39-3-自增锁的优化">39.3-自增锁的优化</h2>
<p>自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请</p>
<p>MySQL 5.1.22 版本引入了新增参数 <code>innodb_autoinc_lock_mode</code>，默认值是 1。</p>
<ol>
<li class="lvl-3">
<p>这个参数的值被设置为 0 时，语句执行结束后才释放锁</p>
</li>
<li class="lvl-3">
<p>这个参数的值被设置为 1 时：普通 <code>insert</code> 语句，自增锁在申请之后就马上释放；类似 <code>insert … select</code> 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放</p>
</li>
<li class="lvl-3">
<p>这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁</p>
</li>
</ol>
<p align="center">
  <img src="/2023/09/30/mysql/52.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>如果我们现在的 <code>binlog_format=statement</code>，binlog 会怎么记录呢？由于两个 session 是同时执行插入数据命令的，所以 binlog 里面对表 t2 的更新日志只有两种情况：要么先记 session A 的，要么先记 session B 的。但不论是哪一种，这个 binlog 拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B 这个语句执行出来，生成的结果里面，id 都是连续的。这时，从库和主库就发生了数据不一致</p>
<p>那么如何解决这个问题呢？</p>
<ol>
<li class="lvl-3">
<p>一种思路是，让原库的批量插入数据语句，固定生成连续的 id 值。所以，<strong>自增锁直到语句执行结束才释放</strong>，就是为了达到这个目的</p>
</li>
<li class="lvl-3">
<p>另一种思路是，在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是 <code>innodb_autoinc_lock_mode</code> 设置为 2，同时 <code>binlog_format</code> 设置为 row。</p>
</li>
</ol>
<p>在生产上，尤其是有 <code>insert … select </code> 和 <code>replace … select</code> 和<code> load data</code> 这种批量插入数据的场景，推荐第2种方式，这样做，既能提升并发性，又不会出现数据一致性问题</p>
<h3 id="批量插入语句，自增ID的策略">批量插入语句，自增ID的策略</h3>
<p>对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略</p>
<ol>
<li class="lvl-3">
<p>语句执行过程中，第一次申请自增 id，会分配 1 个；</p>
</li>
<li class="lvl-3">
<p>1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；</p>
</li>
<li class="lvl-3">
<p>2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；</p>
</li>
<li class="lvl-3">
<p>依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍</p>
</li>
</ol>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">3</span>,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">4</span>,<span class="number">4</span>);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t2 <span class="keyword">like</span> t;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 第一次申请了id=1，第二次申请了 id in (2,3)，第三次申请了 id in (4,5,6,7) 但是只用了id=4</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t2(c,d) <span class="keyword">select</span> c,d <span class="keyword">from</span> t; </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t2 <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">5</span>,<span class="number">5</span>);  <span class="comment">-- 实际插入的值为（8,5,5）</span></span><br></pre></td></tr></tbody></table></figure>
<p>总结一下，ID不连续的原因：</p>
<ol>
<li class="lvl-3">
<p>人为的指定了id，跳过了一些ID</p>
</li>
<li class="lvl-3">
<p>唯一键冲突</p>
</li>
<li class="lvl-3">
<p>事务回滚</p>
</li>
<li class="lvl-3">
<p>批量插入数据的时候，批量申请但是没有用完</p>
</li>
</ol>
<h1>40-insert语句的锁为什么这么多？</h1>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `d` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY `c` (`c`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">3</span>,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="keyword">null</span>, <span class="number">4</span>,<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t2 <span class="keyword">like</span> t</span><br></pre></td></tr></tbody></table></figure>
<p>数据库设置的隔离级别为RR；<code>binlog_format=statement</code></p>
<h2 id="40-1-insert-…-select-语句">40.1-insert … select 语句</h2>
<p align="center">
  <img src="/2023/09/30/mysql/59.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>执行 <code>insert … select</code> 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源</p>
<h2 id="40-2-insert循环写入">40.2-insert循环写入</h2>
<h2 id="40-3-insert-唯一键冲突">40.3-insert 唯一键冲突</h2>
<h1>41-怎么最快地复制一张表？</h1>
<p>如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用 <code>insert … select</code> 语句即可实现，在2个表中拷贝数据。当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建一个表 `db1.t`</span></span><br><span class="line"><span class="keyword">create</span> database db1;</span><br><span class="line">use db1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t(id <span class="type">int</span> <span class="keyword">primary</span> key, a <span class="type">int</span>, b <span class="type">int</span>, index(a))engine<span class="operator">=</span>innodb;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 往 `db1.t` 中 插入 1000 行数据</span></span><br><span class="line">delimiter ;;</span><br><span class="line">  <span class="keyword">create</span> <span class="keyword">procedure</span> idata()</span><br><span class="line">  <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">declare</span> i <span class="type">int</span>;</span><br><span class="line">    <span class="keyword">set</span> i<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">    while(i<span class="operator">&lt;=</span><span class="number">1000</span>)do</span><br><span class="line">      <span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(i,i,i);</span><br><span class="line">      <span class="keyword">set</span> i<span class="operator">=</span>i<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span> while;</span><br><span class="line">  <span class="keyword">end</span>;;</span><br><span class="line">delimiter ;</span><br><span class="line"><span class="keyword">call</span> idata();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建一个和 `db1.t` 相同结构的表 db2.t</span></span><br><span class="line"><span class="keyword">create</span> database db2;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 把 `db1.t` 里面 a&gt;900 的数据行导出来，插入到 db2.t 中</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> db2.t <span class="keyword">like</span> db1.t</span><br></pre></td></tr></tbody></table></figure>
<h2 id="41-1-mysqldump-方法">41.1-mysqldump 方法</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">mysqldump <span class="operator">-</span>h$host <span class="operator">-</span>P$port <span class="operator">-</span>u$<span class="keyword">user</span> <span class="comment">--add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a&gt;900" --result-file=/client_tmp/t.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- –skip-extended-insert 生成单条的 insert 语句</span></span><br></pre></td></tr></tbody></table></figure>
<p>通过 <code>mysqldump</code> 命令生成的 t.sql 文件，大概是这样的： <code>insert into t values(901,901,901),(902,902,902),(903,903,903).....</code> 。得到该文件后，，可以通过以下的命令，将 insert语句放到db2中执行</p>
<p><code>mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"</code></p>
<p><code>source</code> 并不是一条 SQL 语句，而是一个客户端命令。mysql 客户端执行这个命令的流程是这样的：</p>
<ol>
<li class="lvl-3">
<p>打开文件，默认以分号为结尾读取一条条的 SQL 语句</p>
</li>
<li class="lvl-3">
<p>将 SQL 语句发送到服务端执行</p>
</li>
</ol>
<h2 id="41-2-导出-CSV-文件">41.2-导出 CSV 文件</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> db1.t <span class="keyword">where</span> a<span class="operator">&gt;</span><span class="number">900</span> <span class="keyword">into</span> outfile <span class="string">'/server_tmp/t.csv'</span>;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li class="lvl-3">
<p>这条语句会将结果保存在服务端</p>
</li>
<li class="lvl-3">
<p>这条命令不会帮你覆盖文件，因此你需要确保 <code>/server_tmp/t.csv</code>这个文件不存在</p>
</li>
</ol>
<p>得到<code>.csv</code> 导出文件后，你就可以用<code> load data</code> 命令将数据导入到目标表 db2.t 中</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">load data infile <span class="string">'/server_tmp/t.csv'</span> <span class="keyword">into</span> <span class="keyword">table</span> db2.t;</span><br></pre></td></tr></tbody></table></figure>
<p>该语句的执行步骤如下：</p>
<ol>
<li class="lvl-3">
<p>打开文件 <code>/server_tmp/t.csv</code>，以制表符 <code>(\t)</code> 作为字段间的分隔符，以换行符<code>（\n）</code>作为记录之间的分隔符，进行数据读取；</p>
</li>
<li class="lvl-3">
<p>启动事务。判断每一行的字段数与表 db2.t 是否相同：</p>
<ol>
<li class="lvl-6">若不相同，则直接报错，事务回滚；</li>
<li class="lvl-6">若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。</li>
</ol>
</li>
<li class="lvl-3">
<p>重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务</p>
</li>
</ol>
<p>如果 <code>binlog_format=statement</code>，由于 <code>/server_tmp/t.csv</code> 文件只保存在主库所在的主机上，如果只是把这条语句原文写到 binlog 中，在备库执行的时候，备库的本地机器上并没有这个文件，就会导致主备同步停止。所以，这条语句执行的完整流程，如下</p>
<p align="center">
  <img src="/2023/09/30/mysql/49.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<p>load data 命令有两种用法：</p>
<ol>
<li class="lvl-3">
<p>不加“local”，是读取服务端的文件，这个文件必须在 <code>secure_file_priv</code> 指定的目录或子目录下</p>
</li>
<li class="lvl-3">
<p>加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 <code>load data</code> 流程</p>
</li>
<li class="lvl-3">
</li>
</ol>
<h2 id="42-3-物理拷贝方法">42.3-物理拷贝方法</h2>
<p><code>dump</code>和导出CSV方式，都是逻辑导数的方式，即：将数据从表 db1.t 中读出来，生成文本，然后再写入目标表 db2.t 中。有没有一种方式：直接把 db1.t 表的.frm 文件和.ibd 文件拷贝到 db2 目录下呢？</p>
<p>一个 InnoDB 表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有 db2.t 这个表，系统是不会识别和接受它们的，所以直接拷贝的方式不可行</p>
<p>MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能，流程如下：现在的目标是在 db1 库下，复制一个跟表 t 相同的表 r</p>
<p align="center">
  <img src="/2023/09/30/mysql/50.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<h1>42-grant之后要跟着flush privileges吗？</h1>
<h2 id="42-1-全局权限">42.1-全局权限</h2>
<h3 id="mysql-如何创建一个用户？">mysql 如何创建一个用户？</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建一个用户</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> <span class="string">'ua'</span>@<span class="string">'%'</span> identified <span class="keyword">by</span> <span class="string">'pa'</span>; <span class="comment">-- 创建1个用户为 'ua'@'%' 的用户 ， 密码是 pa</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询某个用户</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.user <span class="keyword">where</span> <span class="keyword">User</span> <span class="operator">=</span> <span class="string">'ua'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除一个用户</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> mysql.user <span class="keyword">where</span> <span class="keyword">User</span> <span class="operator">=</span> <span class="string">'ua'</span>; </span><br></pre></td></tr></tbody></table></figure>
<p>在MySQL中，用户名 (user)+ 地址 (host) 才表示一个用户，因此 <code>ua@ip1</code> 和 <code>ua@ip2</code> 代表的是两个不同的用户</p>
<h3 id="如何给MySQL中某个用户赋予最高权限？">如何给MySQL中某个用户赋予最高权限？</h3>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">'ua'</span>@<span class="string">'%'</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br></pre></td></tr></tbody></table></figure>
<p>该命令执行了2个动作：</p>
<ol>
<li class="lvl-3">
<p>磁盘上，将 <code> mysql.user</code> 表里，用户<code>’ua’@’%'</code>这一行的所有表示权限的字段的值都修改为‘Y’；</p>
</li>
<li class="lvl-3">
<p>内存里，从数组 <code>acl_users</code> 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”</p>
</li>
</ol>
<p>在 grant 命令执行完了之后，如果新的客户端使用 ua用户登录，MySQL 会为新连接维护一个线程对象，然后从 <code>acl_users</code> 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。</p>
<p><strong>对于一个已经存在的连接，它的全局权限不受 grant 命令的影响</strong></p>
<h3 id="mysql-如何回收权限？">mysql 如何回收权限？</h3>
<p>如果一个用户有所有权限，一般就不应该设置为所有 IP 地址都可以访问，应该是限制性的IP可以访问</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">from</span> <span class="string">'ua'</span>@<span class="string">'%'</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>该命令对应2个动作：</p>
<ol>
<li class="lvl-3">
<p>磁盘上，将 <code>mysql.user</code> 表里，用户<code>’ua’@’%'</code>这一行的所有表示权限的字段的值都修改为“N”</p>
</li>
<li class="lvl-3">
<p>内存里，从数组 <code>acl_users</code> 中找到这个用户对应的对象，将 access 的值修改为 0</p>
</li>
</ol>
<h2 id="42-2-DB权限">42.2-DB权限</h2>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> db1.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">'ua'</span>@<span class="string">'%'</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br></pre></td></tr></tbody></table></figure>
<p>这条 grant 命令做了如下两个动作：</p>
<ol>
<li class="lvl-3">
<p>磁盘上，往 <code>mysql.db</code> 表中插入了一行记录，所有权限位字段设置为“Y”</p>
</li>
<li class="lvl-3">
<p>内存里，增加一个对象到数组 <code>acl_dbs</code> 中，这个对象的权限位为“全 1”</p>
</li>
</ol>
<p>基于库的权限记录保存在 <code>mysql.db 表</code>中，在内存里则保存在数组 acl_dbs，查询某个用户的库权限方式如下：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.db <span class="keyword">where</span> <span class="keyword">user</span> <span class="operator">=</span> <span class="string">'ua'</span></span><br></pre></td></tr></tbody></table></figure>
<p>每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 <code>acl_dbs</code> 数组，根据 user、host 和 db 找到匹配的对象，然后根据对象的权限位来判断（并没有拷贝到连接对象的线程对象中）。<strong>grant 修改 db 权限的时候，是同时对磁盘和内存生效的</strong></p>
<p align="center">
  <img src="/2023/09/30/mysql/43.png" width="100%" alt="Your image description">
  <span style="color:gray"> info about the picture </span>
</p>
<h2 id="42-3-表列权限">42.3-表列权限</h2>
<p>表权限定义存放在表 <code>mysql.tables_priv</code> 中，列权限定义存放在表 <code>mysql.columns_priv</code> 中。这两类权限，组合起来存放在内存的 hash 结构 <code>column_priv_hash</code> 中</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> db1.t1(id <span class="type">int</span>, a <span class="type">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将`db1.t1` 表的所有权限授权给 ua 用户</span></span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> db1.t1 <span class="keyword">to</span> <span class="string">'ua'</span>@<span class="string">'%'</span> <span class="keyword">with</span> <span class="keyword">grant</span> option; </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将mydb.mytbl的查询 id列权限，和 (id,a) 的插入权限 授权给 ua 用户</span></span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>(id), <span class="keyword">INSERT</span> (id,a) <span class="keyword">ON</span> mydb.mytbl <span class="keyword">TO</span> <span class="string">'ua'</span>@<span class="string">'%'</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br></pre></td></tr></tbody></table></figure>
<p>这两个权限每次 <code>grant</code> 的时候都会修改数据表，也会同步修改内存中的 hash 结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接</p>
<h2 id="42-4-flush-privileges-的作用">42.4- <code>flush privileges</code> 的作用</h2>
<p><code>flush privileges</code> 命令会清空 <code>acl_users</code> 数组，然后从 <code>mysql.user</code> 表中读取数据重新加载，重新构造一个 <code>acl_users</code> 数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。同样地，对于 db 权限、表权限和列权限，MySQL 也做了这样的处理</p>
<p>那么 <code>flush privileges</code> 的使用场景就是：当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态</p>
<p align="center">
  <img src="/2023/09/30/mysql/44.png" width="100%" alt="Your image description">
   <br>
   <span style="color:gray"> info about the picture </span>
</p>
<h1>43-要不要使用分区表？</h1>
<p>创建一个分区表</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `t`</span><br><span class="line">(</span><br><span class="line">    `ftime` datetime <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">    `c`     <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">default</span> <span class="keyword">null</span>,</span><br><span class="line">    key (`ftime`)</span><br><span class="line">) engine <span class="operator">=</span> innodb</span><br><span class="line">  <span class="keyword">default</span> charset <span class="operator">=</span> latin1</span><br><span class="line">    <span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">range</span> (<span class="keyword">year</span>(ftime))</span><br><span class="line">        (<span class="keyword">partition</span> p_2017 <span class="keyword">values</span> less than (<span class="number">2017</span>) engine <span class="operator">=</span> innodb,</span><br><span class="line">        <span class="keyword">partition</span> p_2018 <span class="keyword">values</span> less than (<span class="number">2018</span>) engine <span class="operator">=</span> innodb,</span><br><span class="line">        <span class="keyword">partition</span> p_2019 <span class="keyword">values</span> less than (<span class="number">2019</span>) engine <span class="operator">=</span> innodb,</span><br><span class="line">        <span class="keyword">partition</span> p_others <span class="keyword">values</span> less than maxvalue engine <span class="operator">=</span> innodb</span><br><span class="line">        )</span><br><span class="line">;</span><br></pre></td></tr></tbody></table></figure>
<p>该表的创建会形成以下文件</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>t.frm 即 对于 Server 层来说，这是 1 个表</p>
</li>
<li class="lvl-2">
<p>t#P#p_2017.ibd， t#P#p_2018.ibd，t#P#p_2019.ibd，t#P#p_others.ibd，即 对于引擎层来说，这是 4 个表</p>
</li>
</ul>
<h2 id="43-1-分区表的引擎层行为">43.1-分区表的引擎层行为</h2>
<p>对于InnoDB 来说，这是 4 个表</p>
<p align="center">
  <img src="/2023/09/30/mysql/47.png" width="100%" alt="Your image description">
   <br>
   <span style="color:gray"> info about the picture </span>
</p>
<p>使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式，分区表和手工分表，分区表由 server 层来决定使用哪个分区，手工分表是由应用层代码来决定使用哪个分表</p>
<h2 id="43-2-分区策略">43.2-分区策略</h2>
<p>每当第一次访问一个分区表的时候，MySQL 需要把所有的分区都访问一遍。一个典型的报错情况是这样的：如果一个分区表的分区很多，比如超过了 1000 个，而 MySQL 启动的时候，<code>open_files_limit</code> 参数使用的是默认值 1024，那么就会在访问这个表的时候，会发生“打开表文件的个数超过了上限” 的报错</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line">Too many <span class="keyword">open</span> files </span><br></pre></td></tr></tbody></table></figure>
<p>MyISAM 分区表使用的分区策略，我们称为通用分区策略（generic partitioning），每次访问分区都由 server 层控制。通用分区策略，是 MySQL 一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。从 MySQL 5.7.9 开始，InnoDB 引擎引入了本地分区策略（native partitioning），在InnoDB引擎打开文件超过 <code>innodb_open_files</code> 这个值的时候，就会关掉一些之前打开的文件</p>
<h2 id="43-3-分区表的Server层行为">43.3-分区表的Server层行为</h2>
<p>从server 层看的话，一个分区表就只是一个表</p>
<p align="center">
  <img src="/2023/09/30/mysql/48.png" width="100%" alt="Your image description">
   <br>
   <span style="color:gray"> info about the picture </span>
</p>
<p>虽然 session B 只需要操作 p_2017 这个分区，但是由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 alter 语句被堵住。分区表，在做 DDL 的时候，影响会更大</p>
<p>分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据</p>
<h1>44-答疑文章（三）：说一说这些好问题</h1>
<h1>45-自增id用完怎么办？</h1>
<h2 id="45-1-表定义自增ID">45.1- 表定义自增ID</h2>
<p>表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。因此，当自增主键id 用完时，仍然会得到最后一个ID，再有插入就会报错主键冲突，测试如下：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t</span><br><span class="line">(</span><br><span class="line">    id <span class="type">int</span> unsigned auto_increment <span class="keyword">primary</span> key</span><br><span class="line">) auto_increment <span class="operator">=</span> <span class="number">4294967295</span>; <span class="comment">-- 2^32 - 1 = 4294967295</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span> (<span class="keyword">null</span>);</span><br><span class="line"># 成功插入一行 <span class="number">4294967295</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> t;</span><br><span class="line"><span class="comment">/* CREATE TABLE `t` (</span></span><br><span class="line"><span class="comment">  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,</span></span><br><span class="line"><span class="comment">  PRIMARY KEY (`id`)</span></span><br><span class="line"><span class="comment">) ENGINE=InnoDB AUTO_INCREMENT=4294967295;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t; <span class="comment">-- 4294967295</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span> (<span class="keyword">null</span>);</span><br><span class="line"># Duplicate entry <span class="string">'4294967295'</span> <span class="keyword">for</span> key <span class="string">'PRIMARY'</span></span><br></pre></td></tr></tbody></table></figure>
<p>$2^{32}-1 = 4294967295 $  不是一个特别大的数，对于一个频繁插入删除数据的表来说，是可能会被用完的。因此如果你的表是否有可能达到这个上限，就应该创建成 8 个字节的 <code>bigint unsigned</code></p>
<h2 id="45-2-InnoDB-系统自增-row-id">45.2- InnoDB 系统自增 row_id</h2>
<p>如果创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节（8个字节的后6个字节）的 <code>row_id</code>。InnoDB 维护了一个全局的 <code>dict_sys.row_id</code> 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 <code>dict_sys.row_id</code> 值作为要插入数据的 <code>row_id</code>，然后把 <code>dict_sys.row_id</code> 的值加 1</p>
<p>写入表的 <code>row_id</code> 是从 0 开始到 $2^{48}-1$。达到上限后，下一个值就是 0，然后继续循，<strong>如果突破这个现实，新写入的行就会覆盖原有的行</strong></p>
<h2 id="45-3-Xid">45.3- Xid</h2>
<p>Xid 在 MySQL 内部是怎么生成的呢？</p>
<p>MySQL 内部维护了一个全局变量 <code>global_query_id</code>，每次执行语句的时候将它赋值给 <code>Query_id</code>，然后自身加 1。如果当前语句是某个事务执行的第一条语句，那么 MySQL 还会同时把 <code>Query_id</code> 赋值给这个事务的 Xid</p>
<p><code>global_query_id</code> 是一个纯内存变量，重启之后就清零了。所以，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的</p>
<p>MySQL 重启不会导致同一个 binlog 里面出现两个相同的 Xid，但是如果 <code>global_query_id</code> 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景，这种情况非常极端，无需考虑</p>
<h2 id="45-4-Innodb-trx-id">45.4- Innodb trx_id</h2>
<h4 id="Xid-在-trx-id-的区别在于什么？">Xid 在  trx_id 的区别在于什么？</h4>
<p>Xid是由server层维护的。 trx_id（transaction id）是InnoDB（引擎层） 另外维护的，InnoDB 内部使用Xid，就是为了能够在 InnoDB 事务和 server 之间做关联</p>
<p>Todo: 待更新</p>
<h2 id="45-5-thread-id">45.5- thread_id</h2>
<p>线程 id 是MySQL 中最常见的一种自增 id，<code>show processlist</code> 里面的第一列，就是 <code>thread_id</code>，系统保存了一个全局变量 <code>thread_id_counter</code>，每新建一个连接，就将 <code>thread_id_counter</code> 赋值给这个新连接的线程变量，并且保证该ID在所有线程数组中是唯一的。当连接关闭时，会调用函数 <code>release_thread_id</code>，从<code>thread_ids</code>移除当前 id号</p>
<p><code>thread_id_counter</code> 定义的大小是 4 个字节，因此达到 $2^{32}-1$ 后，它就会重置为 0，然后继续增加</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span>  <span class="operator">*</span> <span class="keyword">from</span> information_schema.innodb_trx; <span class="comment">-- 查看当前的事务</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> processlist;  <span class="comment">-- 查看当前的连接</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>MySQL  的 unique key 约束  ： 允许多个null</strong></p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> `unique_key_test`</span><br><span class="line">(</span><br><span class="line">    id <span class="type">bigint</span>,</span><br><span class="line">    id_card <span class="type">varchar</span>(<span class="number">18</span>) ,</span><br><span class="line">    name <span class="type">varchar</span>(<span class="number">30</span>),</span><br><span class="line">    <span class="keyword">primary</span> key (id),</span><br><span class="line">    <span class="keyword">unique</span> key (id_card)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> unique_key_test <span class="keyword">values</span> (<span class="number">1</span>,<span class="string">'411524199710094032'</span>,<span class="string">'z3'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> unique_key_test <span class="keyword">values</span> (<span class="number">2</span>,<span class="keyword">null</span>,<span class="string">'l4'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> unique_key_test <span class="keyword">values</span> (<span class="number">3</span>,<span class="keyword">null</span>,<span class="string">'w5'</span>); <span class="comment">-- 插入成功</span></span><br></pre></td></tr></tbody></table></figure>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>IO成本就是寻址时间和上下文切换所需要的时间，最主要是用户态和内核态的上下文切换。我们知道用户态是无法直接访问磁盘等硬件上的数据的，只能通过操作系统去调内核态的接口，用内核态的线程去访问。 这里的上下文切换指的是同进程的线程上下文切换，所谓上下文就是线程运行需要的环境信息。 1️⃣ 首先，用户态线程需要一些中间计算结果保存CPU寄存器，保存CPU指令的地址到程序计数器（执行顺序保证），还要保存栈的信息等一些线程私有的信息。2️⃣  然后切换到内核态的线程执行，就需要把线程的私有信息从寄存器，程序计数器里读出来，然后执行读磁盘上的数据。读完后返回，又要把线程的信息写进寄存器和程序计数器。 3️⃣ 切换到用户态后，用户态线程又要读之前保存的线程执行的环境信息出来，恢复执行。这个过程主要是消耗时间资源 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>mvcc : <a href="https://cloud.tencent.com/developer/article/1801920">https://cloud.tencent.com/developer/article/1801920</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>changer buffer 使用的是buffer pool 的内存，默认占用50%，可以通过<code>innodb_change_buffer_max_size</code>来指定 <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>这是数据库里成本最高的 <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://time.geekbang.org/column/article/70848">https://time.geekbang.org/column/article/70848</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>InnoDB选取N个页，计算平均不同的值，然后乘以总页数 <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>建议设置为磁盘的IOPS <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>R% 如何计算，参考：<a href="https://time.geekbang.org/column/article/71806">https://time.geekbang.org/column/article/71806</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值 <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>sort_buffer 是MySQL用于排序的一个缓冲 <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>utf8mb4是支持emoji的，而utf8不支持。utf8mb4是utf8的超集 <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>select blocking_pid from sys.schema_table_lock_waits <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性 <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>select * from information_schema.innodb_trx; 查找处于事务中的id <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志 <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>一个正在执行的事务产生的redo log 也是直接写到 redo  log buffer 的，即一个未被提交的事务也有可能持久化到磁盘 <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>log sequence number，LSN <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景,另一种典型的大事务场景，就是大表 DDL <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>在 MySQL 里面我们说 transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，而 gno 是在事务提交的时候才会分配 <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p>join_buffer 是可以通过 join_buffer_size 进行设定的,默认256k) <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>设计数据密集型应用</title>
    <url>/2023/09/21/ddia/</url>
    <content><![CDATA[<p>这是第二次读DDIA，全名叫做《Design Data-Intensive Application》 直译为：设计数据密集型应用或数据密集型应用的设计；更多精彩内容，欢迎关注微信公众号：stackoverflow</p>
<p>🎈<strong>为什么分享这本书</strong>🎈</p>
<p>我相信各位一定历经过这样的场景：春节档档期一下子上映了很多场电影，一场电影要不要去看呢？对于我来说，通常都是先看一下豆瓣评分，如果高的话，就买票入场，所以为什么选择分享这本书，那就不得不说下这本书的溢美之词</p>
<span id="more"></span>
<h3 id="关于ddia的溢美之词">关于ddia的溢美之词</h3>
<p>可以看到，这本书的评价惊人的高，居然达到了 9.7分的高分，有的同学可能觉得9.7分并不是一个很高的分数，来看下面这部是个码农都知道的书《算法导论》，这本书的评分是多少呢？ 9.2分，当然这是一个很高的分数，但是ddia 比这个高度还要高 0.5分；有的同学可能还是不能很直接的get到这本书的魅力，OK，我们来和豆瓣电影评分类比一下，要知道豆瓣中电影评分最高的也就是9.7分，也就是大名鼎鼎的，我相信各位应该都看过《肖申克的救赎》</p>
<p align="center">
  <img src="/2023/09/21/ddia/01.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 设计数据密集型应用的赞美之词 </span>
</p>
<p>甚至ByteDance 这家公司将这本书写进入interview doc。<strong>所以结论来了，DDIA , 你值得拥有</strong></p>
<h3 id="关于作者">关于作者</h3>
<p><a href="https://martin.kleppmann.com/">Martin Kleppmann</a></p>
<h1>整书大纲</h1>
<p>下面是整书的一个脉络：分为<strong>3</strong>个部分12个章节</p>
<p align="center">
  <img src="/2023/09/21/ddia/37.jpg" width="80%" alt="Your image description">
  <br>
  <span style="color:gray"> 书籍结构目录 </span>
</p>
<h2 id="哪3部分">哪3部分</h2>
<h3 id="1️⃣-数据系统的基石">1️⃣ 数据系统的基石</h3>
<p>主要讲述了数据系统底层的一些概念，无论是单机上的单点数据系统，还是分布在多机器上的分布式数据系统。这个讨论的范围是 <em>单机或者多机器，区别于第二部分仅谈论多机器上的分布式系统</em></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>1：可靠性、可扩展性、可维护性</strong>  在开发一个应用的时候，必须要满足各种功能需求才能称之为有用，除了功能需求（也就是能够实现什么功能）还需要一些非功能需求，也就是通用属性，比如说可靠性<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，可扩展性<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>，可维护性<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<blockquote></blockquote>
<ul class="lvl-2">
<li class="lvl-4">
<p><strong>2：数据模型与查询语言</strong>  这个是从使用者的角度出发（⚠️<em>注意这个视角很重要</em>） 。描述数据录入数据系统的格式，已及如何将存入的数据取出来。涉及<strong>关系模型，文档模型，图模型</strong>。比如说对于关系型数据库来说，数据模型 = DML(Data Manipulation Language)；查询语言 = DQL(Data Query Language 一种声明式的查询语句) 。阐述了关系模型的各个挑战者挑战关系模型的霸主地位，最终落败的过程，数据模型发展至今关系模型依然王者</p>
</li>
</ul>
</li>
<li class="lvl-2">
<p><strong>3：存储与检索</strong>  这个是<strong>从数据系统的角度出发</strong>，描述数据系统如何存储我们录入的数据，以及在我们需要这部分数据，存储系统如何精准、快速的定位到目标数据。这里注意区分<em>2章节和3章节的角度</em></p>
</li>
<li class="lvl-2">
<p><strong>4：编码与演化</strong>  随着时间推移，数据系统由于功能的迭代，需要对初始涉及的数据模型(schema)进行更改，那么如何处理数据模型的前后兼容问题，就是这个章节要讨论的问题</p>
</li>
</ul>
<h3 id="2️⃣-分布式数据">2️⃣ 分布式数据</h3>
<p>本章主要讲述在多机器的分布式数据系统中，将会有多台机器参与数据的存储和检索，数据系统所面临挑战，包括</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>5：复制</strong> ： 同一份数据，多个拷贝/副本。这将为系统的可用性提供支撑</p>
</li>
<li class="lvl-2">
<p><strong>6：分区</strong> ： 同一份数据，分割成多块</p>
</li>
<li class="lvl-2">
<p><strong>7：事务</strong> ： 主要介绍 事务，ACID，隔离级别等内容，这部分内容是重点也是难点</p>
</li>
<li class="lvl-2">
<p><strong>8：分布式系统的麻烦</strong> ： 在极端情况下，分布式系统黑暗的诸多问题，看完这一章节，你会觉得你所处于的环境真的是太幸福了</p>
</li>
<li class="lvl-2">
<p><strong>9：一致性与共识</strong> ：分布式数据系统如何去实现一致性和达成共识，从而避免类似于 brain split  的问题，这一章节会讨论在构建容错分布式系统的时候使用到的 算法和协议(比如Raft、Paxos、ZAB)</p>
</li>
</ul>
<h3 id="3️⃣-派生数据">3️⃣ 派生数据</h3>
<p>第一/二部分系统的考量了分布式数据库的方方面面，真实世界的大型应用程序经常需要以多种方式访问和处理数据，没有一个数据库可以同时满足所有这些不同的需求。因此应用程序通常组合使用多种组件：数据存储，索引，缓存，分析系统，等等，并实现在这些组件中移动数据的机制</p>
<p>该书的最后一部分，研究将多个不同数据系统（可能有着不同数据模型，并针对不同的访问模式进行优化）集成为一个协调一致的应用架构时，会遇到的问题</p>
<p>主要讨论衍生(派生)数据：所谓<em>衍生数据</em> 是以输入数据输出新的数据，输出是衍生数据（derived data）的一种形式 ，流处理和批处理都会产生衍生数据</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>10：批处理</strong>  ： 有界数据的处理</p>
</li>
<li class="lvl-2">
<p><strong>11：流处理</strong>  ： 无界数据的处理</p>
</li>
<li class="lvl-2">
<p><strong>12：数据系统的未来</strong> 🤣</p>
</li>
</ul>
<p>🎈<strong>以上呢</strong>🎈，就是整本书的一个简短的概括，下面的内容就是我基于书中的内容做的一些总结，已及自己的一些启发</p>
<h2 id="计算密集vs数据密集">计算密集vs数据密集</h2>
<p>下图是应用程序的简要分类：</p>
<p align="center">
  <img src="/2023/09/21/ddia/15.jpg" width="80%" alt="Your image description">
  <br>
  <span style="color:gray"> 数据密集型应用和计算密集型应用的区别 </span>
</p>
<p>🅰️ 首先是计算密集型应用，这类应用的瓶颈是算力，比如进行气象预测，对于这类应用我们处理的方式就是不断的提升计算机的算力，比如增加CPU的核数，增加内存等</p>
<p>🅱️ 再有就是数据密集型，这类应用的瓶颈是：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>数据量，Volume</p>
</li>
<li class="lvl-2">
<p>数据的复杂性，Variety</p>
</li>
<li class="lvl-2">
<p>数据的变更速度，Velocity</p>
</li>
</ul>
<p>对于数据密集型应用，我们通常会使用标准的组件来处理：</p>
<p>1️⃣ 存储数据，以便自己或其他应用程序之后能再次找到(数据库 database)</p>
<p>2️⃣ 记住开销昂贵操作的结果，加快读取速度(缓存 cache)</p>
<p>3️⃣ 允许用户按关键字搜索数据，或以各种方式对数据进行过滤(搜索索引 search indexes)</p>
<p>4️⃣ 向其他进程发送消息，进行异步处理(流处理 stream processing)</p>
<p>5️⃣ 定期处理累积的大批量数据(批处理 batch processing)</p>
<h3 id="如何描述负载？">如何描述负载？</h3>
<p>可以使用<strong>负载参数（load parameters）</strong> 的数字来描述负载。参数可能是</p>
<ol>
<li class="lvl-3">
<p>每秒向Web服务器发出的请求</p>
</li>
<li class="lvl-3">
<p>数据库中的读写比率</p>
</li>
<li class="lvl-3">
<p>聊天室中同时活跃的用户数量</p>
</li>
<li class="lvl-3">
<p>缓存命中率</p>
</li>
</ol>
<p>除此之外，需要关注<strong>平均情况</strong>或者<strong>峰值情况</strong>。有写负载和读负载，如果写负载远远低于读负载，此时我们可以让写入时做更多的工作，便于我们在读取的时候做更少的工作</p>
<p>推特在推文写入和推文读取时，使用了两种不同的策略</p>
<h3 id="如何描述性能？">如何描述性能？</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>批处理系统，每秒可以处理的记录数量，即吞吐量（throughput），或者在特定规模数据集上运行作业的总时间</p>
</li>
<li class="lvl-2">
<p>在线系统，通常更重要的是服务的<strong>响应时间（response time）</strong>，即客户端发送请求到接收响应之间的时间</p>
</li>
</ul>
<p>一般而言，将响应时间视为一个可以测量的数值<strong>分布（distribution）</strong>，而不是单个数值，比如<strong>100次请求响应时间的均值与百分位数</strong>。第95、99和99.9百分位点（缩写为p95，p99和p999），如果第95百分位点响应时间是1.5秒，则意味着100个请求中的95个响应时间快于1.5秒，而100个请求中的5个响应时间超过1.5秒</p>
<p>百分位点通常用于<strong>服务级别目标（SLO, service level objectives）<strong>和</strong>服务级别协议（SLA, service level agreements）</strong>，即定义服务预期性能和可用性的合同，如果没达到服务目标，客户可以不付款</p>
<p>什么是头部阻塞？</p>
<blockquote>
<p>由于服务器只能并行处理少量的事务（如受其CPU核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 <strong>头部阻塞（head-of-line blocking）</strong>，也叫做<strong>排队延迟（queueing delay）</strong>，通常占了高百分位点处响应时间的很大一部分</p>
<p><strong>当一个请求需要多个后端请求时，单个后端慢请求就会拖慢整个终端用户的请求</strong>，效果称为尾部延迟放大</p>
</blockquote>
<p>负载参数和性能参数是讨论可扩展性的前提，可扩展性即为当负载参数增加时，如何保持良好的性能？</p>
<h3 id="什么是弹性的？">什么是弹性的？</h3>
<p>如果说系统是 <strong>弹性（elastic）</strong> 的，这意味着可以在检测到负载增加时自动增加计算资源，而其他系统则是手动扩展（人工分析容量并决定向系统添加更多的机器）</p>
<h1>第2章节-数据模型与查询语言</h1>
<h2 id="文档模型和关系模型的优劣势？">文档模型和关系模型的优劣势？</h2>
<p>文档模型如JSON的优势在于结构灵活，你可以将任意的键和值添加到文档中，而在关系模型中你必须提前预设这样的字段或者进行 <code>alter table</code> 操作，文档模型在连接上的劣势，导致数据如果有多份，必须要存储多次，有较高的数据不一致风险。如果每次读取文档的全部或者大部分内容，查询局部性会有很大优势，而关系模型将数据分割多块的行为，不得不进行连接</p>
<p>关系模型一般是规范化的，能够保证数据的一致性（外键），但是其中的结构变化，是一个较耗时的操作如果表很大的话，执行 <code>alter table  &amp; update </code> 需要很久，此时会有锁表行为</p>
<h2 id="声明式查询vs命令式查询">声明式查询vs命令式查询</h2>
<p>声明式查询告诉存储引擎：我需要<code>Sharks</code>类数据，而命令式查询给出找到A类数据的方法，存储引擎按照这个方法执行即可,而众多编程语言就是命令式的</p>
<figure class="highlight java"><table><tbody><tr><td class="code"><pre><span class="line">function <span class="title function_">getSharks</span><span class="params">()</span> {</span><br><span class="line">    <span class="type">var</span> <span class="variable">sharks</span> <span class="operator">=</span> [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">var</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; animals.length; i++) {</span><br><span class="line">        <span class="keyword">if</span> (animals[i].family === <span class="string">"Sharks"</span>) {</span><br><span class="line">            sharks.push(animals[i]);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> sharks;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>SQL是一种声明式的查询语句，声明式查询不提供方法，仅指定结果的模式，接收声明的数据库可以自行选择高校的方法</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> animals <span class="keyword">WHERE</span> family <span class="operator">=</span><span class="string">'Sharks'</span>;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="MapReduce是什么">MapReduce是什么</h2>
<p>MapReduce是一个由Google推广的编程模型，它基于<code>map</code>（也称为<code>collect</code>）和<code>reduce</code>（也称为<code>fold</code>或<code>inject</code>）函数。它既不是一个声明式的查询语言，也不是一个完全命令式的查询API，而是处于两者之间：查询的逻辑用代码片断来表示，这些代码片段会被处理框架重复性调用</p>
<h2 id="图">图</h2>
<p>如果你的应用程序大多数的关系是一对多关系（树状结构化数据），或者大多数记录之间不存在关系，那么使用文档模型是合适的。关系模型可以处理多对多关系的简单情况，但是随着数据之间的连接变得更加复杂，将数据建模为图形显得更加自然</p>
<p>一个图由两种对象组成：<strong>顶点（vertices）</strong> 和 <strong>边（edges）</strong>，典型的例子包括：社交图谱,网络图谱,公路或铁路网络</p>
<h3 id="A-什么是属性图模型？">A-什么是属性图模型？</h3>
<p>在属性图模型中，包含顶点和边，在属性图模型中，顶点和边分别包括</p>
<table>
<thead>
<tr>
<th>顶点（vertex）</th>
<th>边（edge）</th>
</tr>
</thead>
<tbody>
<tr>
<td>唯一的标识符</td>
<td>唯一的标识符</td>
</tr>
<tr>
<td>一组 <strong>出边（outgoing edges）</strong></td>
<td>边的起点（tail vertex）</td>
</tr>
<tr>
<td>一组 <strong>入边（ingoing edges）</strong></td>
<td>边的终点（head vertex）</td>
</tr>
<tr>
<td></td>
<td>描述两个顶点之间关系类型的标签</td>
</tr>
<tr>
<td>一组属性（键值对）</td>
<td>一组属性（键值对）</td>
</tr>
</tbody>
</table>
<p>可以将图存储看作由两个关系表组成：一个存储顶点，另一个存储边</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> vertices (</span><br><span class="line">  vertex_id  <span class="type">INTEGER</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">  properties JSON</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> edges (</span><br><span class="line">  edge_id     <span class="type">INTEGER</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">  tail_vertex <span class="type">INTEGER</span> <span class="keyword">REFERENCES</span> vertices (vertex_id),</span><br><span class="line">  head_vertex <span class="type">INTEGER</span> <span class="keyword">REFERENCES</span> vertices (vertex_id),</span><br><span class="line">  label       TEXT,</span><br><span class="line">  properties  JSON</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 给定任何顶点，可以高效地找到它的入边和出边，从而遍历图，即沿着一系列顶点的路径前后移动，建以下索引</span></span><br><span class="line"><span class="keyword">CREATE</span> INDEX edges_tails <span class="keyword">ON</span> edges (tail_vertex);</span><br><span class="line"><span class="keyword">CREATE</span> INDEX edges_heads <span class="keyword">ON</span> edges (head_vertex);</span><br></pre></td></tr></tbody></table></figure>
<h3 id="B-Cypher-属性图模型声明式查询语句">B-Cypher 属性图模型声明式查询语句</h3>
<p>Cypher是属性图的声明式查询语言，为Neo4j图形数据库而发明</p>
<p align="center">
  <img src="/2023/09/21/ddia/57.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 图模型&amp;图数据写入&amp;图数据查询 </span>
</p>
<h2 id="读时模式vs写时模式">读时模式vs写时模式</h2>
<p><strong>读时模式（schema-on-read）</strong>：数据的结构是隐含的，只有在数据被读取时才被解释，比如文档数据库</p>
<p><strong>写时模式（schema-on-write）</strong>：传统的关系数据库方法中，模式明确，且数据库确保所有的数据都符合其模式</p>
<p>读时模式类似于编程语言中的动态（运行时）类型检查，而写时模式类似于静态（编译时）类型检查，就像静态和动态类型检查的相对优点具有很大的争议性一样，数据库中模式的强制性是一个具有争议的话题，一般来说没有正确或错误的答案</p>
<h2 id="总结">总结</h2>
<p>在历史上，数据最开始被表示为一棵大树（层次数据模型），由于不适合表示多对多的关系，发明了关系模型来解决这个问题。后来，人们发现一些应用程序也不适合采用关系模型，于是新的非关系型“NoSQL”数据</p>
<ol>
<li class="lvl-3">
<p>文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。</p>
</li>
<li class="lvl-3">
<p>图形数据库用于相反的场景：任意事物都可能与任何事物相关联。</p>
</li>
</ol>
<p>这三种模型（文档，关系和图形）在今天都被广泛使用</p>
<h1>第3章节-存储与检索</h1>
<p>存储与检索的内容，即：数据库在最基础的层次上完成的2件事情：</p>
<p>🅰️ 当你把数据交付给它的时候，它如何将数据存储起来</p>
<p>🅱️ 当你向数据库索要数据时，它如何将数据返回给你</p>
<p>由于<strong>事务性负载</strong>和<strong>分析性负载</strong>的存储引擎之间存在着很大的差异，这两类的存储引擎我们分开来描述</p>
<p><strong>在事务处理方面</strong>：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>日志结构存储引擎  ；从最简单的数据库实现append-log(无索引日志)到 LSM(日志结构合并树) 树的演化历程</p>
</li>
<li class="lvl-2">
<p>面向页面的存储引擎 ，典型的比如B-Tree</p>
</li>
</ul>
<p>在<strong>分析性存储引擎方面</strong>，我们谈谈</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>数据仓库</p>
</li>
<li class="lvl-2">
<p>星型模型&amp;雪花模型</p>
</li>
<li class="lvl-2">
<p>列存储</p>
</li>
</ul>
<h2 id="无索引日志">无索引日志</h2>
<p>我们来看下 <strong>世界上最简单的数据库</strong> 是如何实现的</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>插入操作（<code>db_set</code>）</p>
</li>
<li class="lvl-2">
<p>更新操作（<code>db_set</code>）</p>
</li>
<li class="lvl-2">
<p>查询操作（<code>db_get</code>）</p>
</li>
</ul>
<p align="center">
  <img src="/2023/09/21/ddia/16.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 无索引日志 &amp; 最简单的数据库 </span>
</p>
那么这个最简单的数据库底层是如何进行数据的摆放的呢？可以看到`db_set()`就是一个非常简单的追加[^4]，这**简直不是简单，甚至可以说是简陋**但正是由于这种设计使得写入变的非常的高效，代价就查找的开销是 $O(n)$ ， $O(n)$ 的复杂度，这意味着如果数据量增加一倍，查询响应时间将会增加一倍。也就是说查询时间和数据量之间的关系是线性相关的。所以我们需要**更快的得到目标结果**，那么如何去提升数据的查找效率？
<blockquote></blockquote>
<h2 id="如何提升查找效率？">如何提升查找效率？</h2>
<p align="center">
  <img src="/2023/09/21/ddia/17.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 康熙字段VS新华字典 </span>
</p>
<p>当我们还是一个小学生的时候，可能面临过类似的问题，假设说现在有2个小学生，忘记了<strong>囧</strong>字怎么写，想要用新华字典查询一下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>小明同学使用的是一本没有目录的字典(比如说康熙字典)</p>
</li>
<li class="lvl-2">
<p>小红同学 使用的是一本有目录的字典(现代新华字典)</p>
<p>那么谁最后能更快的获知 <code>jiong</code> 字的写法呢？直觉告诉我们小红同学有较大的概率最快获取到 <code>joing</code>字的写法</p>
</li>
</ul>
<p>现代字典的特征就是都会有一个目录，这个目录是在<strong>原始数据之外维护的额外的数据</strong>，正是由于目录的存在，使得小红同学能够更快的获取到目标数据。其实这个目录，其实就相当于英文中的 <code>index</code> , 而 <code>index</code>英译就是索引，至此我们可以得到一个结论：</p>
<blockquote>
<p>索引 是在原始数据之外维护的额外的数据，索引 可以加速数据访问</p>
</blockquote>
<p>🎈<strong>Post Script</strong>🎈</p>
<p>由于需要在原始数据之外额外维护一份数据，这就无形增加了空间复杂度，在计算机领域中，时间和空间就像鱼和熊掌一样，不可兼得，降低时间复杂度的方式就<strong>用空间换取时间</strong>； 可以说这个问题在计算机领域是一个绕不开的话题，如何去提升查找效率这个问题的另外一种问法是：<strong>给我一个更低的时间复杂度</strong>的实现，那么常见的比 $O(n)$  还低的时间复杂度就是 $O(1)$， $O (log_n)$  两个，$O(1)$ 的时间复杂度，我们很容易就会想到哈希表，因为哈希表的时间复杂度默认是 $O(1)$，接下来我们尝试构建哈希索引来提升查询效率</p>
<h2 id="内存中构建hash索引">内存中构建hash索引</h2>
<p align="center">
  <img src="/2023/09/21/ddia/18.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 为日志构建哈希索引 </span>
</p>
<p>那么对于存储于磁盘中的数据，我们在内存中维护一个<code>HashMap</code>，维护<code>key</code>和<code>value</code> 的偏移量，这样一来，我们就能够迅速的定位到目标数据，比如我们想要找到 <code>key = 42</code> 的数据，通过查询内存中的HashMap表，获得偏移量64 ，所以可以直接定位到数据，而不在需要从头开始遍历</p>
<p>随着我们不断的在文件末尾追加文件，磁盘中的单个文件也会越来越大，甚至单个文件可能吃掉整个磁盘的存储。所以，<strong>如何用有限的存储存储更多的数据？</strong> 即，如何避免磁盘的空间的消耗？</p>
<h2 id="分段存储-压缩-分段合并-hash索引的局限性">分段存储&amp;压缩&amp;分段合并 &amp; hash索引的局限性</h2>
<p align="center">
  <img src="/2023/09/21/ddia/19.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 日志分段 &amp; 分段日志压缩 </span>
</p>
<p>我们解决的方案是：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>分段存储：也就是说当追加文件的 <code>size</code>（通常是几兆字节） 达到了一定的阈值之后，我们重新写入新的文件（每个段维护自己的索引）</p>
</li>
<li class="lvl-2">
<p>压缩：丢弃重复的键，保留每个键的最新值</p>
</li>
</ul>
<p>如上图中原本12个键 压缩之后之后3个键，整个文件的<code>size</code>降低。<strong>如何进一步改进？</strong></p>
<p align="center">
  <img src="/2023/09/21/ddia/20.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 日志分段 &amp; 分段日志压缩 &amp; 压缩日志合并 </span>
</p>
<p>在执行压缩的同时，可以将压缩之后的<strong>段合并</strong>。如 Data file segment 1 和 Data file Segment 2 在压缩了之后，进行了一个合并操作，得到了 Merged Segment(比如mew 这个键压缩合并的过程)。压缩和合并对用户是没有感知的，由后台进程完成，在合并的时候由旧的段文件提供读写请求，在合并完成之后，读写请求转化为新的合并后的段</p>
<p>那么由于hash表本身的特性，也会导致我们构建的哈希索引有一定的局限性，比如：</p>
<p>🅰️ 哈希表是存在于内存中的</p>
<p>🅱️ 范围查询是软肋</p>
<p>那么如何突破哈希表的局限性，寻找更好的索引结构？</p>
<h2 id="SSTable-排序字符串表">SSTable 排序字符串表</h2>
<p>这个问题的答案是：排序字符串表，也就是<strong>SSTable<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></strong>, 也就是：在段文件中，对键值对的序列排序</p>
<p align="center">
  <img src="/2023/09/21/ddia/21.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> SStable </span>
</p>
<p>比如上图中，对于已经排好序段文件1，段文件2 ，段文件3 ，进行压缩和合并，而且，在合并之后，仍然需要保证合并之后的段文件有序，所以我们需要一个合适的排序算法：<strong>那么这个排序算法是什么呢？</strong> 是冯诺依曼发明的归并排序算法；merge sort 的优势就在于：内存在小于被排序文件大小的时候，仍然可以将排序完成</p>
<blockquote></blockquote>
<p>使用SSTable可以有效的突破内存限制和解决范围查询的问题。如下图中我们查找，<code>handiwork</code> 的过程，可以发现不是在内存中保存所有键的索引，由于SSTable维护了顺序关系，我们的索引以稀疏索引的方式存在于内存中。同时，可以支持范围查询</p>
<p align="center">
  <img src="/2023/09/21/ddia/22.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 稀疏索引，比如每几千个字节一个键 </span>
</p>
<h2 id="LSM-日志结构合并树">LSM 日志结构合并树</h2>
<p>在前面的讲述中，我们默认了落盘段文件是有序的，在落盘写入段文件之前，<strong>如何按键排序</strong>？考虑到效率问题，最初的的写入一定是在内存中的，到达一定的时间阈值或者是内存阈值的时候，在进行落盘形成 SSTable，那么内存中<strong>选择什么样的数据结构？</strong></p>
<p>1️⃣ 内存表，<strong>为什么是AVL-Tree ？</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>首先平衡二叉树本身就是二叉搜索树，而二叉搜索树中序遍历就是顺序结构，可以直接落盘形成SSTable</p>
</li>
<li class="lvl-2">
<p>由于平衡特性，可以保持树的结构，而不是退化成链表，使得查询的时间复杂度维持在 $O(logN)$, 而且对于新加入的数据，平衡二叉树通过左旋，或者右旋的方式保持平衡性</p>
</li>
</ul>
<p>2️⃣ 落盘，也就是平衡二叉树的中序遍历方式落盘</p>
<p>3️⃣ 读取请求，先请求内存，然后查询磁盘段</p>
<p>4️⃣ 压缩和合并： 后台压缩合并段文件，并丢弃覆盖/删除旧值</p>
<p>5️⃣ 防止数据库崩溃（保存在AVL-Tree，但是未落盘到SStable）：磁盘保留一份单独的日志，每个写入都追加到磁盘上，防止数据库崩溃，内存数据丢失</p>
<p align="center">
  <img src="/2023/09/21/ddia/23.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 那么使用这种LSM结构的组件有哪些 </span>
</p>
<p>Cassandra<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>、Bigtable、HBase、Elasticsearch、Solr<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>、Hologres<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup></p>
<blockquote></blockquote>
<p><strong>这种先内存排序，再落盘排序的结构，就是LSM(Log-Structure Merge Tree 日志结构合并树)结构</strong>，<strong>LSM结构和B±Tree相比，减少了随机IO，极大的提高的写性能</strong></p>
<h2 id="面向页存储引擎">面向页存储引擎</h2>
<p>接下来我们介绍另外一种存储引擎：面向页面的存储引擎，比如B 树，B树会将数据库分解为固定大小的块或者是页面<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>，传统大小为4K而且一次只能读取或者写入一个页面，和LSM对比一下</p>
<p align="center">
  <img src="/2023/09/21/ddia/24.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> B树和LSM比对 </span>
</p>
<blockquote></blockquote>
<p>下图展示了面向页面的存储引擎是如何查询数据的</p>
<p align="center">
  <img src="/2023/09/21/ddia/25.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 面向页面的存储引擎是如何查询数据的 </span>
</p>
<p>分支因子：<strong>在B树中一个页面中对子页面的引用数量</strong>。伴随着上世纪70年代关系型数据库的发展至今，面向页面的存储引擎发展至今已经非常成熟了</p>
<h2 id="向页面添加元素">向页面添加元素</h2>
<p>如何向B树中增加一个数据，如下图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/26.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 如何向B树中增加一个数据 </span>
</p>
<blockquote>
<p>WAL即在数据写数据页之前，先记录到"小黑板"<sub>WAL</sub>上，对于一个更新操作来说，如果每次更新都需要立刻写磁盘，存储引擎需要找到被更新的记录，然后更新，这个先定位再更新的机制必然有一定的成本（查找成本+IO成本），如果<strong>引擎会将记录写到 文件 里，并且更新内存</strong>，在适当（系统比较空）的时候，将操作记录刷写到磁盘， 如此便可以提升更新效率。事实上MySQL的InnDB 引擎就是这么做的</p>
</blockquote>
<h2 id="比对LSM树-和-B树">比对LSM树 和 B树</h2>
<p>最后我们来一起对比一下LSM树和B树，也即面向日志的存储引擎和面向B树的存储引擎的优劣势</p>
<p align="center">
  <img src="/2023/09/21/ddia/27.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 比对LSM树 和 B树 </span>
</p>
<h2 id="OLTP-OLAP-和-数据仓库">OLTP&amp;OLAP 和 数据仓库</h2>
<p>数据库在历史中主要为两种系统提供支持</p>
<p>🅰️ 在线事务处理系统，即 OLTP</p>
<p>🅱️ 在线分析系统，即 OLAP</p>
<p>下表中对比了两者之间的区别，</p>
<p align="center">
  <img src="/2023/09/21/ddia/28.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> OLTP 对比 OLAP </span>
</p>
<p>起初的数据库，能够同时应对以上两种查询的情况，无论是OLTP类型的查询，还是OLAP类型的查询，单一的数据库的表现的都很好，也就是说：<strong><u>也就是说两者是一家的</u></strong>。 OLAP通常会要求 <strong>高可用</strong>与<strong>低延迟</strong>，为了保证业务系统的稳定运行，所以DBA会密切关注他们的OLTP数据库，他们通常不愿意让业务分析人员在OLTP数据库上运行临时分析查询，因为这些查询通常开销巨大，会扫描大部分数据集，这会损害同时执行的事务的性能。可以见得，OALP和OLTP 这对亲兄弟发生了矛盾，矛盾会最佳解决方案就是分家</p>
<p>在20世纪80年代末和90年代初期，渐渐地很多公司有停止使用OLTP系统进行分析，而是在单独的数据库上运行分析。这个单独的数据库被称为<strong>数据仓库(data warehouse)</strong>。因为最初的数据仓库是从关系型数据库中独立出来，只存储关系数据，而且是面向数据分析，BI(商业智能)的，只是到了后来随着大数据时代的到来，数据仓库才慢慢变的越来越像<strong>数据湖<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup></strong> (就是各种数据都跑往数据仓库里面塞)</p>
<blockquote>
<p>数据沼泽：<strong>数据沼泽</strong> 是一个劣化的数据湖，用户无法访问，或是没什么价值</p>
</blockquote>
<p>又或者说，<strong>数据湖是下一代数据仓库</strong>，从OLTP数据库中提取数据，转换成适合分析的模式，清理并加载到数据仓库中，因此数据仓库包含公司各种OLTP系统中所有的只读数据副本。下图是一个简要的示意图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/29.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> ETL过程 </span>
</p>
<h2 id="数据仓库系统组件">数据仓库系统组件</h2>
<p>我们来看一些比较出名的商业数据仓库系统，尽管他们是冠以出名的商业数据仓库系统，但是其中"商业"两个字可能是太贵，导致大多数从事数据仓库相关工作的人，其实并不知道：</p>
<img src="/2023/09/21/ddia/30.jpg" width="100%" height="70%" alt="图片名称" align="center">
<ul class="lvl-0">
<li class="lvl-2">
<p>SQL - Server   使用两套不同的存储和查询引擎来应对OALP和OLTP环境</p>
</li>
<li class="lvl-2">
<p>Teradata       天睿</p>
</li>
<li class="lvl-2">
<p>Vertica          维蒂卡</p>
</li>
<li class="lvl-2">
<p>SAP HANA    SAP  汉那</p>
</li>
<li class="lvl-2">
<p>ParAccel        帕加速</p>
</li>
</ul>
<p>相对而言，我们更喜欢免费的开源产品，下面是一些SQL-on-Hadoop 项目：</p>
<p>Hive-SQL、Spark-SQL、Flink-SQL、Presto、Druid、Kylin、Impala</p>
<h2 id="雪花模型">雪花模型</h2>
<p>在OLTP系统中，可用的数据模型很丰富，比如大类上分为</p>
<p>🅰️ 关系模型</p>
<p>🅱️ 新的非关系模型，No-SQL模型</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>文档数据库模型</p>
</li>
<li class="lvl-2">
<p>图形数据库模型</p>
</li>
</ul>
<p>相对于OATP系统来说，OLAP系统的数据模型多样性就少的多，数据仓库大多使用一样的公式化模型：<strong><u>星型模式|星型模型(也叫维度建模)</u></strong> 如下图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/31.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 星型模式示意图 </span>
</p>
<p>1️⃣ 模式的中心是一个所谓的事实表，事实表的每一行代表在特定时间发生的事件(这里，每一行代表客户购买的产品)</p>
<p>2️⃣ 事实表中的一些列是属性，例如产品销售的价格和从供应商那里购买的成本(允许计算利润余额)，通常是数字等可统计指标</p>
<p>3️⃣ 事实表中的其他列是对其他表(称为维表)的外键引用，由于事实表中的每一行都表示一个事件，因此这些维度代表事件的发生地点，时间，方式和原因</p>
<p>4️⃣ 事实表格有100列以上，有时甚至有数百列，快手宽表列长达1000+列</p>
<p>5️⃣ 星型模型进一步的扩展是雪花模型，也就是基于维度表进一步拆分</p>
<p>当表关系可视化时，事实表在中间，由维表包围；与这些表的连接就像星星的光芒，所以这模式被命名为：“星型模式”</p>
<h2 id="列式存储">列式存储</h2>
<p>在前面的存储结构中，我们介绍了</p>
<p>🅰️ 基于日志的存储：日志结构学派</p>
<p>🅱️ 基于页面的存储：就地更新学派</p>
<p>然而，典型的数据仓库查询一次只访问较少的列，如果使用行存储的话，面向行的存储引擎仍然需要将所有这些行(每个包含超过100个属性)从磁盘加载到内存中，解析它们，并过滤掉那些不符合要求的条件。这可能需要很长时间。面向列的存储背后的想法很简单：<strong>不要将所有来自一行的值存储在一起，而是将来自每一列的所有值存储在一起</strong>。如下图</p>
<p align="center">
  <img src="/2023/09/21/ddia/32.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 列式存储示意图 </span>
</p>
<p>可以观察到红色框选出来的值序列，他们是重复数据，而<strong>重复数据是压缩的好兆头</strong>。我们根据列中的数据，可以使用不同的压缩技术来进一步降低对磁盘吞吐量的需求，在数据仓库中特别有效的一种技术是<em>位图编码</em>(类似哈夫曼编码)，如下图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/33.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 位图编码和压缩 </span>
</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">in</span> () <span class="comment">--  对应着位图的 或</span></span><br><span class="line"><span class="keyword">and</span>   <span class="comment">--  对应着位图的 与</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>比如hive支持的存储格式包括textfile,parquet, rcfile,orc, 其中orc是rcfile的优化版(Optimize Rcfile，Rcfile基于Lazy Decompression)，相较于rcfile有更好的表现，列存和压缩通常会结合，压缩比ORC(ZLIB压缩) &gt;  Parquet (Uncompress即默认不压缩)&gt;  textFile（textfile不压缩），注意点是压缩在有效降低IO的同时会提升CPU的消耗</p>
</blockquote>
<p>列存储中的排列顺序也非常有意义。需要注意的是：即使按列存储数据，也需要一次对整行进行排序，一般对最常见的查询字段做为第一排序的列，第二列可以确定第一列中具有相同值的任何行的排序顺序，这将加快查询速度。同时，排序顺序可以帮助压缩列，第一个排序键的压缩效果最强，一个简单的运行长度编码（比如位图）可以将该列压缩到几千字节 —— 即使表中有数十亿行（不同的值很少，基数少）</p>
<p>写入列存储的困难</p>
<p>如果你想在列存排序表的中间插入一行，你很可能不得不重写所有的列文件。由于行由列中的位置标识，因此插入必须始终更新所有列（这大概就是Hive仅仅支持 <code>overwrite</code>操作的缘故）</p>
<p>另外的解决方案是，LSM树的这种结构，所有的写操作首先进入一个内存中的存储，在这里它们被添加到一个已排序的结构中，并准备写入磁盘。内存中的存储是面向行还是列的，这并不重要。当已经积累了足够的写入数据时，它们将与磁盘上的列文件合并，并批量写入新文件</p>
<p>什么是物化视图？</p>
<p>据仓库查询通常涉及一个聚合函数，如SQL中的COUNT，SUM，AVG，MIN或MAX。如果相同的聚合被许多不同的查询使用，那么每次都可以通过原始数据来处理。为什么不缓存一些查询使用最频繁的计数或总和？创建这种缓存的一种方式是物化视图。物化视图的常见特例称为数据立方体或OLAP立方</p>
<p>物化视图 和 虚拟视图的区别？</p>
<p>不同的是，物化视图是查询结果的实际副本，写入磁盘，而虚拟视图只是写入查询的捷径。从虚拟视图读取时，SQL引擎会将其展开到视图的底层查询中，然后处理展开的查询</p>
<p align="center">
  <img src="/2023/09/21/ddia/58.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 数据立方的两个维度，通过求和聚合 </span>
</p>
<h1>第四章节-编码和演化</h1>
<h2 id="什么是可演化性？">什么是可演化性？</h2>
<p>能灵活适应变化的系统， 修改数据系统并使其适应不断变化需求的容易程度，是与<strong>简单性</strong>和<strong>抽象性</strong>密切相关的：简单易懂的系统通常比复杂系统更容易修改</p>
<h2 id="向后兼容，向前兼容">向后兼容，向前兼容</h2>
<p>向后兼容(backward compatibility)：新代码可以读旧数据</p>
<p>向前兼容（forward compatibility）：旧代码可以读新数据</p>
<h2 id="编码数据的格式有哪些？">编码数据的格式有哪些？</h2>
<ol>
<li class="lvl-3">
<p>在内存中，数据保存在对象，结构体，列表，数组，哈希表，树等中。 这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）</p>
</li>
<li class="lvl-3">
<p>如果要将数据写入文件，或通过网络发送，则必须将其编码为某种自包含的字节序列（例如，JSON文档）</p>
<blockquote>
<p>从内存中表示到字节序列的转换称为编码（也称为序列化（serialization）或编组（marshalling）），反过来称为解码（Decoding）（解析（Parsing），反序列化（deserialization）**，**反编组( unmarshalling））</p>
<p>编码过程也成为序列化Serialization，其中事务的隔离级别中也出现了该词，请区分2者</p>
<p>在一些编程语言中，都内建了将内存对象编码为字节序列的支持，Java有<code>java.io.Serializable</code> ，Python有<code>pickle</code></p>
</blockquote>
</li>
</ol>
<h2 id="文本编码和二进制编码">文本编码和二进制编码</h2>
<table>
<thead>
<tr>
<th>比对方面</th>
<th>文本编码</th>
<th>二进制编码</th>
</tr>
</thead>
<tbody>
<tr>
<td>可读性</td>
<td>人类易读</td>
<td>人类不可读</td>
</tr>
<tr>
<td>数据类型</td>
<td>表示文本字符，如字母、数字、符号</td>
<td>表示各种类型的数据，包括整数、浮点数、图像、音频、程序指令等</td>
</tr>
<tr>
<td>编码方式</td>
<td>采用字符集（如ASCII、UTF-8、ISO-8859-1等）来将字符映射到数字或二进制，每个字符都有一个唯一的编码值</td>
<td>将数据直接表示为由 0 和 1 组成的二进制序列的方式。它不需要字符集</td>
</tr>
<tr>
<td>应用领域</td>
<td>处理文本数据，如文档、网页、电子邮件等</td>
<td>用于计算机内部数据表示、存储和通信，包括整数、浮点数、图像、音频、视频等。它处理的是更底层的数据表示</td>
</tr>
</tbody>
</table>
<figure class="highlight json"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// 二进制编码示例，删除了空格换行后，81个字节</span></span><br><span class="line"><span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"userName"</span><span class="punctuation">:</span> <span class="string">"Martin"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"favoriteNumber"</span><span class="punctuation">:</span> <span class="number">1337</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"interests"</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">"daydreaming"</span><span class="punctuation">,</span> <span class="string">"hacking"</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure>
<p>接下来我们使用不同的二进制编码组件/库对上述的JSON文档进行编码</p>
<p align="center">
  <img src="/2023/09/21/ddia/59.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 使用不同的二进制组件编码同一个JSON文档 </span>
</p>
<p>Avro也使用模式来指定正在编码的数据的结构， 它有两种模式语言：一种（Avro IDL）用于人工编辑，一种（基于JSON），更易于机器读取</p>
<p align="center">
  <img src="/2023/09/21/ddia/61.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> Avro 二进制编码 &amp; Avro Reader 解决读写模式的差异 </span>
</p>
<h2 id="数据流的类型">数据流的类型</h2>
<p>如果要将某些数据发送到不共享内存的另一个进程，例如，通过网络发送数据或将其写入文件，就需要将它编码为一个字节序列</p>
<p>数据在流程之间流动的一些最常见的方式：</p>
<ol>
<li class="lvl-3">
<p>通过数据库：写入编码，读取解码</p>
</li>
<li class="lvl-3">
<p>通过服务调用：REST和RPC</p>
</li>
<li class="lvl-3">
<p>通过异步消息传递：消息队列</p>
</li>
</ol>
<h3 id="A-Web服务">A-Web服务</h3>
<p>有两种流行的Web服务方法：REST和SOAP</p>
<p>将大型应用程序按照功能区域分解为较小的服务，一个服务请求另外一个服务的功能或者数据，这种构建应用程序的方式传统上被称为 <strong>面向服务的体系结构（service-oriented architecture，SOA）</strong> ，也称之为 <strong>微服务架构</strong></p>
<p>REST是一个基于HTTP原则的设计哲学。它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制，身份验证和内容类型协商。与SOAP相比，REST已经越来越受欢迎，至少在跨组织服务集成的背景下【36】，并经常与微服务相关[31]。根据REST原则设计的API称为RESTful。</p>
<h3 id="B-RPC">B-RPC</h3>
<p>RPC是一种协议无关的通信方式，通常使用二进制协议（如Protobuf、Thrift）或文本协议（如XML-RPC、JSON-RPC）来传输数据。它允许客户端调用远程服务器上的函数，就像本地函数一样。RPC通常是无状态的，通常使用二进制格式以提高效率</p>
<p><strong>RESTful</strong>：RESTful是基于HTTP协议的通信方式，使用HTTP动词（GET、POST、PUT、DELETE等）来执行操作，并使用URL来定位资源。它使用标准的HTTP状态码来表示操作的结果。RESTful通常使用文本格式，如JSON或XML，以便数据可以被轻松解析和理解</p>
<p>RPC框架的主要重点在于同一组织拥有的服务之间的请求，通常在同一数据中心内</p>
<h1>第5章节-复制</h1>
<p>接下来是第5章的内容，这章节的内容主要是复制，所谓复制就是<strong>同一份数据保留多个副本</strong>。 复制数据的原因呢？</p>
<p>1️⃣ 使得数据与用户在地理上接近(减少延迟)</p>
<p>2️⃣ 即使系统的一部分出现故障，系统也能继续工作(提高可用性)</p>
<p>3️⃣ 扩展可以接受读请求的机器数量(提高读取吞吐量)</p>
<p>本章主要讨论三种变更<strong>复制算法</strong>（区别于复制方法/策略）：单主复制、多主复制、无主复制。当存在多个副本时，会不可避免的出现一个问题：如何确保所有数据都落在了所有的副本上？所以，复本机制真正的麻烦在于如何<strong>处理复制数据的变更</strong> 。我们来看一个非常普遍且常用解决方案：<strong>单主复制</strong></p>
<h2 id="单主复制">单主复制</h2>
<p>来具体看一个场景，更换新的用户头像的实例：</p>
<p align="center">
  <img src="/2023/09/21/ddia/34.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 单主复制 </span>
</p>
<p>总结一下单主复制符合以下的特点：</p>
<p>1️⃣ 多个副本中只有一个设置为leader,其他是flower</p>
<p>2️⃣ leader接受读请求和写请求，follower只接受读请求</p>
<p>3️⃣ follower从leader拉取日志，更新本地数据库副本</p>
<p>这种复制模式是很多关系型数据库内置的功能，比如PostgreSQL(9.0之后)，MySQL，SQL Server，文档型数据库 MongoDB。基于领导者的复制不局限于数据库，像一些高可用的分布式MQ也在用，比如Kafka、RabbitMQ</p>
<blockquote>
<p>关于主从和主备，主从中，“从”是向外提供服务的，而主备中的备不是对外提供的，备的作用是待“主”crash的时候成为主</p>
</blockquote>
<p>🎈🎈接下来呢，我们讨论复制系统的一个重要细节（复制策略）：复制是 <strong>同步(synchronously)</strong> 发生还是<strong>异步(asynchronously)</strong> 发生</p>
<h2 id="同步-异步">同步/异步</h2>
<p>如下图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/35.jpg" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 同步 &amp; 异步 </span>
</p>
<p>1️⃣ 用户 $id=1234$ 的用户向主库提交数据变更请求</p>
<p>2️⃣ 主库将数据变更同步给从库1（Follower1） ，并且等待从库1（Follower1）的响应，这里从库1（Follower1）复制的方式是同步</p>
<p>3️⃣ 主库将数据变更同步给从库2（Follower），但是不等待从库2（Follower2）的确认，这里从库2（Follower2）的复制方式是异步</p>
<p>整体的配置方式也被称作是半同步。我们来一起看下同步和异步复制的优劣势：</p>
<p>🅰️ 同步复制能够保证数据可靠性，但是如果从库迟迟不能响应主库，主库就不能接收新的读写请求</p>
<p>🅱️ 异步复制的优点是，即便从库落后了，主库也可以继续处理写入请求，劣势是无法保证数据一致性</p>
<p>我们再来看一下设置新从库的步骤：</p>
<p>1️⃣ 获取某个时刻主库的一致性快照</p>
<p>2️⃣ 将快照复制到从库节点</p>
<p>3️⃣ 从库连接主库，拉取快照之后发生的数据变更。拉取快照之后的变更，往往快照和主库复制日志关联，不同的数据库对于<em>这个关联关系</em>实现有着不同的名称：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>PostgreSQL 的叫做<strong>日志序列号(log sequence number, LSN)</strong></p>
</li>
<li class="lvl-2">
<p>MySQL将其称为 <strong>二进制日志坐标(binlog coordinates)</strong></p>
</li>
</ul>
<p>🎈🎈 从库失效的问题很好解决，从库在重新和主库建立连接之后，可以从日志知道最后一个失败的事务。然后开始追赶主库。如果主库失效了，该如何处理呢？</p>
<h2 id="处理故障节点">处理故障节点</h2>
<p><strong>主库失效如何处理？</strong></p>
<p>1️⃣ 确认主库失效</p>
<p>2️⃣ 选择一个新的主库，<strong><u>让所有的副本达成一致意见(共识<sub>consensus</sub>问题)</u></strong></p>
<p>3️⃣ 重新配置新的主库，并且启用新的主库</p>
<p>一些挑战：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果使用异步复制，发生的数据丢失问题，GitHub，MySQL从库切换为主库事故</p>
</li>
<li class="lvl-2">
<p>脑裂的情况，设置新的主库之后，老的主库又一次活过来了，可能会存在两个主库的情况，同时接受写入，可能会导致数据损坏，解决的方案可能是，发送<code>kill</code> comand 去干掉一个主库</p>
</li>
<li class="lvl-2">
<p>宣告主库死亡的阈值，主库在宣告死亡前，超时时间的设置，设置太长意味着恢复时间长，太短就会发生不必要的切换</p>
</li>
</ul>
<p><strong>基于主库的复制底层是如何工作的？</strong></p>
<p>1️⃣ 基于语句的复制，有非确定性函数、自增列的问题</p>
<p>2️⃣ 传输，预写式日志(WAL，Write Ahead Log)，日志包含所有数据库写入的仅追加字节序列，可以将其发给从库，比如说PostgreSQL 、Oracle。<strong>缺点是数据过于底层，WAL包含哪些磁盘块中的哪些字节发生了更改</strong>。这使复制与存储引擎紧密耦合，对数据库版本不友好，会对运维升级数据库造成困难</p>
<blockquote>
<p>MySQL数据库中有2种日志：redo log 和 binlog ，其中的redo log的实现方式即为WAL，先写日志，在罗盘</p>
</blockquote>
<p>3️⃣ 逻辑日志复制(基于行)，也即复制日志和存储引擎存储的日志采用不同的格式，这种复制日志被称为逻辑日志，逻辑日志有一下特点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>对于插入的行，日志包含所有列的新值</p>
</li>
<li class="lvl-2">
<p>对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值</p>
</li>
<li class="lvl-2">
<p>对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值(至少所有已更改的列的新值)</p>
</li>
</ul>
<blockquote>
<p>逻辑日志，可使领导者和跟随者能够运行不同版本的数据库软件甚至不同的存储引擎。MySQL的binlog日志有三种格式，分别是statement、row、mixed，现通常使用row模式，即逻辑日志的形式，MySQL binlog 使用row模式就是当前描述的这种方式</p>
<p>模式下数据库的变更流可以应用在MySQL从库，或者Debezium/Cancel解析后推送至三方系统(消息代理Kafka、存储系统)</p>
</blockquote>
<p>4️⃣ 基于触发器的复制，触发器能够实现，在数据库系统中发生数据更改(写入事务)时，自动执行的自定义应用程序代码，不同于数据库系统实现的复制</p>
<h2 id="复制延迟问题">复制延迟问题</h2>
<h3 id="A-什么是最终一致性？">A-什么是最终一致性？</h3>
<p>从库有可能落后于主库，此时同一个查询打到主库和从库，会得到不一样的结果，这种不一致只是一个暂时的状态，如果停止写入数据库并等待一段时间，从库最终会赶上并与主库保持一致。这种效应被称为 <strong>最终一致性（eventually consistency）</strong></p>
<h3 id="B-什么是写后读一致性？">B-什么是写后读一致性？</h3>
<p>在异步复制策略中，用户向主提交了新数据，但是该用户的查询打到了从库，这种情况下，我们需要写后读一致性（read-after-write consistency），即：自己刚刚更新的内容，再去查询的时候，可以获取到更新</p>
<p>具体实现的方式有：</p>
<ol>
<li class="lvl-3">
<p>读用户<strong>可能已经修改过</strong>的内容时，都从主库读。一个简单的规则是：从主库读取用户自己的档案，在从库读取其他用户的档案</p>
</li>
<li class="lvl-3">
<p>客户端记住最近一次写入的时间戳（可以是逻辑时间戳），如果该时间戳已经传播到了从库，从从库读取没问题，否则从主库读</p>
</li>
</ol>
<p align="center">
  <img src="/2023/09/21/ddia/60.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 写后读一致性保证 &amp; 单调读一致性保证 </span>
</p>
<h3 id="C-什么是单调读？">C-什么是单调读？</h3>
<p>用户首先从新副本读取，然后从旧副本读取。时光倒流，我们需要单调读一致性</p>
<p>实现单调读取的一种方式是，确保每个用户总是从同一个副本进行读取（不同的用户可以从不同的副本读取）。例如，可以基于用户ID的散列来选择副本，而不是随机选择副本。但是，如果该副本失败，用户的查询将需要重新路由到另一个副本</p>
<h3 id="D-什么是一致前缀读？">D-什么是一致前缀读？</h3>
<p>如果某些分区的复制速度慢于其他分区，那么观察者在看到问题之前可能会看到答案，我们需要提供某种保证，如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现</p>
<p align="center">
  <img src="/2023/09/21/ddia/62.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 一致前缀度保证 </span>
</p>
<p>许多分布式数据库中，不同的分区独立运行，因此不存在<strong>全局写入顺序</strong>：当用户从数据库中读取数据时，可能会看到数据库的某些部分处于较旧的状态，而某些处于较新的状态。</p>
<p>一种解决方案是，确保任何因果相关的写入都写入相同的分区。对于某些无法高效完成这种操作的应用，还有一些显式跟踪因果依赖关系的算法，本书将在“一致性与共识”一节中再次聊聊这个问题</p>
<h2 id="多主复制的问题">多主复制的问题</h2>
<p>多领导者复制的最大问题是可能发生写冲突，这意味着需要 <strong>解决冲突</strong></p>
<p align="center">
  <img src="/2023/09/21/ddia/63.png" width="100%" alt="Your image description">
    <br>
  <span style="color:gray"> 两个主库同时更新同一记录引起的写入冲突 </span>
</p>
<h2 id="无主复制">无主复制</h2>
<p>在无主复制，客户端的写入和读取，都请求到所有的副本，副本的写入有可能失败，有可能成功；读取时，选择按照法定人数（5个节点，3个节点返回数据相同）的数据回写到写入失败的节点。同时后台进程追踪节点之间的差异，趋势数据的收敛（因为有一些键没有读请求）</p>
<h3 id="A-什么是并发？">A-什么是并发？</h3>
<p>为了定义并发性，确切的时间并不重要：如果两个操作都意识不到对方的存在，就称这两个操作<strong>并发</strong></p>
<h1>第6章-分区</h1>
<p><strong>分区<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>是一种切分大数据集的方法，即一份数据切成多块</strong>，分区的目的是为了可扩展性，从而提高吞吐量。在实践中，分区通常和复制结合使用，每个分区的副本将处在多个节点上，以此获得容错能力。下图是主从复制模型下，分区和复制相结合的示意图：</p>
<blockquote></blockquote>
<p align="center">
  <img src="/2023/09/21/ddia/47.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 分区和复制的实例 </span>
</p>
<h2 id="键值数据的分区方式">键值数据的分区方式</h2>
<p>分区最核心的问题是</p>
<p>🅰️ 避免倾斜(skew)，即热点数据处理，放的角度</p>
<p>🅱️ 处理访问路由问题，即查询性能的保证，取的角度</p>
<p>下面我们介绍几种常见的分区方式：</p>
<p>1️⃣ 按照key的范围分区，这种方式天生可以解决访问路由的问题，对于热点数据，可根据数据状况进行拆分，Hbase,BigTable使用这种策略。在处理时间范围分区时，为避免一直写当前时间对应分区的 <strong>写入过载</strong> 问题，可引入其他列值+时间做分区</p>
<p align="center">
  <img src="/2023/09/21/ddia/48.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 按照范围分区，可以手动调整分区范围，使得分区尽量均衡</span>
</p>
<p>2️⃣ 散列<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>分区。散列分区可以很好的处理热点问题，弊端是查询能力无法保证，因为曾经相邻的密钥分散在所有分区中，这意味着如果执行范围查询，则该查询将被发送到所有分区中</p>
<p align="center">
  <img src="/2023/09/21/ddia/49.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 哈希的方式处理热点问题 </span>
</p>
改进的办法是多个列组成的复合主键，键中只有第一列会作为散列的依据，而其他列则被用作SSTables中排序数据的索引，此时如果第一列（如`user_id`）已经指定了固定值，则可以对该键的其他列（`timestamp`）执行有效的范围扫描。例如，在社交媒体网站上，一个用户可能会发布很多更新。若更新的主键被选择为`(user_id, update_timestamp)`，那么可以有效地检索，特定用户在某个时间间隔内按时间戳排序的所有更新。Casssandra使用了这种优化方式
<blockquote></blockquote>
<h2 id="分区和二级索引">分区和二级索引</h2>
<p>上文中我们讨论了 &lt;键值数据模型&gt; 的分区方案，次级索引是关系型数据库/文档型数据库的基础，也是<code>Solr</code>和<code>ElasticSearch</code>等搜索服务器的基石，次级索引由于不具备主键唯一的特性，导致我们并不能整齐的映射到各自的分区，有2种用二级索引对数据进行分区的方法：</p>
<p>🅰️ 基于文档的分区(docment-based)，如下图在汽车表/文档上建立颜色和厂商的次级索引，这种索引方法中，<strong>每个分区是完全独立，每个分区维护自己的次级索引</strong>，因此，文档分区索引也叫做本地索引(local index)。在执行特定的颜色的搜索(look for red)的时候，需要将查询发送到所有分区，并合并所有返回的结果。故，这种分区查询数据库的方式有时被称为<strong>分散/聚集(scatter/gather)</strong>，这种基于二级索引上的查询可能会相当昂贵</p>
<p align="center">
  <img src="/2023/09/21/ddia/50.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 基于文档的二级索引分区 </span>
</p>
<p>🅱️ 基于关键词(term-based)的分区，对所有分区的数据构建全局索引的同时，对全局索引进行分区。这种索引称为<strong>关键词分区(term-partitioned)</strong> <sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>，关键词分区的全局索引的优势在于不需要<strong>分散/收集</strong>所有分区，客户端只需要向包含关键词的分区发出请求。全局索引的缺点在于写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区。在实践中，全局二级索引的更新通常是<strong>异步</strong>的</p>
<blockquote>
<p>(在任何时候)使用关键词本身进行分区适用于范围扫描，而对关键词的哈希分区提供更好的负载均衡能力</p>
</blockquote>
<p align="center">
  <img src="/2023/09/21/ddia/51.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 基于关键词的二级索引分区 </span>
</p>
<blockquote></blockquote>
<h2 id="分区再平衡">分区再平衡</h2>
<p>将负载(数据存储和读写请求)从集群中的一个节点，向另一个节点移动的过程称为<strong>再平衡(reblancing)</strong>，再平衡应该满足一下几个要求：</p>
<ol>
<li class="lvl-3">
<p>再平衡之后，负载(数据存储，读取和写入请求)应该，在集群中的节点之间公平地共享</p>
</li>
<li class="lvl-3">
<p>再平衡发生时，数据库应该继续接受读取和写入</p>
</li>
<li class="lvl-3">
<p>节点之间只移动必须的数据<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>，以便快速再平衡，并减少网络和磁盘I/O负载</p>
</li>
</ol>
<blockquote></blockquote>
<p>相应的，我们有三种分区方式，来进行处理</p>
<p>1️⃣ 固定数量的分区，创建比节点更多的分区，并为每个节点分配多个分区，如果一个节点被添加到集群中，新节点可以从当前每个节点中<strong>窃取</strong>一些分区，直到分区再次公平分配，如下图。Riak，Elasticsearch使用了这种再平衡的分区方式</p>
<p align="center">
  <img src="/2023/09/21/ddia/52.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 新节点从旧节点中窃取一些分区 </span>
</p>
<p>2️⃣ 动态分区，当分区增长到超过配置的大小时(在HBase上，默认值是10GB)，会被分成两个分区，每个分区约占一半的数据，反之进行合并，类似B树的页分裂/合并的过程</p>
<p>3️⃣ 分区数与节点数成正比，节点数量不变时，每个分区的大小与数据集大小成比例地增长，节点数增加时，分区数也增加，分区数据变少</p>
<h2 id="请求路由">请求路由</h2>
<p>数据集已经分割到多个机器上运行的多个节点上，那么当客户想要发出请求时，如何知道要连接哪个节点呢？即请求应该路由给谁？这个问题也可以概括为<strong>服务发现(service discovery)</strong>，有目前以下三种方案：</p>
<p>1️⃣ 允许客户联系任何节点(例如，通过<strong>循环策略的负载均衡(Round-Robin Load Balancer)</strong>)。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求，否则，它将请求转发到适当的节点，接收回复并传递给客户端</p>
<p>2️⃣ 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求，它仅负责分区的负载均衡</p>
<p>3️⃣ 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介</p>
<p align="center">
  <img src="/2023/09/21/ddia/53.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 客户端连接到分区的3种方式 </span>
</p>
<p>以上三种方式都会面临一个问题：作出路由决策的组件(节点之一/路由层/客户端)，如何了解分区-节点之间的分配关系变化？许多分布式数据系统都依赖于一个独立的协调服务(如ZooKeeper)来跟踪集群元数据，每个节点在ZooKeeper中注册自己，ZooKeeper维护分区到节点的可靠映射</p>
<p>其他参与者(如路由层或分区感知客户端)可以在ZooKeeper中订阅此信息。 只要分区分配发生的改变，或者集群中添加或删除了一个节点，ZooKeeper就会通知路由层使路由信息保持最新状态。HBase，SolrCloud和Kafka，使用ZooKeeper来跟踪分区分配</p>
<p>MongoDB具有类似的体系结构，但它依赖于自己的<strong>配置服务器（config server）</strong> 实现和mongos守护进程作为路由层</p>
<p align="center">
  <img src="/2023/09/21/ddia/56.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 路由层如何感知分区和节点之间的关系 </span>
</p>
<h1>第7章节-事务</h1>
<h2 id="事务的起源">事务的起源</h2>
<p>很早就接触事务这个概念，关于事务网上的文章动不动就把转账的的例子拿出来讲，坑的时候有的压根就没有讲明白，事务的概念<strong>事务要不就执行成功，要不执行失败，只有这2种状态</strong>也背的烂熟，也知道事务的4大特性ACID (原子性、一致性、隔离性、持久性)，但是这么些年从来没有思考过：为什么要有事务？他解决了什么样子的问题/痛点？那么我们带着这个问题来回顾一下事务起源：</p>
<p align="center">
  <img src="/2023/09/21/ddia/36.jpg" width="90%" alt="Your image description">
    <br>
  <span style="color:gray"> 事务的起源 </span>
</p>
<p>上图中有一个名为猪小明的程序员，抱着电脑正在疯狂的写代码(开发应用程序)，其中应用程序需要透过网络在数据库中存放数据/获取数据，数据库软件依托于是操作系统，操作系统的底层是一些计算机硬件(存储介质/磁盘/缓存/Cache/RAM /ROM/CPU/主板等)。整个过程中，各个环节都有可能出错，比如：</p>
<p>1️⃣ 网络中断，客户端和应用程序服务之间，服务和数据库之间</p>
<p>2️⃣ 数据库软件本身挂掉了，硬件发生故障<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup></p>
<blockquote></blockquote>
<p>3️⃣ 应用程序在进行写入的时候，写到一半，自己崩溃了</p>
<p>4️⃣ 多个客户端同时操作数据库，覆盖彼此的更新</p>
<p>5️⃣ 客户写到一半的数据，被另外一个客户读取到</p>
<p>6️⃣ 客户之间的竞争导致的令人惊讶的错误</p>
<p>所有的这一些都需要应用程序的开发者，猪小明去解决，但是这个工作量是巨大的，应用开发应该专注于业务，而不是通用问题的处理，这些问题应该留给下层的数据库去处理。所以为了<strong>简化应用编程模型</strong> ，事务诞生了。通过使用事务，应用程序可以自由地忽略某些潜在的错误情况和并发问题，因为数据库会替应用处理好这些问题</p>
<p>1974年的时候，IBM的圣荷西研究中心发布了，第一款提供优秀的事务处理能力的关系型数据库R[seminal-project]。时至今日开发者已经习惯了事务，他们觉得事务是理所当然的，是天然就存在的，然而并不是，了解事务出现的历史，我们可以发现事务是我们的计算机先驱们为了解决一揽子问题，提供的一种解决方案</p>
<h2 id="ACID">ACID</h2>
<p>谈及事务，必谈事务的4大特性ACID；那么ACID 分别指的是什么？</p>
<p><em><strong>A</strong>tomicity</em> ： 原子性。<strong>能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力</strong>，可以理解为<strong>可终止性</strong>。假设没有原子性，如果有多次更改，但是更改发生过程中发生了错误，应用程序很难判断哪些更改生效了，哪些没有生效。如果有了原子性，应用程序可以确定的知道在发生错误时，所有更改没有生效。<strong>没有原子性，错误处理就会变的很复杂</strong></p>
<blockquote>
<p>区别于线程的原子操作：多线程中的原子操作描述的是，如果一个线程执行一个原子操作，意味着另外一个线程无法看到该原子操作的中间结果。而这个特性在ACID中是 <em>I(isolation)</em> 来描述的</p>
</blockquote>
<p><em><strong>C</strong>onsistency</em>：一致性。在事务中，一致性是指：<strong>对数据的一组特定陈述必须始终成立</strong>，即为<em>不变量</em>，如在会计系统中，所有账户整体上必须借贷相抵，转账过程中，加钱和减钱是相等的。原子性，隔离性和持久性是数据库的属性，而一致性(在ACID意义上)是应用程序的属性</p>
<blockquote>
<p>这是一个一词多意的词，用行话来说，这个词被重载了</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>有别于副本一致性，比如在单主复制的模式下，采用异步复制的方式，收敛最终一致</p>
</li>
<li class="lvl-2">
<p>还有大家有可能会听过一致性hash(一致性散列)那是一种为了避免重新分区带来的复杂度提高的一种解决方案</p>
</li>
<li class="lvl-2">
<p>CAP定理中，C指的是线性一致性</p>
</li>
</ul>
</blockquote>
<p><em><strong>I</strong>solation</em>：隔离性。<strong>竞争条件下，同时执行的事务是相互隔离的</strong>，下图是两个客户之间的竞争状态同时递增计数器的图述。<strong>缺乏隔离性，就会导致并发问题</strong></p>
<p align="center">
  <img src="/2023/09/21/ddia/02.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 两个客户之间的竞争状态同时递增计数器 </span>
</p>
<p><em><strong>D</strong>urability</em> ：持久性。持久性是事务的一个承诺，也即事务完成后，即便发生硬件故障或者数据库崩溃，写入的任务数据也不会丢失。持久性过去一般被认为写入了非易失性存储介质</p>
<h2 id="单对象操作和多对象操作">单对象操作和多对象操作</h2>
<p><strong>单一对象操作</strong>，所谓单对象操作中的对象，指的是数据库中被修改的对象，比如你正在向数据库写入一个20KB的Json文档，以下场景可能会发生：</p>
<p>1️⃣ 在发送第一个10KB之后，网络连接中断，数据库是否存储了不可解析的10KBJSON片段？</p>
<p>2️⃣ 在数据库正在覆盖的磁盘上前一个值的过程中电源发生故障，是否最终将新旧值拼接在一起？</p>
<p>3️⃣ 如果另一个客户端在写入过程中读取该文档，是否会看到部分更新？</p>
<p>这里的 JSON对象，就是单一对象，单一对象是相对于多对象而言的，待会我们会谈及到多对象。为了针对以上的问题，存储引擎会在单个对象上提供原子性和隔离性，如此一来：</p>
<p>🅰️ 原子性通过WAL(即redo-log)日志来实现崩溃恢复</p>
<p>🅱️ 使用每个对象的锁来实现隔离(每次仅仅允许一个线程访问对象)</p>
<p>除了单对象操作，还有就是CAS(Compare-and-set)，防止多个客户端同时写入同一个对象时的更新丢失，即当值没有并发被其他人修改的时候，才允许执行写入操作。CAS操作和单对象操作，被称作是轻量级事务。<strong>事务通常更多的强调 ： 将多个对象的多个操作合并为一个执行的单元的机制</strong></p>
<p><strong>何为多对象？</strong> 在操作数据库时，需要协调写入几个不同的对象：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>关系模型中，一个表中的行对另外一个表的外键引用。你得确保外键是最新的，可用的</p>
</li>
<li class="lvl-2">
<p>在字段冗余的场景中，单个字段在多处被存储，你得保证这几处是同步的</p>
</li>
<li class="lvl-2">
<p>二级索引的数据库中，数据更新的时候，二级索引也需要更新</p>
</li>
</ul>
<p>在这种情形下，需要使用事务来进行处理</p>
<p>接下来我们会讲述隔离级别，在讲述隔离级别之前，明确两点：</p>
<p>🅰️ 隔离级别是对事务的4大特性之一隔离性上进行了一个等级划分，数据库标准的事务隔离级别包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>读未提交(read uncommitted)</p>
</li>
<li class="lvl-2">
<p>读已提交(read committed)</p>
</li>
<li class="lvl-2">
<p>可重复读/快照隔离(repeatable read)</p>
</li>
<li class="lvl-2">
<p>串行化(serializable)</p>
</li>
</ul>
<p>🅱️ 隔离级别最高是可序列化，表示同一时间只能有一个事务。隔离级别和性能之间是一个负相关的关系，也就是说隔离级别越高，数据一致性的保证越好，但是性能越差。隔离级别是数据一致性和服务性能的一场博弈。为了实现更优的性能，我们需要较弱的隔离级别</p>
<p>下面介绍这些弱隔离级别</p>
<h2 id="读已提交">读已提交</h2>
<p>最基本的弱隔离级别是，读已提交，它提供了两个保证：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>没有<strong>脏读(dirty reads)</strong>，从数据库读时，只能看到已提交的数据</p>
</li>
<li class="lvl-2">
<p>没有<strong>脏写(dirty writes)</strong>，写入数据库时，只会覆盖已经写入的数据</p>
</li>
</ul>
<p>另外读未提交：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>可以防止脏写</p>
</li>
<li class="lvl-2">
<p>但是不能够防止脏读</p>
</li>
</ul>
<p>下图是一个没有脏读的例子：可以看到<em>直到用户1提交了之后</em>，用户2才看到提交之后的值x=3,而在这之前用户1只能看到x=2</p>
<p align="center">
  <img src="/2023/09/21/ddia/03.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 用户2只有在用户1的事务已经提交后才能看到x的新值 </span>
</p>
<p>那么为什么要防止脏读呢？主要是下面两个原因：</p>
<p>1️⃣ 如果事务需要更新多个对象，脏读取意味着另一个事务可能会只看到一部分更新。比如说下面这个电子邮件的例子。事务还没有提交，但是用户2看到了未读邮件，可是未读邮件的数量却还是旧值</p>
<p align="center">
  <img src="/2023/09/21/ddia/04.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 一个事务读取另一个事务的未被执行的写入（“脏读”） </span>
</p>
<p>2️⃣ 若数据库允许脏读，意味着一个事务可能会看到稍后需要回滚的数据，即从未实际提交给数据库的数据。比如下面的例子中读到了未提交的数据，但是后面事务回滚了</p>
<p align="center">
  <img src="/2023/09/21/ddia/05.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 原子性确保发生错误时，事务先前的任何写入都会被撤消，以避免状态不一致 </span>
</p>
<p>两个事务同时更新数据库中的对象，先前的写入没有提交，后面的写入覆盖这个尚未提交的值，这就是脏写。没有脏写，意味着在写入数据库时，只会覆盖已经写入的数据。在<strong>读已提交</strong>的隔离级别上运行的事务必须防止脏写，通常是延迟第二次写入，直到第一次写入事务提交或中止为止。下图是脏写发生的示例，发票属于Alice; 销售属于Bob’</p>
<p align="center">
  <img src="/2023/09/21/ddia/06.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 如果存在脏写，来自不同事务的冲突写入可能会混淆在一起 </span>
</p>
<h2 id="实现读已提交">实现读已提交</h2>
<p>读已提交是一种非常Fashion的一个隔离级别，有很多数据库软件将读已提交设置为默认的隔离级别，比如Oracle 11、PostgreSQL、SQLServer 2012 ，那么如何实现</p>
<p>1️⃣ 无脏写保证：数据库通过使用 <strong>行锁(row-level lock)<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup></strong> 来防止脏写；即当事务想要修改特定对象时，必须获取该对象的锁，然后必须持有该锁，直到事务被提交或终止。这种锁定是读已提交模式（或更强的隔离级别）的数据库自动完成的</p>
<blockquote></blockquote>
<p>2️⃣ 无脏读保证：MVCC<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup> ，数据库都会记住旧的已提交值，和当前持有写入锁的事务设置的新值。 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值</p>
<blockquote>
<p align="center">
  <img src="/2023/09/21/ddia/07.png" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 一个值从1按顺序修改为4的过程。在读已提交的隔离级别下，仅仅保留为提交版本和提交前版本2个版本 </span>
</p>
</blockquote>
<p>读已提交的隔离级别无法避免<em>不可重复读</em>的情况，下面的例子：爱丽丝在银行有1000美元的储蓄，两个账户，每个500美元；现在一个事务从她的一个账户中，转移了100美元到另一个账户</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Alice在转账事务之前查询了账户1的金额为500元</p>
</li>
<li class="lvl-2">
<p>Alice在转账之后完成之后，查询了账户2的金额为400元</p>
</li>
<li class="lvl-2">
<p>此时账户的总额为900元，Alice就很疑惑为什么自己的钱少了？</p>
</li>
</ul>
<p align="center">
  <img src="/2023/09/21/ddia/07.jpg" width="75%" alt="Your image description">
    <br>
  <span style="color:gray">读取偏差：Alice观察数据库处于不一致的状态 </span>
</p> 
<p>这种，这种异常被称为<strong>不可重复读(nonrepeatable read)</strong>，如果Alice在事务结束时再次读取账户1的余额，她将看到与她之前的查询中看到的不同的值(600美元)。在读已提交的隔离条件下，<strong>不可重复读</strong>可能会发生</p>
<h2 id="实现快照隔离">实现快照隔离</h2>
<p>快照隔离的另外一个叫法是可重复读，快照隔离和读已提交一致，使用写锁来防止脏写，也就是正在进行写入的事务会阻止另外一个事务修改同一个对象。读取没有任何的锁定，<strong>写不阻塞读，读不阻塞写</strong>，RC下也是，数据库使用<strong>多版本并发控制(MVCC, multi-version concurrentcy control)</strong> 数据库保留一个对象的几个不同的提交版本。另外使用MVCC实现快照隔离的存储引擎通常也会使用MVCC来实现读已提交(一个对象的两个版本：提交的版本和被覆盖但尚未提交的版本)</p>
<p align="center">
  <img src="/2023/09/21/ddia/08.jpg" width="75%" alt="Your image description">
    <br>
  <span style="color:gray">  使用多版本对象实现快照隔离 </span>
</p>
<p>那么我们再来看一下<em>一致性快照的可见性规则</em>：也就是说当一个事务从数据库中读取时，事务ID用于决定它可以看见哪些对象，看不见哪些对象。规则如下：</p>
<p>1️⃣ 在每次事务开始时，数据库列出当时所有其他(尚未提交或中止)的事务清单，即使之后提交了，这些事务的写入也都会被忽略</p>
<p>2️⃣ 被中止事务所执行的任何写入都将被忽略</p>
<p>3️⃣ 由具有较晚事务ID(即，在当前事务开始之后开始的)的事务所做的任何写入都被忽略，而不管这些事务是否已经提交</p>
<p>4️⃣ 所有其他写入，对应用都是可见的</p>
<p>更简单的讲，对于隔离级别的实现数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准</p>
<p>1️⃣ “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念</p>
<p>2️⃣ 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的</p>
<p>3️⃣ 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图</p>
<p>4️⃣ “串行化”隔离级别下直接用加锁的方式来避免并行访问</p>
<h2 id="丢失更新">丢失更新</h2>
<p>前面描述的是读-写并发场景下，只读事务在并发写入时候能看到什么，另外一个问题是两个事务并发写入的问题，即写-写冲突。如下图就是<strong>丢失更新</strong>的例子</p>
<p align="center">
  <img src="/2023/09/21/ddia/02.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> 丢失更新：两个客户之间的竞争状态同时递增计数器 </span>
</p>
<p>解决写-写冲突有很多方式，比如原子写（数据库提供），显示锁定，比较并设置(CAS)</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">-- 数据库提供原子更新操作，消除在应用程序代码中执行读取-修改-写入序列的需要</span></span><br><span class="line"><span class="keyword">update</span> counters <span class="keyword">set</span> <span class="keyword">value</span> <span class="operator">=</span> <span class="keyword">value</span> <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> key <span class="operator">=</span> <span class="string">'foo'</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 显示锁定</span></span><br><span class="line"><span class="keyword">begin</span> transaction;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> figures</span><br><span class="line">    <span class="keyword">where</span> name <span class="operator">=</span> <span class="string">'robot'</span> <span class="keyword">and</span> game_id <span class="operator">=</span> <span class="number">222</span></span><br><span class="line"><span class="keyword">for</span> <span class="keyword">update</span>; <span class="comment">-- `for update` 子句告诉数据库应该对该查询返回的所有行加锁</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 检查玩家的操作是否有效，然后更新先前select返回棋子的位置</span></span><br><span class="line"><span class="keyword">update</span> figures <span class="keyword">set</span> position <span class="operator">=</span> <span class="string">'c4'</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1234</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 设置(CAS)</span></span><br><span class="line"><span class="keyword">update</span> wiki_pages <span class="keyword">set</span> content <span class="operator">=</span> <span class="string">'新内容'</span></span><br><span class="line">  <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1234</span> <span class="keyword">and</span> content <span class="operator">=</span> <span class="string">'旧内容'</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>在MySQL中，使用当前读<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup>的方式来处理写-写冲突，下图为RR隔离级别下，写-写冲突的例子</p>
<blockquote></blockquote>
<p align="center">
  <img src="/2023/09/21/ddia/10.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray">  </span>
</p>
<h2 id="写偏差">写偏差</h2>
<p>如果两个事务读取相同的对象，然后不同的事务可能更新不同的对象，则可能发生写偏差(写偏差包含丢失更新)</p>
<p>下面是写偏差的例子，描述的是一个医生轮班管理程序，医院有以下的要求：至少有一位医生在待命，现在Alice 和 Bob 两位值班医生都感觉到不适，决定请假：</p>
<p align="center">
  <img src="/2023/09/21/ddia/09.jpg" width="75%" alt="Your image description">
    <br>
  <span style="color:gray"> 写入偏差导致应用程序错误的示例 </span>
</p>
<p>在多个事务更新同一个对象的特殊情况下，就会发生脏写或丢失更新(取决于时机) <strong>防止写偏差，需要使用序列化隔离级别</strong></p>
<h2 id="幻读">幻读</h2>
<p><strong>一个事务中的写入改变另一个事务的搜索查询的结果，称为幻读</strong></p>
<p>下图是一个幻读的例子：</p>
<blockquote>
<p>幻读会导致写偏差。快照隔离避免了只读事务中的幻读，但是无法避免读写事务中的幻读。从上面的例子来看，幻读的问题貌似是没有对象可以加锁。人为的引入锁对象的方式被称之为<em>物化冲突</em></p>
</blockquote>
<p align="center">
  <img src="/2023/09/21/ddia/11.jpg" width="75%" alt="Your image description">
    <br>
  <span style="color:gray"> 干扰事务 干扰 主事务的执行 </span>
</p>
<p>🅰️ 主事务，检测表中是否有<code>id=1</code>的记录，没有则插入（<code>for update</code> 没有用，因为没有加锁对象），这是我们期望的正常业务逻辑</p>
<p>🅱️ 干扰事务，目的在于扰乱，主事务的正常的事务执行</p>
<p>我们看到，干扰事务率先执行了，主事务发生了幻读，因为主事务读取的状态并不能支持它的下一步逻辑，感觉看到了幻影。上例中是干扰事务妨碍了主事务搜索结果。在MySQL中，使用间隙锁（下文会涉及到）来处理幻读问题。<em>不可重复读侧重表达读-读，幻读则是说读-写，用写来证实读的是鬼影</em></p>
<h2 id="序列化-串行化">序列化/串行化</h2>
<p>对串行化的理解应当是这样的：一次只执行一个事务。设计单线程的系统有时候比支持并发的系统更好，因为它可以避免协调锁的开销。数据库的早期，数据库意图包含整个用户的活动流程，但是如今的web应用，一个事务不会跨越多个请求，事务会在同一个HTTP请求被提交</p>
<h3 id="两阶段锁定-2PL">两阶段锁定-2PL</h3>
<p>30年以来，数据库中只有一种广泛使用的序列化算法：<strong>两阶段锁定(2PL，two-phase locking)</strong>。两阶段这个名字的来源：第1阶段（当事务正在执行时）获取锁，第2阶段(在事务结束时)释放所有的锁</p>
<p>2PL要求只要没有写入，就允许多个事务同时读取同一个对象。但对象只要有写入(修改或删除)，就需要<strong>独占访问(exclusive access)</strong> 权限。锁可以处于<em>共享模式</em>，可以处于<em>独占模式</em>：</p>
<p>1️⃣ 若事务要读取对象，则须先以共享模式获取锁。允许多个事务同时持有共享锁。但如果另一个事务已经在对象上持有排它锁，则这些事务必须等待</p>
<p>2️⃣ 若事务要写入一个对象，它必须首先以独占模式获取该锁。没有其他事务可以同时持有锁(无论是共享模式还是独占模式)，所以如果对象上存在任何锁，该事务必须等待</p>
<p>3️⃣ 如果事务先读取再写入对象，则它可能会将其共享锁升级为独占锁。升级锁的工作与直接获得排他锁相同</p>
<p>4️⃣ 事务获得锁之后，必须继续持有锁直到事务结束（提交或中止）</p>
<p>由于加了这么多的锁，可能会发生死锁情况，死锁及死锁检测的内容可以看看MySQL的笔记</p>
<p>在Java中有这么一个定律：对象（Object）就是锁，前面内容涉及到的锁都是针对特定对象的(如表中的一行)，对于某些更改没有特定对象，有没有一种锁针对这种场景呢？</p>
<h3 id="谓词锁">谓词锁</h3>
<p>谓词锁类似于共享/排它锁，但不属于特定的对象（例如，表中的一行），它属于所有符合某些搜索条件的对象，如：</p>
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> bookings</span><br><span class="line"><span class="keyword">where</span> room_id <span class="operator">=</span> <span class="number">123</span> <span class="keyword">and</span></span><br><span class="line">      end_time <span class="operator">&gt;</span> <span class="string">'2018-01-01 12:00'</span> <span class="keyword">and</span> </span><br><span class="line">      start_time <span class="operator">&lt;</span> <span class="string">'2018-01-01 13:00'</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>谓词锁限制访问：</p>
<p>🅰️ 如果事务A想要，<strong>读取</strong>匹配某些条件的对象，就像在这个 <code>select</code> 查询中那样，它必须获取查询条件上的<strong>共享谓词锁(shared-mode predicate lock)</strong>。如果另一个事务B，持有任何满足这一查询条件对象的排它锁，事务A必须等到B释放它的锁之后才允许进行查询</p>
<p>🅱️ 如果事务A想要，<strong>插入，更新或删除</strong>任何对象，则必须首先检查旧值或新值，是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B已经提交或中止后才能继续</p>
<p>谓词锁的关键思想是，<strong>谓词锁甚至适用于数据库中尚不存在，但将来可能会添加的对象（幻象）</strong>。和快照隔离的区别在是：快照隔离中读不阻塞写，写不阻塞读；2PL中，写阻塞读，读阻塞写</p>
<h3 id="索引范围锁">索引范围锁</h3>
<p>索引范围锁，也称为<strong>间隙锁(next-key locking)</strong></p>
<p>谓词锁的弊端是性能不佳：<strong>如果活跃事务持有很多锁，检查匹配的锁会非常耗时</strong>。因此，大多数使用2PL的数据库实际上实现了索引范围锁，间隙锁是一种简化的近似版谓词锁</p>
<p>比如在房间预订数据库中，您可能会在<code>room_id</code>列上有一个索引，并且/或者在<code>start_time</code> 和 <code>end_time</code>上有索引（否则前面的查询在大型数据库上的速度会非常慢</p>
<p>🅰️ 假设您的索引位于<code>room_id</code>上，并且数据库使用此索引查找<code>123</code>号房间的现有预订。现在数据库可以简单地将共享锁附加到这个索引项上，指示事务已搜索<code>123</code>号房间用于预订</p>
<p>🅱️ 或者，如果数据库使用基于时间的索引来查找现有预订，那么它可以将共享锁附加到该索引中的一系列值，指示事务已经将<code>12:00~13:00</code> 时间段标记为用于预定</p>
<p>无论哪种方式，搜索条件的近似值都附加到其中一个索引上。现在，如果另一个事务想要插入，更新或删除同一个房间和/或重叠时间段的预订，则它将不得不更新索引的相同部分。在这样做的过程中，它会遇到共享锁，它将被迫等到锁被释放。这种方法能够有效防止幻读和写入偏差</p>
<h2 id="序列化快照隔离（SSI）">序列化快照隔离（SSI）</h2>
<p><strong>可序列化快照隔离(SSI, serializable snapshot isolation)</strong> 它提供了完整的可序列化隔离级别，但与快照隔离相比只有只有很小的性能损失，是一种新的隔离技术</p>
<h2 id="总结-2">总结</h2>
<p>1️⃣ 脏读: 一个客户端读取到另一个客户端尚未提交的写入。<strong>读已提交</strong>或更强的隔离级别可以防止脏读</p>
<p>2️⃣ 脏写: 一个客户端覆盖写入了另一个客户端尚未提交的写入。几乎所有的事务实现都可以防止脏写</p>
<p>3️⃣ 读取偏差(不可重复读): 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。<strong>快照隔离</strong>经常用于解决这个问题，它允许事务，从一个特定时间点的一致性快照中读取数据。快照隔离通常使用<strong>多版本并发控制(MVCC)</strong> 来实现</p>
<p>4️⃣ 更新丢失: 两个客户端同时执行<strong>读取-修改-写入序列</strong>。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定(<code>select for update</code>)</p>
<blockquote>
<p>和脏写的区别在于：脏写是覆盖尚未提交的写入，更新丢失是覆盖了一个已提交的写入</p>
</blockquote>
<p>5️⃣ 写偏差: 一个事务读取一些东西，根据它所看到的值作出决定，并将决定写入数据库。但是，写的时候，决定的前提不再是真实的。只有可序列化的隔离才能防止这种异常</p>
<p>6️⃣ 幻读 : 事务读取符合某些搜索条件的对象，另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入歪斜环境中的幻读需要特殊处理，例如索引范围锁定。只有可序列化的隔离才能防范所有这些问题。我们讨论了实现可序列化事务的三种不同方法：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>字面意义上的串行执行: 如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个CPU核上处理，这是一个简单而有效的选择</p>
</li>
<li class="lvl-2">
<p>两阶段锁定: 数十年来，两阶段锁定一直是实现可序列化的标准方式，但是许多应用出于性能问题的考虑避免使用它</p>
</li>
<li class="lvl-2">
<p><strong>可串行化快照隔离(SSI)</strong></p>
</li>
</ul>
<h1>第9章节-一致性与共识</h1>
<p>构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。比如通过使用<strong>事务</strong>这个抽象，应用可以假装没有崩溃(原子性)，没有其他人同时访问数据库(隔离性)，存储设备是完全可靠的(持久性)。即使发生崩溃，竞态条件和磁盘故障，事务抽象隐藏了这些问题，因此应用不必担心它们</p>
<p>同样的分布式系统最重要的抽象之一就是<strong>共识(consensus)</strong>：<strong>其非正式定义是让所有的节点对某件事达成一致</strong></p>
<blockquote>
<p>分布式一致性模型和事务的特性ACID中的一致性 ，隔离级别的区别❓</p>
<p>ACID一致性的概念是，<strong>对数据的一组特定陈述必须始终成立</strong>。即<strong>不变量(invariants)</strong></p>
<p>分布式一致性主要是关于：面对延迟和故障时，如何协调副本间的状态</p>
<p>事务隔离的目的是为了，避免由于同时执行事务而导致的竞争状态</p>
</blockquote>
<h2 id="线性一致性">线性一致性</h2>
<p>多数的数据库提供了最终一致性的保证(数据是最终收敛的)。最终一致性的问题是：如果你在同一个时刻问2个副本同样一个问题，可能得到不同的答案，<strong>线性一致性</strong>尝试提供只有一个副本的假象，即提供新鲜度保证(一个客户端完成写操作，所有client可以必须能看到最新的答案)</p>
<blockquote>
<p>线性一致性和可序列化的区别❓</p>
<p>可序列化是事务的隔离性，它确保事务的执行是特定的顺序</p>
<p>线性一致性是读取和写入寄存器(单个对象)的新鲜度保证，它不会将多个操作组合为事务</p>
<p>一个数据库可以提供可串行性和线性一致性，这种组合称之为，单副本强可串行性(strong-1SR)，基于2阶段锁的可串行化实现，通常是线性一致的，可重复读不是线性一致的</p>
</blockquote>
<h3 id="线性一致性的作用">线性一致性的作用</h3>
<p>🅰️ 单主复制的系统中，领导选取(只有一个节点持有锁)</p>
<p>🅱️ 唯一性约束(只有一个对象持有该id)</p>
<h3 id="实现线性一致的系统">实现线性一致的系统</h3>
<p>1️⃣ 单主复制：可能线性一致</p>
<p>2️⃣ 共识算法：线性一致</p>
<p>3️⃣ 多主复制：非线性一致</p>
<h2 id="CAP">CAP</h2>
<p>有一种说法是： 一致性、可用性、分区容错性，三者只能选择其二，这种说法有一定的误导性。这里的<em>P</em>指的是网络分区<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>，网络分区是一种故障，是一定会(概率事件)存在的，P不是一个可选项而是一个必选项，那么就有了</p>
<p>🅰️ CP : 在网络分区下一致但不可用 。若应用需要线性一致性，某些副本和其他副本断开连接，那么这些副本掉线时不能处理请求(单主复制+同步)，请求必须等到网络问题解决，或直接返回错误。无论哪种方式，服务都<strong>不可用(unavailable)</strong></p>
<p>🅱️ AP : 在网络分区下可用但不一致 。应用不需要线性一致性，那么某个副本即使与其他副本断开连接，也可以独立处理请求（例如多主复制）。在这种情况下，应用可以在网络问题前保持可用，但其行为不是线性一致的</p>
<blockquote></blockquote>
<h2 id="全序-vs-偏序">全序 vs 偏序</h2>
<h3 id="因果顺序不是全序的">因果顺序不是全序的</h3>
<p>自然数集是全序的，如1,2,3；数学集合是偏序的，比如<code>{a,b}</code>  和 <code>{b,c}</code> 是没有办法比较大小的。线性一致是全序的，不存在任何并发，所有的操作在一条时间线上。而因果关系是偏序的，存在着并发，线性一致性强于因果一致性，但是性能不如因果一致性</p>
<h3 id="序列号顺序">序列号顺序</h3>
<p>显示跟踪所有已读数据确保因果关系意味着巨大的额外开销，可以使用序列号或时间戳来排序事件，时间戳并不一定来自时钟，可以是一个逻辑时钟(自增计数器)，单主复制的数据库中，主库为每个操作自增一个计数器，从库按照复制日志的顺序来应用写操作，那么从库的状态始终是因果一致的</p>
<h3 id="非因果序列号生成器">非因果序列号生成器</h3>
<p>对于无主复制或者多主复制，如何生成序列号呢？有下面三种方式：</p>
<p>1️⃣ 每个节点生成自己独立的一组序列号，如有2个节点，一个奇数一个偶数</p>
<p>2️⃣ 将物理时钟附加到每个操作上，也许可以提供一个全序关系</p>
<p>3️⃣ 预先分配序列区块号，如节点A是1-1000区块的所有权；节点B是1001-2000区块的所有权</p>
<p>三种共同的问题是：生成的序列号与因果关系不一致。兰伯特时间戳可以产生与因果关系一致的时间戳</p>
<h3 id="兰伯特时间戳">兰伯特时间戳</h3>
<p>(计数器，节点ID)$(counter, node ID)$ 组成<em>兰伯特</em>时间戳，每个节点和每个客户端跟踪迄今为止所见到的最大<strong>计数器</strong>值，并在每个请求中包含这个最大计数器值。当一个节点收到最大计数器值大于自身计数器值的请求或响应时，它立即将自己的计数器设置为这个最大值。下面2条规则去判断：</p>
<p>🅰️ 如果你有两个时间戳，则<strong>计数器</strong>值大者是更大的时间戳</p>
<p>🅱️  如果计数器值相同，则节点ID越大的，时间戳越大</p>
<p align="center">
  <img src="/2023/09/21/ddia/12.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>其中客户端 A 从节点2 接收计数器值 <code>5</code> ，然后将最大值 <code>5</code> 发送到节点1 。此时，节点1 的计数器仅为 <code>1</code> ，但是它立即前移至 <code>5</code> ，所以下一个操作的计数器的值为 <code>6</code> 。虽然兰伯特时间戳定义了一个与因果一致的全序，但它还不足以解决分布式系统中的许多常见问题，比如确保用户名能唯一标识用户帐户的系统，你得搜集所有相同用户名的兰伯特时间戳，才能比较他们的时间戳，节点无法马上决定当前请求失败还是成功。所以仅知道全序是不够的，还需要知道全序何时结束</p>
<h2 id="全序广播-原子广播">全序广播(原子广播)</h2>
<p>全序广播通常被描述为在节点间交换消息的协议。 非正式地讲，它要满足两个安全属性：</p>
<p>1️⃣ 可靠交付（reliable delivery）:  没有消息丢失：如果消息被传递到一个节点，它将被传递到所有节点</p>
<p>2️⃣ 全序交付（totally ordered delivery）:  消息以相同的顺序传递给每个节点</p>
<p>正确的全序广播算法必须始终保证可靠性和有序性，即使节点或网络出现故障。当然在网络中断的时候，消息是传不出去的，但是算法可以不断重试，以便在网络最终修复时，消息能及时通过并送达</p>
<p>可以使用全序广播来实现可序列化的事务，由于具备上述2个安全属性，数据库的分区和副本就可以相互保持一致。<em>节点得到了共识</em></p>
<blockquote>
<p>🅰️ <strong>全序广播等于共识</strong></p>
<p>🅱️ <strong>线性一致的CAS等于共识</strong></p>
</blockquote>
<h2 id="分布式事务与共识">分布式事务与共识</h2>
<p>共识的目标只是<strong>让几个节点达成一致(get serveral nodes to agree on something)</strong>。节点达成一致(共识)的应用场景：</p>
<p>🅰️ 领导选取：如在单主复制中，如果有2个以上领导就会有发生脑裂情况，脑裂时2主都会接收写入，导致数据不一致或数据丢失</p>
<p>🅱️ 原子提交：在跨多节点或跨多分区事务的数据库中，所有节点必须就：<em>一个事务是否成功</em>这件事达成一致(要不都成功；要不都失败)</p>
<p>2PC是一个最简单的共识算法，更好的一致性算法比如ZooKeeper(Zab)和etcd(Raft)中使用的算法</p>
<blockquote>
<p>区分普通事务和两种的不同的分布式事务</p>
<p>0️⃣ 普通事务是相对单个节点而言的多对象操作；而分布式事务涉及多个节点</p>
<p>1️⃣ 数据库内部的分布式事务， 一些分布式数据库(即在其标准配置中使用复制和分区的数据库)支持数据库节点之间的内部事务，比如MySQL Cluster的NDB存储引擎就有这样的内部事务支持。此情形下，所有参与事务的节点都运行相同的软件</p>
<p>2️⃣ 异构分布式事务：在异构事务中，参与者是2者或者以上的技术，比如来自不同供应商的2个数据库/消息代理，跨系统的分布式事务需要保证原子提交</p>
</blockquote>
<h2 id="原子提交和2PC">原子提交和2PC</h2>
<p>对于多对象事务及维护次级索引的数据库，原子提交可以防止失败的事务搅乱数据库，避免数据库陷入半成品结果和半更新状态；对于单对象的原子性一般时都由数据库(存储引擎)本身保证。 <strong>两阶段提交(two-phase commit)</strong> 是一种用于实现跨多个节点的原子事务提交的算法，即确保所有节点提交或所有节点中止</p>
<p align="center">
  <img src="/2023/09/21/ddia/13.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>2PC使用一个通常不会出现在单节点事务中的新组件：<strong>协调者(coordinator)</strong>（也称为<strong>事务管理器(transaction manager)</strong>）。2PC事务以应用在多个数据库节点(<strong>参与者(participants)</strong>)上读写数据开始。当应用准备提交时，协调者开始阶段1：它发送一个 <strong>准备(prepare)</strong> 请求到每个节点，询问它们是否能够提交，然后协调者会跟踪参与者的响应：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果所有参与者都回答“是”，表示它们已经准备好提交，那么协调者在阶段2发出 <strong>提交(commit)</strong> 请求，然后提交真正发生</p>
</li>
<li class="lvl-2">
<p>如果任意一个参与者回复了“否”，则协调者在阶段2 中向所有节点发送 <strong>中止(abort)</strong> 请求</p>
</li>
</ul>
<p>2PC具体的流程如下：</p>
<p>1️⃣ 当应用想要启动一个分布式事务时，它向协调者请求一个事务ID。此事务ID是全局唯一的</p>
<p>2️⃣ 应用在每个参与者上启动单节点事务，并在单节点事务上捎带上这个全局事务ID</p>
<p>3️⃣ 当应用准备提交时，协调者向所有参与者发送一个<strong>准备</strong>请求，并打上全局事务ID的标记。如果任意一个请求失败或超时，则协调者向所有参与者发送针对该事务ID的中止请求</p>
<p>4️⃣ 参与者收到准备请求时，需要确保在任意情况下都可以提交事务。这包括将所有事务数据写入磁盘(出现故障，电源故障，或硬盘空间不足都不能是稍后拒绝提交的理由)以及检查是否存在任何冲突或违反约束。通过向协调者回答“是”，节点承诺，只要请求，这个事务一定可以不出差错地提交。换句话说，<em>参与者放弃了中止事务的权利，但没有实际提交</em></p>
<p>5️⃣ 当协调者收到所有准备请求的答复时，会就提交或中止事务作出明确的决定(只有在所有参与者投赞成票的情况下才会提交)。协调者必须把这个决定写到磁盘上的事务日志中，如果它随后就崩溃，恢复后也能知道自己所做的决定。这被称为<strong>提交点(commit point)</strong></p>
<p>6️⃣一旦协调者的决定落盘，提交或放弃请求会发送给所有参与者。如果这个请求失败或超时，协调者必须永远保持重试，直到成功为止。没有回头路：如果已经做出决定，不管需要多少次重试它都必须被执行。如果参与者在此期间崩溃，事务将在其恢复后提交——由于参与者投了赞成，因此恢复后它不能拒绝提交</p>
<p>下图是MySQL的两阶段提交过程，该过程保证bin-log和redo-log一致</p>
<p align="center">
  <img src="/2023/09/21/ddia/03.png" width="55%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<h2 id="协调者失效">协调者失效</h2>
<p>上述第3️⃣步中很协调者发送“准备”请求之前失败，参与者可以安全的终止事务；在第5️⃣ 步中如果任何提交和终止请求失败，协调者将无条件重试，但是协调者崩溃，参与者就什么也做不了只能等待。参与者的这这种事务状态称为：<strong>存疑或者不确定</strong></p>
<p align="center">
  <img src="/2023/09/21/ddia/14.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>上图中：协调者实际上决定提交，数据库2收到提交请求，但是协调者在将提交请求发送到数据库1之前发生崩溃，因此数据库1不知道是否提交或中止。这里即便<strong>超时</strong>， 也是没用的：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果数据库1 在超时后单方面中止，它将最终与执行提交的数据库2 不一致</p>
</li>
<li class="lvl-2">
<p>单方面提交也是不安全的，因为另一个参与者可能已经中止了</p>
</li>
</ul>
<p>此时完成2PC的唯一方法是等待协调者恢复，因此，协调者必须在<em>向</em>参与者发送提交/中止请求之前，将其提交/中止决定写入磁盘上的事务日志，协调者恢复后，通过读取其事务日志来确定所有存疑事务的状态，任何在协调者日志中没有提交记录的事务都会中止</p>
<h2 id="恰好一次的消息处理">恰好一次的消息处理</h2>
<p>异构的分布式事务能够集成两种不同的系统，比如当用于处理消息的数据库事务成功提交后，消息队列中的一条消息可以被认为已处理。如果消息或者数据库事务任意一个失败，2者都会终止，而消息代理可能会在稍后安全的重传消息。通过这种方式，可以确保消息被有效地恰好处理一次</p>
<h2 id="XA事务">XA事务</h2>
<p>扩展架构(eXtended Architecture)是跨异构技术实现两阶段提交的标准。许多关系型数据库(PostgresSQL、MySQL、SQL Server、Oracle))和消息代理(ActiveMQ，HornetQ，MSMQ和IBM MQ)都支持XA</p>
<h2 id="容错共识">容错共识</h2>
<blockquote>
<p>共识的定义：一个或多个节点可以**提议(propose)<strong>某些值，而共识算法</strong>决定(decides)**采用其中的某个值</p>
<p>共识算法需要满足以下性质：</p>
<p>1️⃣ 一致同意：没有2个节点的决定不同</p>
<p>2️⃣ 完整性：没有节点决定2次</p>
<p>3️⃣ 有效性：如果一个节点决定了值<code>v</code>,则<code>v</code>由某个节点所提议</p>
<p>4️⃣ 终止 ： 由所有未崩溃的节点来最终决定值</p>
</blockquote>
<p>终止属性形成了容错的思想，该属性是一个活性属性，而另外三个是安全属性。如果不关心容错，仅仅满足前三个属性就OK，因为你可以将其中一个节点硬编码为leader，让该节点做出所有的决定，但是节点一旦失效，系统无法就无法做出决定了。比如2PC就能够满足，但是2PC的问题是，协调者失效，存疑的参与者无法决定是提交还是终止，故2PC不满足终止属性的要求</p>
<p>绝大多数共识算法实际上并不直接使用1️⃣2️⃣3️⃣4️⃣形式化模型，而是使用全序广播代为实现</p>
<h2 id="共识算法和全序广播">共识算法和全序广播</h2>
<p>最著名的容错共识算法是<strong>视图戳复制(VSR, viewstamped replication)</strong>，Paxos，Raft 以及 Zab。视图戳复制，Raft和Zab直接实现了全序广播，因为这样做比重复 <strong>一次一值(one value a time)</strong> 的共识更高效，因为全序广播的要求是：</p>
<blockquote>
<p>1️⃣ 可靠交付（reliable delivery）:  没有消息丢失：如果消息被传递到一个节点，它将被传递到所有节点</p>
<p>2️⃣ 全序交付（totally ordered delivery）:  消息以相同的顺序传递给每个节点</p>
</blockquote>
<p>可以发现，<strong>全序广播等于进行了重复多轮共识</strong></p>
<p>在单主复制中，将所有的写入操作都交给主库，并以相同的顺序将他们应用到从库，从而使副本保持在最新状态，这里其实是一种 <strong>“独裁类型”</strong> 的共识算法，领导者是运维指定的，一旦故障必须人为干预，它无法满足共识算法的终止属性</p>
<h2 id="时代编号和法定人数">时代编号和法定人数</h2>
<p>共识协议一般会定义1个<strong>时代编号(epoch number)</strong>，在Paxos中称为<strong>投票编号(ballot number)</strong>，视图戳复制中的<strong>视图编号(view number)</strong>，以及Raft中的<strong>任期号码(term number)</strong>，并确保在每个时代中，领导者都是唯一的。每次领导者被认为挂掉的时候，会产生全序且单调递增的新的时代编号，更高时代编号的领导才真的领导。节点在做出决定之前对提议进行投票的过程是一种同步复制，这是共识的局限性</p>
<h2 id="总结：">总结：</h2>
<p>很多问题都可以归结为共识问题，并且彼此等价(从这个意义上来讲，如果你有其中之一的解决方案，就可以轻易将它转换为其他问题的解决方案)。这些等价的问题包括：</p>
<p>1️⃣ <strong>线性一致性的CAS寄存器</strong>:  寄存器需要基于当前值是否等于操作给出的参数，原子地<strong>决定</strong>是否设置新值</p>
<p>2️⃣ <strong>原子事务提交</strong> :  数据库必须<strong>决定</strong>是否提交或中止分布式事务</p>
<p>3️⃣  <strong>全序广播</strong>:  消息系统必须<strong>决定</strong>传递消息的顺序</p>
<p>4️⃣ <strong>锁和租约</strong>:  当几个客户端争抢锁或租约时，由锁来<strong>决定</strong>哪个客户端成功获得锁</p>
<p>5️⃣ <strong>成员/协调服务</strong>: 给定某种故障检测器(例如超时)，系统必须<strong>决定</strong>哪些节点活着，哪些节点因为会话超时需要被宣告死亡</p>
<p>6️⃣ <strong>唯一性约束</strong>: 当多个事务同时尝试使用相同的键创建冲突记录时，约束必须<strong>决定</strong>哪一个被允许，哪些因为违反约束而失败</p>
<p>如果你只有一个节点，或者你愿意将决策权分配给单个节点，所有这些事都很简单。这就是在单领导者数据库中发生的事情：所有决策权归属于领导者，这就是为什么这样的数据库能够提供线性一致的操作，唯一性约束，完全有序的复制日志等。但如果该领导者失效，或者如果网络中断导致领导者不可达，这样的系统就无法取得任何进展。应对这种情况可以有三种方法：</p>
<blockquote>
<p>1️⃣等待领导者恢复，接受系统将在这段时间阻塞的事实。许多XA/JTA事务协调者选择这个选项。这种方法并不能完全达成共识，因为它不能满足<strong>终止</strong>属性的要求：如果领导者续命失败，系统可能会永久阻塞</p>
<p>2️⃣ 人工故障切换，让人类选择一个新的领导者节点，并重新配置系统使之生效，许多关系型数据库都采用这种方方式。这是一种来自“天意”的共识 —— 由计算机系统之外的运维人员做出决定。故障切换的速度受到人类行动速度的限制，通常要比计算机慢得多</p>
<p>3️⃣ 使用算法自动选择一个新的领导者。这种方法需要一种共识算法，使用成熟的算法来正确处理恶劣的网络条件是明智之举</p>
</blockquote>
<h1>批处理</h1>
<h2 id="关于衍生数据">关于衍生数据</h2>
<p>第三部分的内容，主要讨论将多个不同数据系统(有着不同的数据模型，并针对不同的访问模式进行优化)集成为一个协调一致的应用架构时，会遇到的问题。从高层次看，存储和记录数据系统分为2大类：</p>
<p>🅰️ 记录系统(System of record) ：数据的权威版本(如果其他系统和<strong>记录系统</strong>之间存在任何差异，那么记录系统中的值是正确的)</p>
<p>🅱️ 衍生数据系统(Derived data systems) ：通常是另一个系统中的现有数据进行转换或处理的结果，如缓存、索引、物化视图等，推荐系统中，预测汇总数据通常衍生自用户日志</p>
<p>三种不同的数据处理系统：</p>
<p>1️⃣ 服务(在线系统)</p>
<p>2️⃣ 批处理系统(离线系统)</p>
<p>3️⃣ 流处理系统(准实时系统)</p>
<p>流处理和批处理最关键的区别是处理无界数据和有界数据</p>
<blockquote>
<p>MPP数据库(大规模并行处理(MPP， massively parallel processing)专注于在一组机器上并行执行分析SQL查询，而MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统，批处理框架看起来越来越像MPP数据库了</p>
</blockquote>
<h2 id="UNIX">UNIX</h2>
<p>基于Unix的awk，sed，grep，sort，uniq和xargs等工具的组合，可以轻松的帮助我们完成一些数据分析的工作，而且性能相当的好。而且，这些工具使用相同的接口，在Unix中，这种接口是一个file(准确的说是一个文件描述符)</p>
<blockquote>
<p>文件是一个统一的接口，如果我们的程序的输入和输出都是文件，那么所有的程序缝合起来，像接力一样完成复杂的工作；统一的接口还包括URL和HTTP(我们可以在网站和网站之间无缝跳转)。这和函数式编程的理念非常类似</p>
</blockquote>
<p>Unix工具很强大，但是其局限性就是只能在一台机器上运行，所以Hadoop这样的工具应运而生</p>
<h2 id="MapReduce">MapReduce</h2>
<p>Unix和MapReduce比对</p>
<table>
<thead>
<tr>
<th>MR</th>
<th>除了生成输出没有副作用</th>
<th>简单粗暴却有效</th>
<th>分布式</th>
<th>分布式文件系统上读写文件</th>
<th>使用无共享架构</th>
<th>通过工作流(workflow)将多个MR作业连接在一起，文件</th>
</tr>
</thead>
<tbody>
<tr>
<td>Unix</td>
<td>除了生成输出没有副作用</td>
<td>简单粗暴却有效</td>
<td>单机</td>
<td>使用<code>stdin</code>和<code>stdout</code>作为输入输出</td>
<td>共享架构</td>
<td>管道符，内存缓存区<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup></td>
</tr>
</tbody>
</table>
<blockquote></blockquote>
<p>MapReduce是一个编程框架，可以使用它编写代码处理HDFS等分布式文件系统中的大型数据集，并且遵循<em>移动计算大于移动数据的原则</em>。MapReduce的数据处理过程如下：</p>
<p>1️⃣ 读取一组输入文件，并将其分解成记录(records)</p>
<p>2️⃣ 调用Mapper函数，从每条输入记录中提取一对键值；map的任务数由输入文件块的数量决定</p>
<p>3️⃣ 按键排序所有的键值对</p>
<p>4️⃣ 调用Reducer函数遍历排序后的键值对，相同的key，将会在reducer中相邻；reduce的任务数量是可配置的</p>
<p>其中第2️⃣4️⃣步是自定义数据处理代码的地方，第3️⃣步Mapper的输出始终在送往Reducer之前进行排序，无须编写。下图是个三个Mapper和三个Reducer的MR任务：</p>
<p align="center">
  <img src="/2023/09/21/ddia/42.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>Mapper中的数据去往Reducer的过程可以看做是Mapper将消息发送给Reducer，每当Mapper发出一个键值对，这个键的作用就好像是去往到目标地址(IP地址)</p>
<h2 id="Reducer端联接：">Reducer端联接：</h2>
<p>如下图，左侧是事件日志，右侧是用户数据库，任务需要将用户活动和用户档案相关联：</p>
<p align="center">
  <img src="/2023/09/21/ddia/43.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
整个连接的MapReduce过程如下:
<p align="center">
  <img src="/2023/09/21/ddia/44.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
MapReduce框架通过键对Mapper输出进行分区，然后对键值对进行排序，使得具有相同ID的所有活动事件和用户记录在Reducer输入中彼此相邻。 Map-Reduce作业可以进一步让这些记录排序，使Reducer总能先看到来自用户数据库的记录，紧接着是按时间戳顺序排序的活动事件(二次排序/secondary sort)
<p>然后Reducer可以执行实际的连接逻辑：每个用户ID都会被调用一次Reducer函数，且因为二次排序，第一个值应该是来自用户数据库的出生日期记录。 Reducer将出生日期存储在局部变量中，然后使用相同的用户ID遍历活动事件，输出已观看网址和观看者年龄的结果对。随后的Map-Reduce作业可以计算每个URL的查看者年龄分布，并按年龄段进行聚集</p>
<p>因为Mapper的输出是按键排序的，然后Reducer将来自连接两侧的有序记录列表合并在一起，所以这个算法被称为排序合并连接(sort-merge join)</p>
<p>MapReduce实现这分组操作的方法是设置Mapper，使得Mapper生成的键值对使用所需的分组键</p>
<blockquote>
<p>热键(hot pot)和倾斜连接(skewed join) ： 热键是指记录中某个键记录数显著高于其他的键，热键关联是会产生倾斜关联(1个Reducer会处理比其他Reducer更多的记录)；一般处理倾斜连接方式是分2次MR</p>
</blockquote>
<h2 id="Map端联接：">Map端联接<sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup>：</h2>
<p>在Reducer端连接中，排序，复制至Reducer，以及合并Reducer输入，所有这些操作可能开销巨大，如果数据具备某些特性，或许可以使用一些性能更优的连接方式，如：</p>
<p>1️⃣广播散列连接：在小表足够小的情况下，将小表读取到内存散列表中，然后Mapper扫描大表在散列表中查找每个事件</p>
<p>2️⃣ 分区散列连接：本质是GRACE Hash Join，在Hive中叫做：Map 端桶连接</p>
<p>3️⃣ Map端合并连接：本质是 sort-merge-join</p>
<blockquote></blockquote>
<p>批处理的常见用途是：构建机器学习系统(分类器/推荐系统等)，建立搜索索引(google最初使用MR就是为其搜索索引建立索引)，批处理的输出哲学和Unix一致，除了产生输出不会产生任何副作用，即容错能力高</p>
<h2 id="Hadoop与分布式数据库比对">Hadoop与分布式数据库比对</h2>
<p>Hadoop很像Unix的分布式版本，其中HDFS是分布式文件系统，MapReduce是Unix进程的变种实现，我们一直讨论的并行连接算法在MPP数据库中已有实现，区别在于MPP数据库专注于在一组机器上并行执行分析SQL，而MapReduce和分布式文件系统的组合更像是可以运行任意通用程序的操作系统</p>
<table>
<thead>
<tr>
<th></th>
<th>存储多样性</th>
<th>处理模型</th>
<th>故障处理</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hadoop</td>
<td>字节序列</td>
<td>MapReduce模型，SQL模型等<br>处理模型多样性<sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup></td>
<td>针对故障频繁而设计<sup class="footnote-ref"><a href="#fn22" id="fnref22">[22]</a></sup></td>
</tr>
<tr>
<td>分布式数据库</td>
<td>要求特定的模型(关系/文档)</td>
<td>SQL模型<sup class="footnote-ref"><a href="#fn23" id="fnref23">[23]</a></sup></td>
<td>查询失效时，多数MPP会终止查询</td>
</tr>
</tbody>
</table>
<blockquote></blockquote>
<p>💔：使用原始的<code>MapReduce API</code>来实现复杂的处理工作实际上是非常困难，所以在MapReduce上有很多高级编程模型(Pig，Hive，Cascading，Crunch)被创造出来。🅰️方面，MapReduce非常稳健；🅱️方面，对于某些类型的处理而言，其他工具有时会快上几个数量级。流处理组件(storm、spark、flink)可以认为是解决"慢"这个问题而被发展出来的，物化中间状态也是一种加速方式</p>
<h2 id="物化中间状态">物化中间状态</h2>
<p>将数据发布到分布式文件系统中众所周知的位置能够带来<strong>松耦合</strong>，这样作业就不需要知道是谁在提供输入或谁在消费输出，一个作业的输出只能用作另一个作业的输入的情况下，分布式文件系统上的文件只是简单的<strong>中间状态(intermediate state)</strong>：一种将数据从一个作业传递到下一个作业的方式。将这个中间状态写入文件的过程称为<strong>物化(materialization)</strong>[<sup>22][</sup>23]</p>
<blockquote>
<p>link: <a href="https://en.wikipedia.org/wiki/Materialized_view">https://en.wikipedia.org/wiki/Materialized_view</a> + <a href="https://stackoverflow.com/questions/93539/what-is-the-difference-between-views-and-materialized-views-in-oracle">https://stackoverflow.com/questions/93539/what-is-the-difference-between-views-and-materialized-views-in-oracle</a> + <a href="https://en.wikipedia.org/wiki/Materialized_view">https://en.wikipedia.org/wiki/Materialized_view</a></p>
</blockquote>
<p>💔：Unix管道将一个命令的输出与另一个命令的输入连接起来。管道并没有完全物化中间状态，而是只使用一个小的内存缓冲区，将输出增量地**流(stream)**向输入，与Unix管道相比，MapReduce完全物化中间状态的方法的不足之处在于：</p>
<p>1️⃣MapReduce作业只有在前驱作业(生成其输入)中的所有任务都完成时才能启动，而由Unix管道连接的进程会同时启动，输出一旦生成就会被消费</p>
<p>2️⃣ Mapper通常是多余的，如果Reducer和Mapper的输出有着相同的分区与排序方式，那么Reducer就可以直接串在一起，而不用与Mapper相互交织</p>
<p>3️⃣ 将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点</p>
<h2 id="数据流引擎">数据流引擎</h2>
<p>为了解决MapReduce的这些问题，几种用于分布式批处理的新执行引擎(Spark、Tez、Flink)被开发出来，它们的设计方式有很多区别，但有一个共同点：把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。由于它们将工作流显式建模为数据从几个处理阶段穿过，所以这些系统被称为<strong>数据流引擎(dataflow engines)</strong>，像MapReduce一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，这些函数为<strong>算子(operators)</strong>，数据流引擎提供了几种不同的选项来将一个算子的输出连接到另一个算子的输入：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>一种选项是对记录按键重新分区并排序，就像在MapReduce的混洗阶段一样。这种功能可以用于实现排序合并连接和分组</p>
</li>
<li class="lvl-2">
<p>另一种可能是接受多个输入，并以相同的方式进行分区，但跳过排序。当记录的分区重要但顺序无关紧要时，这省去了分区散列连接的工作，因为构建散列表还是会把顺序随机打乱</p>
</li>
<li class="lvl-2">
<p>对于广播散列连接，可以将一个算子的输出，发送到连接算子的所有分区</p>
</li>
</ul>
<p>与MapReduce模型相比，它有几个优点：</p>
<p>1️⃣排序等昂贵的工作只需要在实际需要的地方执行，而不是默认地在每个Map和Reduce阶段之间出现</p>
<p>2️⃣没有不必要的Map任务，因为Mapper所做的工作通常可以合并到前面的Reduce算子中(因为Mapper不会更改数据集的分区)</p>
<p>3️⃣由于工作流中的所有连接和数据依赖都是显式声明的，因此调度程序能够总览全局，知道哪里需要哪些数据，因而能够利用局部性进行优化。例如，它可以尝试将消费某些数据的任务放在与生成这些数据的任务相同的机器上，从而数据可以通过共享内存缓冲区传输，而不必通过网络复制</p>
<p>4️⃣通常，算子间的中间状态足以保存在内存中或写入本地磁盘，这比写入HDFS需要更少的I/O(必须将其复制到多台机器，并将每个副本写入磁盘)。 MapReduce已经对Mapper的输出做了这种优化，但数据流引擎将这种思想推广至所有的中间状态</p>
<p>5️⃣ 算子可以在输入就绪后立即开始执行；后续阶段无需等待前驱阶段整个完成后再开始</p>
<p>6️⃣ 与MapReduce(为每个任务启动一个新的JVM)相比，现有Java虚拟机(JVM)进程可以重用来运行新算子，从而减少启动开销</p>
<p>你可以使用数据流引擎执行与MapReduce工作流同样的计算，而且由于此处所述的优化，通常执行速度要明显快得多。相同的处理逻辑，可以通过修改配置切换底层计算引擎，简单地从MapReduce切换到Tez或Spark<sup class="footnote-ref"><a href="#fn24" id="fnref24">[24]</a></sup></p>
<blockquote></blockquote>
<h2 id="总结-3">总结</h2>
<p>本章主要讲述了Unix的管道思想，MapReduce与其接口HDFS，最后是数据流引擎构建自己的管道式的数据传输机制。并且还讨论了分布式批处理框架要解决的2个主要问题：</p>
<p>🅰️ 分区：这一过程的目的是把所有的<strong>相关</strong>数据(例如带有相同键的所有记录)都放在同一个地方</p>
<p>🅱️容错：MapReduce经常写入磁盘，这使得从单个失败的任务恢复很轻松，无需重新启动整个作业，但在无故障的情况下减慢了执行速度。数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态，这意味着如果节点发生故障，则需要重算更多的数据。确定性算子减少了需要重算的数据量</p>
<h1>流处理</h1>
<p>流处理和批处理最原始的区别在于，流处理处理无界数据，而批处理针对有界数据。在流处理中的上下文中，记录通常被叫做<strong>事件</strong>，一个事件由生产者(producer)/发布者(publisher)/发送者(sender)生成一次，然后可能由多个消费者(consumer)/订阅者(subscribers)/接收者(recipients)进行处理。流处理的目标是<strong>事件发生后，立刻得到处理</strong>。流处理中相关的事件通常被聚合为一个主题(topic)或流(stream)</p>
<p>本质上来说，文件或者是数据库可以连接生产者和消费者，但是这种方式下消费者需要不断降低轮询文件/数据库的间隔，才能降低事件处理的延迟，而轮询会增加数据库的额外开销，我们希望在有新的事件产生的时候，能够通知到消费者，数据库的触发器或许是一个可选项，但是触发器功能有限，为了解决这个问题，消息系统应运而生</p>
<blockquote>
<p>2个进程之间进行消息传递(通信)，可以通过接口调用，还可以使用消息服务</p>
</blockquote>
<h2 id="消息系统">消息系统</h2>
<p>消息系统一定要考虑2个问题：</p>
<p>🅰️生产者发送消息的速度比消费者能够处理的速度快该如何应对？有三种方式处理：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1️⃣丢掉消息</p>
</li>
<li class="lvl-2">
<p>2️⃣将消息放入缓冲队列</p>
</li>
<li class="lvl-2">
<p>3️⃣ 背压机制(backpressure)/流量控制(flow control)：即为阻塞生产者，避免其发送更多的消息<sup class="footnote-ref"><a href="#fn25" id="fnref25">[25]</a></sup></p>
</li>
</ul>
<blockquote></blockquote>
<p>🅱️ 如果节点崩溃或短暂脱机，是否会有消息丢失？也即<strong>持久性</strong>要求</p>
<p>批处理的一个优良的特性是，它提供了强大的可靠性保证：失败的任务会自动重试，且失败任务的输出会自动丢弃。这意味着好像故障没有发生一样，我们尝试⚠️<em>在流处理中达到类似的保证</em>。有些消息系统是直连生产者和消费者，比如使用UDP连接的应用，这种方式的确latency很低，但此类应用有一个前提假设：消费者和生产者始终在线，流处理如果是用这种方式，消费者一旦脱机，可能会丢失期间的消息</p>
<p><strong>消息代理/消息队列</strong></p>
<p>本质上消息代理是<strong>针对处理消息流</strong>的数据库。消息代理解决了上文提及的2个问题：</p>
<p>🅰️ (消费者)消费能力不足时，暂存消息；不需要丢弃消息或者背压</p>
<p>🅱️ 持久性保证：落盘</p>
<table>
<thead>
<tr>
<th>消息代理</th>
<th>消息<em>成功</em>传递给消费者后，自动删除</th>
<th>基于主题的模式匹配</th>
<th>不支持任意查询，数据变化时，会通知消费者</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据库</td>
<td>数据库保留数据直到显示删除</td>
<td>数据库支持二级索引</td>
<td>查询时，往往是基于某个时间点的快照</td>
</tr>
</tbody>
</table>
<p>如上描述的，消息队列和常规的数据的差别，其中行1是关于消息代理的传统观点，被封装在JMS/AMQP<sup class="footnote-ref"><a href="#fn26" id="fnref26">[26]</a></sup>标准中，其实现有RabbitMQ，ActiveMQ等</p>
<blockquote>
<p>AMQP: Advanced Message Queuing Protocol 高级消息队列协议：面向消息中间件提供的开放的应用层协定</p>
</blockquote>
<p>消息代理中，如果有多个消费者读取同一个主题的消息时，使用2种主要的消息传递模式:</p>
<p>🅰️ 负载均衡(load balance) : 在消费者间共享消费主题</p>
<p>🅱️ 扇出(fan-out) ： 将每条消息传递给多个消费者</p>
<p>两种模式可以组合使用：两个独立的消费者组可以每组各订阅一个主题，每一组都共同收到所有消息，但在每一组内部，每条消息仅由单个节点处理</p>
<p align="center">
  <img src="/2023/09/21/ddia/38.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>消息代理使用确认(acknowledgment)<sup class="footnote-ref"><a href="#fn27" id="fnref27">[27]</a></sup>机制，来确保消息不会丢失，但一种可能的情况是：代理向消费者传递消息后消费者崩溃或处理了部分崩溃了，代理由于超出一段时间没有收到确认(也可能是确认在网络中丢失了)，便将消息传递给另外一个消费者，当消费者的消费模式是负载均衡时，下面的情况可能会发生：处理m3时消费者2崩溃，因此稍后重传至消费者1</p>
<p align="center">
  <img src="/2023/09/21/ddia/39.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<blockquote></blockquote>
<p>批处理的关键特性是：重试失败任务不会发生任何副作用，而AMQP/JMS风格的消息传递收到消息是具有破坏性的，因为确认可能导致消息从代理中被删除，因此再次运行同一个消费者可能会得到不同的结果。即便是注册新的消费者到消息系统，通常只能接收到消费者注册之后开始发送的消息，而文件系统/数据库系统新增的客户端能够读取到任意久远的数据</p>
<p><strong>基于日志的消息代理(log-based message brokers)</strong> 尝试实现 🅰️既有数据库的持久存储方式；🅱️又有消息传递的低延迟通知</p>
<h2 id="基于日志的消息代理">基于日志的消息代理</h2>
<p>在基于日志(append only mode)的消息代理中，生产者通过将消息追加到日志末尾来发送消息，而消费者通过依次读取日志来接收消息，若消费者读到日志末尾，则会等待新消息追加的通知(如Unix的 <code>tail -f</code>)。同时为了提升吞吐量，基于日志的消息代理可以对日志进行分区，每个分区内，代理为每个消息分配一个<em>单调递增</em>的序列号/偏移量(offset)。并且<em>分区内消息完全有序(跨分区无顺序保证</em>)</p>
<p align="center">
  <img src="/2023/09/21/ddia/40.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>Apache Kafka、Amazon Kinesis Streams、Twitter的DistributedLog都是基于日志的消息代理。其中下面几点要注意：</p>
<p>1️⃣消费者组：支持多个消费者组成一个消费者主订阅一个主题，单个节点消费特定的分区，一般而言单线程处理单分区是更适合的选择，通过增加分区的方式提高并行度</p>
<p>2️⃣ 消费者偏移量：所有偏移量小于消费者的当前偏移量的消息已经被处理(类似单主复制中的日志序列号)<sup class="footnote-ref"><a href="#fn28" id="fnref28">[28]</a></sup></p>
<blockquote></blockquote>
<p>3️⃣重播旧消息：消费者的消费唯一的副作用就是导致偏移量的前进，但是消费者可以操纵偏移量(类似于批处理)</p>
<h2 id="流和数据库">流和数据库</h2>
<p>此间的讨论，我们发现基于日志的消息代理从数据库中获得灵感并将其应用于消息传递，其实也可以反过来，从消息传递和流中获得灵感，并将他们应用于数据库。在单主复制中，主库的写入事件构成写入流，将写入流应用到从库，最终得到数据的精确副本。在异构数据系统中，由于相同或相关的数据出现在了不同的地方，因此相互间需要保持同步：如果某个项目在数据库中被更新，它也应当在缓存，搜索索引和数据仓库(使用ETL)中被更新，我们在批处理将描述了如何使用批处理去更新其他衍生数据系统。使用的批处理的弊端是时延，如何保证衍生数据系统低延迟获取记录系统的变更数据？</p>
<p>这就涉及到<strong>变更数据捕获(change data capture, CDC)</strong>,这是一种观察写入数据库的所有数据变更，并将其提取并转换为可以复制到其他系统中的形式的过程。如下图：捕获数据库中的变更，并不断将相同的变更应用至搜索索引</p>
<p align="center">
  <img src="/2023/09/21/ddia/45.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
从本质上说，变更数据捕获使得一个数据库成为领导者(被捕获变化的数据库)，并将其他组件变为追随者。基于日志的消息代理非常适合从源数据库传输变更事件，因为它保留了消息的顺序。 LinkedIn的Databus，Facebook的Wormhole和Yahoo!的Sherpa大规模地应用这个思路。 Bottled Water使用解码WAL的API实现了PostgreSQL的CDC，Maxwell和Debezium通过解析binlog对MySQL做了类似的事情
<p>重放<strong>所有</strong>对数据库进行变更的日志，过于耗时，因此一般会保留数据库的快照，快照+快照时刻对应的偏移量可以加快重建数据库的完整状态。另外一个加速重建数据库完整状态的方式是日志压缩<sup class="footnote-ref"><a href="#fn29" id="fnref29">[29]</a></sup>，Apache Kafka支持这种日志压缩功能</p>
<blockquote></blockquote>
<h2 id="事件溯源-Event-Sourcing">事件溯源(Event Sourcing)</h2>
<p>事件溯源起源于领取驱动设计(domain-driven design,DDD)，和CDC类似，事件溯源将<strong>所有涉及对应用状态的变更存储为变更事件日志</strong>，其核心在于将用户的行为记录为不可变的事件，而不是在可变数据库中记录这些行为的影响。事件存储是仅追加的，原地删除和更新是不被鼓励的。事件日志和星型模式中的事实表有相似之处</p>
<p>使用事件溯源的应用需要拉取事件日志(表示写入系统的数据)，并将其转换为适合向用户显示的应用状态，和CDC一样，重放事件日志可以重新构建系统的当前状态。 事件溯源的哲学是仔细区分<strong>事件(event)<strong>和</strong>命令(command)</strong>，用户的请求刚到达时，它一开始是一个命令(在这个时间点上它仍然可能可能失败，比如违反了一些完整性条件)应用必须首先验证它是否可以执行该命令。如果验证成功并且命令被接受，则它变为一个持久化且不可变的事件。从数学角度来看，应用状态是事件流对时间求积分的结果 $state(now) = \int_{t=0}^{now}{stream(t) \ dt}$，变更流是应用状态对时间求微分的结果 $stream(t) = \frac{d\ state(t)}{dt}$</p>
<p>日志压缩是连接事件日志与数据库状态之间的桥梁：它只保留每条记录的最新版本，并丢弃被覆盖的版本。我们可以基于事件溯源中的记录的事件日志派生出多个视图，通过将数据写入的形式与读取形式相分离<sup class="footnote-ref"><a href="#fn30" id="fnref30">[30]</a></sup>，并允许几个不同的读取视图，这样极大的提高了灵活性</p>
<blockquote></blockquote>
<p>事件溯源和变更数据捕获的最大缺点是事件日志的消费者通常是异步的，所以可能出现的情况是：用户写入日志，然后从日志衍生视图中读取，结果发现他的写入还没有反映在读取视图中，一种解决方案是将事件附加到日志时同步执行读取视图的更新，如果是事件日志和读取视图保存在同一个存储系统中，需要使用事务，如果是异构数据库则涉及分布式事务</p>
<p>🎈至此，我们谈及到了流的来源1️⃣用户活动事件，2️⃣传感器，3️⃣写入数据库；流如何传输1️⃣直接通过消息传送 2️⃣消息代理 3️⃣ 事件日志。那么我们用流干什么？</p>
<h2 id="流处理">流处理</h2>
<p>流一般有以下三种用途</p>
<p>1️⃣ 你可以将事件中的数据写入数据库，缓存，搜索索引或类似的存储系统，然后能被其他客户端查询</p>
<p>2️⃣ 以某种方式将事件推送给用户，如发送报警邮件或推送通知，或将事件流式传输到可实时显示的仪表板上。这种情况下，人是流的最终消费者</p>
<p>3️⃣ 你可以处理一个或多个输入流，并产生一个或多个输出流。流可能会经过由几个这样的处理阶段组成的流水线，最后再输出1️⃣或2️⃣</p>
<p>我们将重点讨论3️⃣处理流产生其他衍生流，处理这样的流的代码片段，称之为算子(operator)或者作业(job)；流处理和批处理最大的区别是流处理处理无界数据，由于是无界导致排序没有意义，也就无法使用排序合并连接（sort merge join），容错机制也不能像批处理那样通过从头执行的方式</p>
<h2 id="流处理应用">流处理应用</h2>
<p>1️⃣ 复合事件处理(complex,event processing CEP)，CEP通常使用高层次的声明式查询语句如SQL，在流中搜索某些事件（就像正则表达式一样），当发现匹配时，引擎发出一个<strong>复合事件(complex event)</strong>（因此得名）。一般而言，数据库会持久存储数据，并将查询视为临时的，当查询进入时，数据库搜索与查询匹配的数据，然后在查询完成时丢掉查询。 CEP引擎反转了角色：查询是长期存储的，来自输入流的事件不断流过它们。CEP的实现包括 Esper、IBM InfoSphere Streams</p>
<p>2️⃣流分析，流分析关注大量事件上的聚合与统计指标，统计指标通常是在固定时间区（窗口[window]）间内进行计算的。许多开源分布式流处理框架的设计都是针对分析设计的：例如Apache Storm，Spark Streaming，Flink</p>
<p>3️⃣ 维护物化视图。数据库的变更流（CDC或是事件日志）可以用于维护衍生数据系统，使其与源数据库保持最新，基于衍生查询（写入和查询相分离）。也是流的一个应用，但是要求任意时间段内的所有事件，和流分析场景有很大的不同。类似Spark Streaming 不支持</p>
<h3 id="关于事件时间和处理时间">关于事件时间和处理时间</h3>
<p>🅰️ 处理时间：事件到达处理节点的时钟。使用处理时间定义窗口，会因为处理速率的变动引入人为因素，如下图：</p>
<p align="center">
  <img src="/2023/09/21/ddia/46.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<p>🅱️ 事件时间：事件发生的时间。延迟先发生的事件先到达处理节点，无法确定是否已经收到了特定窗口的所有事件，如何处理这种在窗口宣告完成之后到达的滞留（straggler）事件？</p>
<h3 id="窗口">窗口</h3>
<p>1️⃣ 滚动窗口(Tumbling Window)：窗口有固定的长度，而且每个事件都只属于一个窗口</p>
<p>2️⃣跳动窗口(Hopping Window) ：窗口有固定的长度，如1分钟跳跃步长的5分钟窗口</p>
<p>3️⃣滑动窗口(Sliding Window)：滑动窗口包含了彼此间距在特定时长内的所有事件，通过维护一个按时间排序的事件缓冲区，并不断从窗口中移除过期的旧事件，可以实现滑动窗口</p>
<p>4️⃣会话窗口(Session window) 将同一用户出现时间相近的所有事件分组在一起，而当用户一段时间没有活动时（例如，如果30分钟内没有事件）窗口结束</p>
<h2 id="流式连接">流式连接</h2>
<p>涉及<strong>流-流</strong>连接，<strong>流-表</strong>连接，与<strong>表-表</strong>连接</p>
<p>1️⃣ 流流连接，实际是窗口的连接，Window join 作用在两个流中有<em>相同 key</em> 且处于<em>相同窗口</em>的元素上。比如Flink将流流连接细分为滚动Window Join，滑动Window Join，会话Window Join。<a href="https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/datastream/operators/joining/">Flink的双流Join</a>。比如下图是Spark Streaming中一个广告流和一个点击流的连接</p>
<p align="center">
  <img src="/2023/09/21/ddia/55.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<span class="github-emoji" style="display:inline;vertical-align:middle"><span>2⃣</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/0032-20e3.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>流表连接，实际是流扩展。如下图的点击流和用户档案的连接，首先将数据库副本加载到流处理器中，然后流处理器需要一次处理一个活动事件。 流表连接实际上非常类似于流流连接；最大的区别在于对于表的变更日志流，连接使用了一个可以回溯到“时间起点”的窗口
<p align="center">
  <img src="/2023/09/21/ddia/43.jpg" width="85%" alt="Your image description">
    <br>
  <span style="color:gray"> todo </span>
</p>
<span class="github-emoji" style="display:inline;vertical-align:middle"><span>3⃣</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/0033-20e3.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 表表连接。在推特时间线的例子中，用户查看自身主页时间线时，迭代用户所关注人群的推文并合并它们需要一个时间线缓存，在流处理器中实现这种缓存维护，需要推文事件流(发送与删除)和关注关系事件流(关注与取消关注)，即该流处理的过程是维护了一个连接了两个表(推文与关注)的物化视图，如下时间线实际上是这个查询结果的缓存，每当基础表发生变化时都会更新
<figure class="highlight sql"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> follows.follower_id <span class="keyword">as</span> timeline_id, </span><br><span class="line">    <span class="built_in">array_agg</span>(tweets.<span class="operator">*</span> <span class="keyword">order</span> <span class="keyword">by</span> tweets.timestamp <span class="keyword">desc</span>)</span><br><span class="line"><span class="keyword">from</span> tweets</span><br><span class="line"><span class="keyword">join</span> follows <span class="keyword">on</span>  tweets.sender_id <span class="operator">=</span> follows.followee_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> follows.follower_id</span><br></pre></td></tr></tbody></table></figure>
<h2 id="连接的时间依赖性">连接的时间依赖性</h2>
<p>流流、流表、表表连接有很多共同点，<strong>他们都需流处理器维护连接一侧的一些状态(广告流和点击流，用户档案，关注列表)，然后当连接另外一侧的消息到达时查询该状态</strong>。这里会有一个问题，如在流表连接的例子中，如果用户更新了档案，哪些活动事件与旧档案连接(在档案更新前)？，哪些又与新档案连接(在档案更新后)？即连接存在<em>时序依赖</em>，比如处理发票和税率问题时，当连接销售额与税率表时，你可能期望的是使用销售时的税率参与连接，如果你正在重新处理历史数据，销售时的税率可能和现在的税率有所不同</p>
<p>即如果跨流事件的顺序是未定的，则连接会变成不确定性的，那么在同样输入上重跑可能会得到不同的结果。这个问题在数仓中叫<em>缓慢变化的维度(slowly changing dimension,SCD)<sup class="footnote-ref"><a href="#fn31" id="fnref31">[31]</a></sup></em>，通常通过对特定版本的记录使用唯一的标识符来解决：例如，每当税率改变时都会获得一个新的标识符，而发票在销售时会带有税率的标识符。这种变化使连接变为确定性的，但也会导致日志压缩无法进行：表中所有的记录版本都需要保留</p>
<blockquote></blockquote>
<h2 id="流处理如何处理容错">流处理如何处理容错</h2>
<p>在批处理中，容错的方式就是重跑，而且其输出的效果就像只处理了一次一样，这个原则叫做<strong>恰好/精确一次语义(exactly-once semantics)</strong>，流处理为了实现恰好一次语义，有以下2种方式</p>
<p>🅰️ 微批，即将流分解成小块，并像微型批处理一样处理每个块，微批次(通常为1S)也隐式提供了一个与批次大小相等的滚动窗口(<em>按处理时间而不是事件时间戳分窗</em>)，代表应用为Spark Streaming</p>
<p>🅱️存档点， Apache Flink会定期生成状态的滚动存档点并将其写入持久存储。如果流算子崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出</p>
<p>在流处理框架的范围内，微批次与存档点方法提供了与批处理一样的<strong>恰好一次语义</strong>。但是，只要输出离开流处理器(例如，写入数据库，向外部消息代理发送消息，或发送电子邮件)，框架就无法抛弃失败批次的输出了。在这种情况下，重启失败任务会导致外部副作用发生两次，只有微批次或存档点不足以阻止这一问题，我们需要确保事件处理的所有输出和副作用<strong>当且仅当</strong>处理成功时才会生效。分布式事务是一种解决方案，另外一种方式是<strong>幂等性</strong>(idempotence)</p>
<p>幂等操作是多次重复执行与单次执行效果相同的操作，例如，将键值存储中的某个键设置为某个特定值是幂等的（再次写入该值，只是用同样的值替代），而递增一个计数器不是幂等的(再次执行递增意味着该值递增两次)。在使用来自Kafka的消息时，每条消息都有一个持久的，单调递增的偏移量。将值写入外部数据库时可以将这个偏移量带上，这样你就可以判断一条更新是不是已经执行过了，因而避免重复执行</p>
<p>&lt;完&gt;</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>意味着即使发生故障，系统也能正常工作 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>意味着即使在负载增加的情况下也有保持性能的策略 <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>有许多方面，但实质上是关于工程师和运维团队的生活质量的 <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>SSTable : Sort String Table ，排序字符串表，对每个段文件中的键进行排序 <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>卡桑德拉，Apache Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于改善电子邮件系统的搜索性能的简单格式数据，集Google BigTable的数据模型与Amazon Dynamo的完全分布式架构于一身 <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>和ES一样是一个企业级的搜索索引 <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Hologres存储引擎： <a href="https://developer.aliyun.com/article/779284?spm=a2c4g.11186623.0.0.11cf49fc9XL2Nw&amp;groupCode=hologres">https://developer.aliyun.com/article/779284?spm=a2c4g.11186623.0.0.11cf49fc9XL2Nw&amp;groupCode=hologres</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>固定大小的块或者页面：如果读者注意到过SQL引擎的执行计划的话，一般会有一个类似seq_page_cost（postgresql叫这个）的参数描述的就是每次Planner抓取一个数据页的成本（cost）， the planner’s estimate of the cost of a disk page fetch that is part of a series of sequential fetches <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>数据湖：是指使用<a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%80%B2%E4%BD%8D%E5%A4%A7%E5%9E%8B%E7%89%A9%E4%BB%B6">大型二进制对象</a>或文件这样的自然格式储存数据的系统[<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E6%B9%96#cite_note-1">1]</a>  ，数据湖可以包括<a href="https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93">关系数据库</a>的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B">结构化数据</a>(行与列)、半结构化的数据(<a href="https://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC">CSV</a>，日志，<a href="https://zh.wikipedia.org/wiki/XML">XML</a>, <a href="https://zh.wikipedia.org/wiki/JSON">JSON</a>)，非结构化数据 (电子邮件、文件、PDF)和 二进制数据(图像、<a href="https://zh.wikipedia.org/wiki/%E6%95%B8%E4%BD%8D%E9%9F%B3%E8%A8%8A">音频</a>、视频) <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>分区有很多中叫法，比如Solr Cloud中被称为分片(shard),在HBase中称之为区域(Region)，Bigtable/Kudu中则是表块(tablet，Cassandra和Riak中是虚节点(vnode), Couchbase中叫做虚桶(vBucket)，但是分区(partition)是约定俗成的叫法 <a href="#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>该分区方式依赖于散列函数，一个 $32$ 位散列函数,无论何时给定一个新的字符串输入，它将返回一个 $0$ 到 $2^{32} -1$ 之间的"随机"数 <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>我们搜索的关键词决定了次级索引的分区方式，因此称之为关键词索引，关键词(term)一词来源于全文搜索索引(一种特殊的次级索引)。 <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>即一致性哈希解决的问题，一致性哈希的主要应用就是降低路由成本 <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>关于硬件故障：硬件故障率是很高的，磁盘在进行大量的读写之后失效的概率是很高的，IDC数据中心对物理环境的要求是很苛刻的，为了降低温度空调不够用，甚至把数据中心搬到山洞里，比如阿里在贵州云南的IDC，地板使用静电地板，每个机房入口的挡鼠板比膝盖还高，供电都是双路供电等。 <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>行锁满足两阶段锁协议，两阶段锁协议是说：锁需要的时候才加上的，在事务结束的时候才释放；同时行锁也是2PL（2阶段锁定），在当前事务写入时必须持有排它锁，直到事务提交才释放排它锁。 <strong>两阶段锁协议和2pl说的是一个事情</strong> <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制； <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>更新数据是先读后写的，读只能读当前<strong>已提交</strong>的最新值，这就是当前读 <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>网络分区区别于分区，分区是一种中将数据集划分为多块，以此来提升并发读写能力； 而网络分区是指节点<em>彼此断开</em>但是仍然活跃。 <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>多个MR任务连接的方式是将后一个MR任务的输入配置为前一个MR任务的输出；而Unix命令管道是直接将一个进程的输出作为另外一个进程的输入，仅用一个很小的内存缓冲区 <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p>关于上述三种连接方式请参阅：<a href="https://mp.weixin.qq.com/s/lulNpgxillQ0s5fb_rgvdw">https://mp.weixin.qq.com/s/lulNpgxillQ0s5fb_rgvdw</a> <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p>并非所有数据类型的处理都可以合理的用SQL表达(推进系统、特征工程等)，所以编写代码是必须的，而MR能使得工程师可以轻松的在大型数据集上执行自己的代码，甚至还可以基于MapReduce+HDFS 建立SQL查询执行引擎，比如Hive就是这么做的；除了SQL和MapReduce之外，由于Hadoop平台的开放性，还可以构建更多的模型。由于不需要将数据导入到专门的系统进行不同类型的处理，采用新的处理模型也更容易。如MPP风格的分析型数据库impala，随机访问风格的OLTP数据库HBase(LSM) <a href="#fnref21" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p>落盘一方面是容错，一方面是假设数据集太大不能适应内存。并且支持支持资源的过度使用 <a href="#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p>MPP 是单体的紧密集成的软件，负责磁盘上的存储布局，查询计划，调度和执行，这些组件针对数据库的特定需求做了优化，因此可以对特定查询有很好的性能，但只支持SQL模型 <a href="#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p>Tez是一个相当薄的库，它依赖于YARN shuffle服务来实现节点间数据的实际复制，而Spark和Flink则是包含了独立网络通信层，调度器，及用户向API的大型框架 <a href="#fnref24" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn25" class="footnote-item"><p>比如能够恰好连接1个生产者和一个消费者Unix管道和TCP连接，他们在应对这个问题的时候使用背压机制，它们有一个固定大小的缓冲区，一旦填满发送者就会被阻塞，直到接受者从缓冲区取出数据 <a href="#fnref25" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn26" class="footnote-item"><p>JMS: Java Message Service，是关于Java消息中间的一组接口标准，所有消息中间件(MOM)需要实现这组接口，可类比JDBC <a href="#fnref26" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn27" class="footnote-item"><p>确认机制：消费者必须显示的告知代理处理完毕的时间，以便代理将消息从队列中移除 <a href="#fnref27" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn28" class="footnote-item"><p>❓消费者节点失效，则失效消费者的分区将指派给其他节点，并从最后记录的偏移量开始消费消息。如果消费者已经处理了后续的消息，但还没有记录它们的偏移量，那么重启后这些消息将被处理两次，这个问题如何解决呢? <a href="#fnref28" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn29" class="footnote-item"><p>日志压缩：类似在hash索引中讨论的日志压缩，存储引擎定期查找具有相同键的记录，丢弃到重复的内容并且只保留每个键的最新值。比如在CDC系统被配置为，每个变更都包含一个主键，且每个键的更新都替换了该键以前的值，那么只需要保留对键的最新写入就足够了。无论何时需要重建衍生数据系统(如搜索索引)，你可以从压缩日志主题0偏移量处启动新的消费者，然后依次扫描日志中的所有消息 <a href="#fnref29" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn30" class="footnote-item"><p>写入和读取形式相分离，也叫命令查询责任分离(command query responsibility segregation, CQRS） <a href="#fnref30" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn31" class="footnote-item"><p>SCD，处理SCD问题有很多种方式，从SCD0到SCD6，其中最流行的是：SCD1和SCD2；wiki：<a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension%EF%BC%9BYouTube">https://en.wikipedia.org/wiki/Slowly_changing_dimension；YouTube</a> tutorial：<a href="https://www.youtube.com/watch?v=XqdZF0DJpUs">https://www.youtube.com/watch?v=XqdZF0DJpUs</a> <a href="#fnref31" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
</search>
